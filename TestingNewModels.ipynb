{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3e31034-f4fb-481e-b6f0-4dc10bce5dc6",
   "metadata": {},
   "source": [
    "# Собираем датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67986054-41c4-4890-bbf4-a47dd27d6769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ta\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def add_ta_features_for_asset(df: pd.DataFrame, prefix: str, volume_col_override: str = None) -> pd.DataFrame:\n",
    "    \"\"\"Добавляет TA-индикаторы для актива с заданным префиксом.\n",
    "    \n",
    "    Parameters:\n",
    "        prefix: префикс колонок актива (e.g. \"gold\", \"sp500\", \"spot_price_history\")\n",
    "        volume_col_override: полное имя volume-колонки, если оно не {prefix}__volume\n",
    "                             (e.g. \"spot_price_history__volume_usd\" для BTC)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    required = ['open', 'close', 'high', 'low', 'volume']\n",
    "    col_map = {col: f\"{prefix}__{col}\" for col in required}\n",
    "\n",
    "    # Позволяем переопределить имя volume-колонки\n",
    "    if volume_col_override:\n",
    "        col_map['volume'] = volume_col_override\n",
    "\n",
    "    missing = [col_map[c] for c in required if col_map[c] not in df.columns]\n",
    "    if missing:\n",
    "        print(f\"  Пропущены колонки для {prefix}: {missing}\")\n",
    "        return df\n",
    "\n",
    "    temp_df = pd.DataFrame({\n",
    "        'open': df[col_map['open']].values,\n",
    "        'high': df[col_map['high']].values,\n",
    "        'low': df[col_map['low']].values,\n",
    "        'close': df[col_map['close']].values,\n",
    "        'volume': df[col_map['volume']].values\n",
    "    })\n",
    "\n",
    "    temp_with_ta = ta.add_all_ta_features(\n",
    "        temp_df,\n",
    "        open=\"open\", high=\"high\", low=\"low\", close=\"close\", volume=\"volume\",\n",
    "        fillna=False\n",
    "    )\n",
    "\n",
    "    original_cols = {'open', 'high', 'low', 'close', 'volume'}\n",
    "    ta_cols = [c for c in temp_with_ta.columns if c not in original_cols]\n",
    "\n",
    "    for col in ta_cols:\n",
    "        df.loc[df.index, f\"{prefix}__{col}\"] = temp_with_ta[col].values\n",
    "\n",
    "    print(f\"  Добавлено {len(ta_cols)} TA-фичей для {prefix}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def add_lags(df: pd.DataFrame, cols: list, lags: tuple) -> pd.DataFrame:\n",
    "    \"\"\"Добавляет лаговые признаки для указанных колонок.\"\"\"\n",
    "    df = df.copy()\n",
    "    for col in cols:\n",
    "        for lag in lags:\n",
    "            df[f\"{col}__lag{lag}\"] = df[col].shift(lag)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48bdddf3-781e-4d4a-9562-100aa492946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "from LoggingSystem.LoggingSystem import LoggingSystem\n",
    "from FeaturesGetterModule.FeaturesGetter import FeaturesGetter\n",
    "from get_features_from_API import get_features\n",
    "from FeaturesGetterModule.helpers._merge_features_by_date import merge_by_date\n",
    "from FeaturesEngineer.FeaturesEngineer import FeaturesEngineer\n",
    "\n",
    "# =============================================================================\n",
    "# Конфигурация\n",
    "# =============================================================================\n",
    "load_dotenv(\"dev.env\")\n",
    "api_key = os.getenv(\"COINGLASS_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"COINGLASS_API_KEY not found in dev.env\")\n",
    "\n",
    "N_DAYS = 3\n",
    "TARGET_COLUMN_NAME = f\"y_up_{N_DAYS}d\"\n",
    "EXTERNAL_LAGS = (1, 3, 5, 7, 10, 15)\n",
    "\n",
    "# Инициализация\n",
    "getter = FeaturesGetter(api_key=api_key)\n",
    "features_engineer = FeaturesEngineer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "411911f4-9e9c-4791-95f6-fd5a940808a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "1. Gathering features from API...\n",
      "   Raw data shape: (5659, 112)\n",
      "============================================================\n",
      "2. Normalizing spot columns & Applying ffill...\n",
      "   Remaining NaN after ffill: 400195\n",
      "============================================================\n",
      "3. Engineering features & Adding lags...\n",
      "   Shape before feature engineering: (5659, 112)\n",
      "  Добавлено 86 TA-фичей для gold\n",
      "  Добавлено 86 TA-фичей для sp500\n",
      "  Добавлено 86 TA-фичей для spot_price_history\n",
      "   Added 180 lag features (OHLCV only, no TA lags)\n",
      "   Lagged columns: 30 per asset\n",
      "============================================================\n",
      "4. Filtering last 1500 days...\n",
      "   Rows kept: 1501 (from 5659)\n",
      "============================================================\n",
      "5. Final cleanup...\n",
      "   Dropping 127 columns with >30% NaN\n",
      "   Final Dropna: removed 431 rows.\n",
      "============================================================\n",
      "FINAL DATASET SHAPE: (1070, 650)\n",
      "Date range: 2022-11-26 00:00:00 to 2026-02-12 00:00:00\n",
      "Target distribution: {np.int64(1): 569, np.int64(0): 501}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>futures_open_interest_history__open</th>\n",
       "      <th>futures_open_interest_history__high</th>\n",
       "      <th>futures_open_interest_history__low</th>\n",
       "      <th>futures_open_interest_history__close</th>\n",
       "      <th>date</th>\n",
       "      <th>futures_open_interest_aggregated_history__open</th>\n",
       "      <th>futures_open_interest_aggregated_history__high</th>\n",
       "      <th>futures_open_interest_aggregated_history__low</th>\n",
       "      <th>futures_open_interest_aggregated_history__close</th>\n",
       "      <th>futures_funding_rate_history__open</th>\n",
       "      <th>...</th>\n",
       "      <th>sp500__volume__diff1__lag7</th>\n",
       "      <th>sp500__volume__diff1__lag10</th>\n",
       "      <th>sp500__volume__diff1__lag15</th>\n",
       "      <th>sp500__volume__pct1__lag1</th>\n",
       "      <th>sp500__volume__pct1__lag3</th>\n",
       "      <th>sp500__volume__pct1__lag5</th>\n",
       "      <th>sp500__volume__pct1__lag7</th>\n",
       "      <th>sp500__volume__pct1__lag10</th>\n",
       "      <th>sp500__volume__pct1__lag15</th>\n",
       "      <th>y_up_3d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.071097e+09</td>\n",
       "      <td>2.098987e+09</td>\n",
       "      <td>2.060349e+09</td>\n",
       "      <td>2.074905e+09</td>\n",
       "      <td>2022-11-26</td>\n",
       "      <td>9.841010e+09</td>\n",
       "      <td>9.985549e+09</td>\n",
       "      <td>9.841010e+09</td>\n",
       "      <td>9.904054e+09</td>\n",
       "      <td>0.003810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-849990000.0</td>\n",
       "      <td>-1.879500e+08</td>\n",
       "      <td>-0.479693</td>\n",
       "      <td>-0.156448</td>\n",
       "      <td>-0.046236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.169479</td>\n",
       "      <td>-0.032510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.074905e+09</td>\n",
       "      <td>2.118137e+09</td>\n",
       "      <td>2.062621e+09</td>\n",
       "      <td>2.081465e+09</td>\n",
       "      <td>2022-11-27</td>\n",
       "      <td>9.904054e+09</td>\n",
       "      <td>1.002793e+10</td>\n",
       "      <td>9.868134e+09</td>\n",
       "      <td>9.946130e+09</td>\n",
       "      <td>0.001088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-113540000.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.027258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.081465e+09</td>\n",
       "      <td>2.090258e+09</td>\n",
       "      <td>1.970674e+09</td>\n",
       "      <td>2.025418e+09</td>\n",
       "      <td>2022-11-28</td>\n",
       "      <td>9.946130e+09</td>\n",
       "      <td>1.000509e+10</td>\n",
       "      <td>9.699231e+09</td>\n",
       "      <td>9.894938e+09</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>...</td>\n",
       "      <td>-186670000.0</td>\n",
       "      <td>-14420000.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.479693</td>\n",
       "      <td>-0.156448</td>\n",
       "      <td>-0.046236</td>\n",
       "      <td>-0.003559</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.025418e+09</td>\n",
       "      <td>2.131462e+09</td>\n",
       "      <td>2.001265e+09</td>\n",
       "      <td>2.095082e+09</td>\n",
       "      <td>2022-11-29</td>\n",
       "      <td>9.894938e+09</td>\n",
       "      <td>1.029943e+10</td>\n",
       "      <td>8.754260e+09</td>\n",
       "      <td>9.991988e+09</td>\n",
       "      <td>0.004760</td>\n",
       "      <td>...</td>\n",
       "      <td>37300000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.031380e+09</td>\n",
       "      <td>1.118673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.184395</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.095082e+09</td>\n",
       "      <td>2.189434e+09</td>\n",
       "      <td>2.082092e+09</td>\n",
       "      <td>2.179708e+09</td>\n",
       "      <td>2022-11-30</td>\n",
       "      <td>9.991988e+09</td>\n",
       "      <td>1.035248e+10</td>\n",
       "      <td>8.399971e+09</td>\n",
       "      <td>1.025955e+10</td>\n",
       "      <td>0.003404</td>\n",
       "      <td>...</td>\n",
       "      <td>-608270000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.533800e+08</td>\n",
       "      <td>-0.019193</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.479693</td>\n",
       "      <td>-0.156448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099383</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 650 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   futures_open_interest_history__open  futures_open_interest_history__high  \\\n",
       "0                         2.071097e+09                         2.098987e+09   \n",
       "1                         2.074905e+09                         2.118137e+09   \n",
       "2                         2.081465e+09                         2.090258e+09   \n",
       "3                         2.025418e+09                         2.131462e+09   \n",
       "4                         2.095082e+09                         2.189434e+09   \n",
       "\n",
       "   futures_open_interest_history__low  futures_open_interest_history__close  \\\n",
       "0                        2.060349e+09                          2.074905e+09   \n",
       "1                        2.062621e+09                          2.081465e+09   \n",
       "2                        1.970674e+09                          2.025418e+09   \n",
       "3                        2.001265e+09                          2.095082e+09   \n",
       "4                        2.082092e+09                          2.179708e+09   \n",
       "\n",
       "        date  futures_open_interest_aggregated_history__open  \\\n",
       "0 2022-11-26                                    9.841010e+09   \n",
       "1 2022-11-27                                    9.904054e+09   \n",
       "2 2022-11-28                                    9.946130e+09   \n",
       "3 2022-11-29                                    9.894938e+09   \n",
       "4 2022-11-30                                    9.991988e+09   \n",
       "\n",
       "   futures_open_interest_aggregated_history__high  \\\n",
       "0                                    9.985549e+09   \n",
       "1                                    1.002793e+10   \n",
       "2                                    1.000509e+10   \n",
       "3                                    1.029943e+10   \n",
       "4                                    1.035248e+10   \n",
       "\n",
       "   futures_open_interest_aggregated_history__low  \\\n",
       "0                                   9.841010e+09   \n",
       "1                                   9.868134e+09   \n",
       "2                                   9.699231e+09   \n",
       "3                                   8.754260e+09   \n",
       "4                                   8.399971e+09   \n",
       "\n",
       "   futures_open_interest_aggregated_history__close  \\\n",
       "0                                     9.904054e+09   \n",
       "1                                     9.946130e+09   \n",
       "2                                     9.894938e+09   \n",
       "3                                     9.991988e+09   \n",
       "4                                     1.025955e+10   \n",
       "\n",
       "   futures_funding_rate_history__open  ...  sp500__volume__diff1__lag7  \\\n",
       "0                            0.003810  ...                         0.0   \n",
       "1                            0.001088  ...                         0.0   \n",
       "2                            0.002267  ...                -186670000.0   \n",
       "3                            0.004760  ...                  37300000.0   \n",
       "4                            0.003404  ...                -608270000.0   \n",
       "\n",
       "   sp500__volume__diff1__lag10  sp500__volume__diff1__lag15  \\\n",
       "0                 -849990000.0                -1.879500e+08   \n",
       "1                 -113540000.0                 0.000000e+00   \n",
       "2                  -14420000.0                 0.000000e+00   \n",
       "3                          0.0                -1.031380e+09   \n",
       "4                          0.0                 4.533800e+08   \n",
       "\n",
       "   sp500__volume__pct1__lag1  sp500__volume__pct1__lag3  \\\n",
       "0                  -0.479693                  -0.156448   \n",
       "1                   0.000000                   0.000000   \n",
       "2                   0.000000                  -0.479693   \n",
       "3                   1.118673                   0.000000   \n",
       "4                  -0.019193                   0.000000   \n",
       "\n",
       "   sp500__volume__pct1__lag5  sp500__volume__pct1__lag7  \\\n",
       "0                  -0.046236                   0.000000   \n",
       "1                   0.009687                   0.000000   \n",
       "2                  -0.156448                  -0.046236   \n",
       "3                   0.000000                   0.009687   \n",
       "4                  -0.479693                  -0.156448   \n",
       "\n",
       "   sp500__volume__pct1__lag10  sp500__volume__pct1__lag15  y_up_3d  \n",
       "0                   -0.169479                   -0.032510        0  \n",
       "1                   -0.027258                    0.000000        1  \n",
       "2                   -0.003559                    0.000000        1  \n",
       "3                    0.000000                   -0.184395        1  \n",
       "4                    0.000000                    0.099383        0  \n",
       "\n",
       "[5 rows x 650 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 1. Сбор данных из API\n",
    "# =============================================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"1. Gathering features from API...\")\n",
    "dfs = get_features(getter, api_key)\n",
    "df_all = merge_by_date(dfs, how=\"outer\", dedupe=\"last\")\n",
    "df_all = df_all.sort_values('date').reset_index(drop=True)\n",
    "print(f\"   Raw data shape: {df_all.shape}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Нормализация и первичное заполнение (ffill)\n",
    "# =============================================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"2. Normalizing spot columns & Applying ffill...\")\n",
    "df_all = features_engineer.ensure_spot_prefix(df_all)\n",
    "\n",
    "# Заполняем пропуски вперед (чтобы не было дырок в выходные/праздники перед генерацией фичей)\n",
    "feature_cols = [c for c in df_all.columns if c != \"date\"]\n",
    "df_all[feature_cols] = df_all[feature_cols].ffill()\n",
    "print(f\"   Remaining NaN after ffill: {df_all[feature_cols].isna().sum().sum()}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Генерация фичей (ДО обрезки даты!)\n",
    "# =============================================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"3. Engineering features & Adding lags...\")\n",
    "\n",
    "# --- 3.1 Инженерные фичи ---\n",
    "print(f\"   Shape before feature engineering: {df_all.shape}\")\n",
    "df_all = features_engineer.add_engineered_features(df_all, horizon=N_DAYS)\n",
    "\n",
    "# --- 3.2 TA-фичи ---\n",
    "df_all = add_ta_features_for_asset(df_all, prefix=\"gold\")\n",
    "df_all = add_ta_features_for_asset(df_all, prefix=\"sp500\")\n",
    "df_all = add_ta_features_for_asset(df_all, prefix=\"spot_price_history\",\n",
    "                                    volume_col_override=\"spot_price_history__volume_usd\")\n",
    "\n",
    "# --- 3.3 Лаги для внешних рынков (только OHLCV + diff/pct, НЕ TA-индикаторы) ---\n",
    "# TA-индикаторы уже кодируют историю (RSI=14 дней, BB=20 дней и т.д.),\n",
    "# лагирование их создаёт бесполезное дублирование и взрыв размерности.\n",
    "_OHLCV_BASES = {'open', 'close', 'high', 'low', 'volume'}\n",
    "\n",
    "def _is_ohlcv_based(col, prefix):\n",
    "    \"\"\"True для gold__open, gold__close__diff1, gold__volume__pct1.\n",
    "       False для gold__trend_macd, gold__momentum_rsi и т.д.\"\"\"\n",
    "    suffix = col[len(prefix) + 2:]       # \"open__diff1\" из \"gold__open__diff1\"\n",
    "    base = suffix.split('__')[0]          # \"open\" из \"open__diff1\"\n",
    "    return base in _OHLCV_BASES\n",
    "\n",
    "gold_cols = [c for c in df_all.columns\n",
    "             if c.startswith(\"gold__\") and \"__lag\" not in c and _is_ohlcv_based(c, \"gold\")]\n",
    "sp500_cols = [c for c in df_all.columns\n",
    "              if c.startswith(\"sp500__\") and \"__lag\" not in c and _is_ohlcv_based(c, \"sp500\")]\n",
    "external_market_cols = gold_cols + sp500_cols\n",
    "\n",
    "if external_market_cols:\n",
    "    df_all = add_lags(df_all, cols=external_market_cols, lags=EXTERNAL_LAGS)\n",
    "    print(f\"   Added {len(external_market_cols) * len(EXTERNAL_LAGS)} lag features (OHLCV only, no TA lags)\")\n",
    "    print(f\"   Lagged columns: {len(external_market_cols)} per asset\")\n",
    "\n",
    "# --- 3.4 Целевая колонка ---\n",
    "df_all = features_engineer.add_y_up_custom(df_all, horizon=N_DAYS, close_col=\"spot_price_history__close\")\n",
    "\n",
    "# =============================================================================\n",
    "# 4. Фильтрация по дате (Оставляем последние 1500 дней)\n",
    "# =============================================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"4. Filtering last 1500 days...\")\n",
    "\n",
    "df_all['date'] = pd.to_datetime(df_all['date'])\n",
    "max_date = df_all['date'].max()\n",
    "cutoff_date = max_date - pd.Timedelta(days=1500)\n",
    "\n",
    "rows_total = len(df_all)\n",
    "df_all = df_all[df_all['date'] >= cutoff_date]\n",
    "print(f\"   Rows kept: {len(df_all)} (from {rows_total})\")\n",
    "\n",
    "# =============================================================================\n",
    "# 5. Очистка колонок и строк\n",
    "# =============================================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"5. Final cleanup...\")\n",
    "\n",
    "df_all = df_all.dropna(subset=[TARGET_COLUMN_NAME])\n",
    "\n",
    "nan_threshold = 0.3\n",
    "nan_ratio = df_all.isna().mean()\n",
    "cols_to_drop = [\n",
    "    c for c in nan_ratio[nan_ratio > nan_threshold].index\n",
    "    if not c.startswith(\"y_up_\")\n",
    "]\n",
    "if cols_to_drop:\n",
    "    print(f\"   Dropping {len(cols_to_drop)} columns with >30% NaN\")\n",
    "    df_all = df_all.drop(columns=cols_to_drop)\n",
    "\n",
    "rows_before_final = len(df_all)\n",
    "df_all = df_all.dropna().reset_index(drop=True)\n",
    "print(f\"   Final Dropna: removed {rows_before_final - len(df_all)} rows.\")\n",
    "\n",
    "# =============================================================================\n",
    "# Итоговый результат\n",
    "# =============================================================================\n",
    "print(\"=\" * 60)\n",
    "print(f\"FINAL DATASET SHAPE: {df_all.shape}\")\n",
    "print(f\"Date range: {df_all['date'].min()} to {df_all['date'].max()}\")\n",
    "print(f\"Target distribution: {df_all[TARGET_COLUMN_NAME].value_counts().to_dict()}\")\n",
    "\n",
    "df2 = df_all\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bef6f240-e0df-45c2-bd5e-9df40a3cc8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold фичей: 184\n",
      "S&P500 фичей: 184\n",
      "\n",
      "Примеры gold фичей: ['gold__open', 'gold__close', 'gold__high', 'gold__low', 'gold__volume', 'gold__open__diff1', 'gold__open__pct1', 'gold__close__diff1', 'gold__close__pct1', 'gold__high__diff1', 'gold__high__pct1', 'gold__low__diff1', 'gold__low__pct1', 'gold__volume__diff1', 'gold__volume__pct1', 'gold__volume_adi', 'gold__volume_obv', 'gold__volume_cmf', 'gold__volume_fi', 'gold__volume_em', 'gold__volume_sma_em', 'gold__volume_vpt', 'gold__volume_vwap', 'gold__volume_mfi', 'gold__volume_nvi', 'gold__volatility_bbm', 'gold__volatility_bbh', 'gold__volatility_bbl', 'gold__volatility_bbw', 'gold__volatility_bbp', 'gold__volatility_bbhi', 'gold__volatility_bbli', 'gold__volatility_kcc', 'gold__volatility_kch', 'gold__volatility_kcl', 'gold__volatility_kcw', 'gold__volatility_kcp', 'gold__volatility_kchi', 'gold__volatility_kcli', 'gold__volatility_dcl', 'gold__volatility_dch', 'gold__volatility_dcm', 'gold__volatility_dcw', 'gold__volatility_dcp', 'gold__volatility_ui', 'gold__trend_macd', 'gold__trend_macd_signal', 'gold__trend_macd_diff', 'gold__trend_sma_fast', 'gold__trend_sma_slow', 'gold__trend_ema_fast', 'gold__trend_ema_slow', 'gold__trend_vortex_ind_pos', 'gold__trend_vortex_ind_neg', 'gold__trend_vortex_ind_diff', 'gold__trend_trix', 'gold__trend_mass_index', 'gold__trend_dpo', 'gold__trend_kst', 'gold__trend_kst_sig', 'gold__trend_kst_diff', 'gold__trend_ichimoku_conv', 'gold__trend_ichimoku_base', 'gold__trend_ichimoku_a', 'gold__trend_ichimoku_b', 'gold__trend_stc', 'gold__trend_cci', 'gold__trend_visual_ichimoku_a', 'gold__trend_visual_ichimoku_b', 'gold__trend_aroon_up', 'gold__trend_aroon_down', 'gold__trend_aroon_ind', 'gold__trend_psar_up_indicator', 'gold__trend_psar_down_indicator', 'gold__momentum_rsi', 'gold__momentum_stoch_rsi', 'gold__momentum_stoch_rsi_k', 'gold__momentum_stoch_rsi_d', 'gold__momentum_tsi', 'gold__momentum_uo', 'gold__momentum_stoch', 'gold__momentum_stoch_signal', 'gold__momentum_wr', 'gold__momentum_ao', 'gold__momentum_roc', 'gold__momentum_ppo', 'gold__momentum_ppo_signal', 'gold__momentum_ppo_hist', 'gold__momentum_pvo', 'gold__momentum_pvo_signal', 'gold__momentum_pvo_hist', 'gold__momentum_kama', 'gold__others_dr', 'gold__others_dlr', 'gold__open__lag1', 'gold__open__lag3', 'gold__open__lag5', 'gold__open__lag7', 'gold__open__lag10', 'gold__open__lag15']\n",
      "\n",
      "Примеры sp500 фичей: ['sp500__open', 'sp500__close', 'sp500__high', 'sp500__low', 'sp500__volume', 'sp500__open__diff1', 'sp500__open__pct1', 'sp500__close__diff1', 'sp500__close__pct1', 'sp500__high__diff1', 'sp500__high__pct1', 'sp500__low__diff1', 'sp500__low__pct1', 'sp500__volume__diff1', 'sp500__volume__pct1', 'sp500__volume_adi', 'sp500__volume_obv', 'sp500__volume_cmf', 'sp500__volume_fi', 'sp500__volume_em', 'sp500__volume_sma_em', 'sp500__volume_vpt', 'sp500__volume_vwap', 'sp500__volume_mfi', 'sp500__volume_nvi']\n"
     ]
    }
   ],
   "source": [
    "# Проверка внешних рыночных фичей\n",
    "gold_cols = [c for c in df2.columns if c.startswith(\"gold__\")]\n",
    "sp500_cols = [c for c in df2.columns if c.startswith(\"sp500__\")]\n",
    "\n",
    "print(f\"Gold фичей: {len(gold_cols)}\")\n",
    "print(f\"S&P500 фичей: {len(sp500_cols)}\")\n",
    "\n",
    "if gold_cols:\n",
    "    print(f\"\\nПримеры gold фичей: {gold_cols[:100]}\")\n",
    "if sp500_cols:\n",
    "    print(f\"\\nПримеры sp500 фичей: {sp500_cols[:25]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91ec854f-4617-437b-92dd-33b9e83c6ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels in c:\\users\\flays\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.14.6)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in c:\\users\\flays\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from statsmodels) (2.2.6)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in c:\\users\\flays\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from statsmodels) (1.16.2)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in c:\\users\\flays\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from statsmodels) (2.3.2)\n",
      "Requirement already satisfied: patsy>=0.5.6 in c:\\users\\flays\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from statsmodels) (1.0.2)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\flays\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from statsmodels) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\flays\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\flays\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2022.7.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\flays\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\flays\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: C:\\Users\\flays\\AppData\\Local\\Programs\\Python\\Python312\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af6e1a1e-74c2-4454-bc88-cca3ed27a6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined: smart_corr_removal(), select_features_spearman_fdr()\n",
      "Config: N_SPLITS=5, MAX_FEATURES=20, CORR_THRESHOLD=0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, precision_score, recall_score\n",
    "from scipy.stats import spearmanr\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# =============================================================================\n",
    "# Конфигурация walk-forward CV\n",
    "# =============================================================================\n",
    "N_SPLITS = 5\n",
    "MAX_FEATURES = 20          # макс. фичей на fold\n",
    "CORR_THRESHOLD = 0.75      # порог удаления коррелированных фичей\n",
    "\n",
    "# =============================================================================\n",
    "# Вспомогательные функции\n",
    "# =============================================================================\n",
    "\n",
    "def smart_corr_removal(X: pd.DataFrame, y: pd.Series, threshold: float = 0.75) -> list:\n",
    "    \"\"\"Удаляет коррелированные фичи, сохраняя ту, у которой выше |Spearman| с таргетом.\n",
    "    \n",
    "    Возвращает список колонок, которые нужно ОСТАВИТЬ.\n",
    "    \"\"\"\n",
    "    corr_matrix = X.corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "    # abs(Spearman) с таргетом для каждой фичи\n",
    "    target_corr = {}\n",
    "    for col in X.columns:\n",
    "        c, _ = spearmanr(X[col], y)\n",
    "        target_corr[col] = abs(c)\n",
    "\n",
    "    to_drop = set()\n",
    "    for col in upper.columns:\n",
    "        if col in to_drop:\n",
    "            continue\n",
    "        correlated_with = upper.index[upper[col] > threshold].tolist()\n",
    "        for corr_col in correlated_with:\n",
    "            if corr_col in to_drop:\n",
    "                continue\n",
    "            # Убираем фичу с МЕНЬШЕЙ корреляцией с таргетом\n",
    "            if target_corr.get(col, 0) >= target_corr.get(corr_col, 0):\n",
    "                to_drop.add(corr_col)\n",
    "            else:\n",
    "                to_drop.add(col)\n",
    "                break  # col уже помечен на удаление, переходим к следующей\n",
    "\n",
    "    keep = [c for c in X.columns if c not in to_drop]\n",
    "    return keep\n",
    "\n",
    "\n",
    "def select_features_spearman_fdr(X: pd.DataFrame, y: pd.Series, max_features: int = 20):\n",
    "    \"\"\"Отбирает top-K фичей по |Spearman| с FDR-коррекцией (Benjamini-Hochberg).\n",
    "    \n",
    "    Returns:\n",
    "        selected: список отобранных фичей\n",
    "        stats: DataFrame со статистикой по всем фичам\n",
    "    \"\"\"\n",
    "    correlations = []\n",
    "    p_values = []\n",
    "\n",
    "    for col in X.columns:\n",
    "        corr, p_val = spearmanr(X[col], y)\n",
    "        correlations.append(abs(corr))\n",
    "        p_values.append(p_val)\n",
    "\n",
    "    # FDR коррекция\n",
    "    reject, p_corrected, _, _ = multipletests(p_values, alpha=0.05, method='fdr_bh')\n",
    "\n",
    "    stats = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'abs_corr': correlations,\n",
    "        'p_raw': p_values,\n",
    "        'p_fdr': p_corrected,\n",
    "        'significant_fdr': reject\n",
    "    }).sort_values('abs_corr', ascending=False)\n",
    "\n",
    "    # Берём значимые после FDR, ограничиваем max_features\n",
    "    significant = stats[stats['significant_fdr']]\n",
    "\n",
    "    if len(significant) >= 3:\n",
    "        selected = significant.head(max_features)['feature'].tolist()\n",
    "        method = f\"FDR (q<0.05): {len(significant)} significant, took top-{len(selected)}\"\n",
    "    else:\n",
    "        # Fallback: top по raw p < 0.01 (жёстче, т.к. без коррекции)\n",
    "        fallback = stats[stats['p_raw'] < 0.01].head(max_features)\n",
    "        selected = fallback['feature'].tolist()\n",
    "        method = f\"Fallback (raw p<0.01): {len(selected)} features\"\n",
    "\n",
    "    return selected, method, stats\n",
    "\n",
    "\n",
    "print(\"Helper functions defined: smart_corr_removal(), select_features_spearman_fdr()\")\n",
    "print(f\"Config: N_SPLITS={N_SPLITS}, MAX_FEATURES={MAX_FEATURES}, CORR_THRESHOLD={CORR_THRESHOLD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d8c1cac-c08b-4053-8a12-6241a227ba16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walk-Forward CV: 5 splits, gap=3\n",
      "Total samples: 1070, Features: 648\n",
      "======================================================================\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "FOLD 1/5\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "  Train: 177 rows (2022-11-26 → 2023-06-25)\n",
      "  Test:  178 rows (2023-06-29 → 2023-12-23)\n",
      "  [1] Corr removal: 648 → 236 features\n",
      "  [2] Feature selection: FDR (q<0.05): 8 significant, took top-8\n",
      "  [3] Train acc: 0.7062 | Test acc: 0.4438 | Gap: +0.2624\n",
      "      AUC: 0.5639 | F1: 0.2080 | Prec: 0.5909 | Rec: 0.1262\n",
      "      Features (8): ['index_btc_reserve_risk__hodl_bank__pct1', 'futures_open_interest_aggregated_history__close', 'gold__volatility_ui', 'gold__volume_vpt', 'sp500__volatility_dch']...\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "FOLD 2/5\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "  Train: 355 rows (2022-11-26 → 2023-12-20)\n",
      "  Test:  178 rows (2023-12-24 → 2024-06-18)\n",
      "  [1] Corr removal: 648 → 243 features\n",
      "  [2] Feature selection: Fallback (raw p<0.01): 9 features\n",
      "  [3] Train acc: 0.7127 | Test acc: 0.6348 | Gap: +0.0778\n",
      "      AUC: 0.6231 | F1: 0.7137 | Prec: 0.6090 | Rec: 0.8617\n",
      "      Features (9): ['gold__volume_sma_em', 'gold__momentum_rsi', 'gold__trend_stc', 'gold__volatility_ui', 'sp500__volume__diff1__lag3']...\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "FOLD 3/5\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "  Train: 533 rows (2022-11-26 → 2024-06-15)\n",
      "  Test:  178 rows (2024-06-19 → 2024-12-13)\n",
      "  [1] Corr removal: 648 → 237 features\n",
      "  [2] Feature selection: FDR (q<0.05): 4 significant, took top-4\n",
      "  [3] Train acc: 0.6867 | Test acc: 0.5337 | Gap: +0.1530\n",
      "      AUC: 0.5224 | F1: 0.6175 | Prec: 0.5929 | Rec: 0.6442\n",
      "      Features (4): ['gold__volume_sma_em', 'gold__volatility_dcp', 'gold__volatility_ui', 'gold__trend_kst_diff']\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "FOLD 4/5\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "  Train: 711 rows (2022-11-26 → 2024-12-10)\n",
      "  Test:  178 rows (2024-12-14 → 2025-06-09)\n",
      "  [1] Corr removal: 648 → 241 features\n",
      "  [2] Feature selection: FDR (q<0.05): 4 significant, took top-4\n",
      "  [3] Train acc: 0.6596 | Test acc: 0.4326 | Gap: +0.2271\n",
      "      AUC: 0.4244 | F1: 0.5430 | Prec: 0.4839 | Rec: 0.6186\n",
      "      Features (4): ['gold__volume_sma_em', 'gold__volatility_ui', 'index_btc_active_addresses__aa_z180', 'gold__volatility_dcp']\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "FOLD 5/5\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "  Train: 889 rows (2022-11-26 → 2025-06-06)\n",
      "  Test:  178 rows (2025-06-10 → 2026-02-12)\n",
      "  [1] Corr removal: 648 → 239 features\n",
      "  [2] Feature selection: Fallback (raw p<0.01): 12 features\n",
      "  [3] Train acc: 0.6738 | Test acc: 0.4326 | Gap: +0.2412\n",
      "      AUC: 0.4458 | F1: 0.5073 | Prec: 0.4000 | Rec: 0.6933\n",
      "      Features (12): ['gold__volume_sma_em', 'sp500__volatility_bbw', 'gold__volatility_dcp', 'gold__low__diff1__lag15', 'spot_price_history__volatility_kcli']...\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Walk-Forward CV с NESTED feature selection (внутри каждого fold)\n",
    "# =============================================================================\n",
    "# Ключевое отличие от предыдущей версии:\n",
    "# - Корреляционное удаление и Spearman-отбор делаются ВНУТРИ каждого fold\n",
    "# - Это устраняет selection leakage — главную причину переобучения\n",
    "# =============================================================================\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=N_SPLITS, gap=N_DAYS)\n",
    "\n",
    "X_all = df2.drop([TARGET_COLUMN_NAME, 'date'], axis=1)\n",
    "y_all = df2[TARGET_COLUMN_NAME]\n",
    "\n",
    "fold_results = []\n",
    "all_feature_sets = []\n",
    "\n",
    "print(f\"Walk-Forward CV: {N_SPLITS} splits, gap={N_DAYS}\")\n",
    "print(f\"Total samples: {len(X_all)}, Features: {X_all.shape[1]}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(tscv.split(X_all)):\n",
    "    print(f\"\\n{'─'*70}\")\n",
    "    print(f\"FOLD {fold_idx + 1}/{N_SPLITS}\")\n",
    "    print(f\"{'─'*70}\")\n",
    "\n",
    "    X_fold_train = X_all.iloc[train_idx].copy()\n",
    "    X_fold_test = X_all.iloc[test_idx].copy()\n",
    "    y_fold_train = y_all.iloc[train_idx]\n",
    "    y_fold_test = y_all.iloc[test_idx]\n",
    "\n",
    "    dates_train = df2['date'].iloc[train_idx]\n",
    "    dates_test = df2['date'].iloc[test_idx]\n",
    "    print(f\"  Train: {len(train_idx)} rows ({dates_train.min().date()} → {dates_train.max().date()})\")\n",
    "    print(f\"  Test:  {len(test_idx)} rows ({dates_test.min().date()} → {dates_test.max().date()})\")\n",
    "\n",
    "    # --- Шаг 1: Smart correlation removal (на train fold) ---\n",
    "    keep_cols = smart_corr_removal(X_fold_train, y_fold_train, threshold=CORR_THRESHOLD)\n",
    "    X_fold_train = X_fold_train[keep_cols]\n",
    "    X_fold_test = X_fold_test[keep_cols]\n",
    "    print(f\"  [1] Corr removal: {X_all.shape[1]} → {len(keep_cols)} features\")\n",
    "\n",
    "    # --- Шаг 2: Feature selection с FDR (на train fold) ---\n",
    "    selected_features, method, feat_stats = select_features_spearman_fdr(\n",
    "        X_fold_train, y_fold_train, max_features=MAX_FEATURES\n",
    "    )\n",
    "    print(f\"  [2] Feature selection: {method}\")\n",
    "    all_feature_sets.append(set(selected_features))\n",
    "\n",
    "    if len(selected_features) == 0:\n",
    "        print(\"  SKIP: нет отобранных фичей!\")\n",
    "        continue\n",
    "\n",
    "    # --- Шаг 3: Формируем финальные данные fold ---\n",
    "    X_tr = X_fold_train[selected_features]\n",
    "    X_te = X_fold_test[selected_features]\n",
    "\n",
    "    # --- Шаг 4: Масштабируем ---\n",
    "    scaler = StandardScaler()\n",
    "    X_tr_scaled = scaler.fit_transform(X_tr)\n",
    "    X_te_scaled = scaler.transform(X_te)\n",
    "\n",
    "    # --- Шаг 5: Обучаем RF ---\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=3,\n",
    "        min_samples_leaf=20,\n",
    "        min_samples_split=40,\n",
    "        max_features='sqrt',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    model.fit(X_tr_scaled, y_fold_train)\n",
    "\n",
    "    train_acc = model.score(X_tr_scaled, y_fold_train)\n",
    "    test_acc = model.score(X_te_scaled, y_fold_test)\n",
    "\n",
    "    y_pred = model.predict(X_te_scaled)\n",
    "    y_proba = model.predict_proba(X_te_scaled)[:, 1]\n",
    "\n",
    "    auc = roc_auc_score(y_fold_test, y_proba)\n",
    "    f1 = f1_score(y_fold_test, y_pred)\n",
    "    prec = precision_score(y_fold_test, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_fold_test, y_pred, zero_division=0)\n",
    "    gap = train_acc - test_acc\n",
    "\n",
    "    print(f\"  [3] Train acc: {train_acc:.4f} | Test acc: {test_acc:.4f} | Gap: {gap:+.4f}\")\n",
    "    print(f\"      AUC: {auc:.4f} | F1: {f1:.4f} | Prec: {prec:.4f} | Rec: {rec:.4f}\")\n",
    "    print(f\"      Features ({len(selected_features)}): {selected_features[:5]}{'...' if len(selected_features) > 5 else ''}\")\n",
    "\n",
    "    fold_results.append({\n",
    "        'fold': fold_idx + 1,\n",
    "        'train_size': len(train_idx),\n",
    "        'test_size': len(test_idx),\n",
    "        'n_features': len(selected_features),\n",
    "        'train_acc': train_acc,\n",
    "        'test_acc': test_acc,\n",
    "        'gap': gap,\n",
    "        'auc': auc,\n",
    "        'f1': f1,\n",
    "        'precision': prec,\n",
    "        'recall': rec,\n",
    "        'features': selected_features,\n",
    "        'model': model,\n",
    "        'scaler': scaler,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "v2zgtmov8bq",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "СВОДКА ПО FOLD'АМ\n",
      "======================================================================\n",
      " fold  train_size  test_size  n_features  train_acc  test_acc      gap      auc       f1  precision   recall\n",
      "    1         177        178           8   0.706215  0.443820 0.262394 0.563883 0.208000   0.590909 0.126214\n",
      "    2         355        178           9   0.712676  0.634831 0.077845 0.623100 0.713656   0.609023 0.861702\n",
      "    3         533        178           4   0.686679  0.533708 0.152971 0.522414 0.617512   0.592920 0.644231\n",
      "    4         711        178           4   0.659634  0.432584 0.227050 0.424399 0.542986   0.483871 0.618557\n",
      "    5         889        178          12   0.673791  0.432584 0.241207 0.445825 0.507317   0.400000 0.693333\n",
      "\n",
      "────────────────────────────────────────\n",
      "Средний test acc:  0.4955 +/- 0.0887\n",
      "Средний AUC:       0.5159 +/- 0.0823\n",
      "Средний F1:        0.5179 +/- 0.1904\n",
      "Средний gap:       +0.1923\n",
      "────────────────────────────────────────\n",
      "\n",
      "======================================================================\n",
      "СТАБИЛЬНОСТЬ ФИЧЕЙ\n",
      "======================================================================\n",
      "Фичей, общих для ВСЕХ fold'ов: 1\n",
      "Всего уникальных фичей: 23\n",
      "\n",
      "Фичи по частоте появления в fold'ах:\n",
      "  [5/5] gold__volume_sma_em ***\n",
      "  [4/5] gold__volatility_ui\n",
      "  [3/5] gold__volatility_dcp\n",
      "  [2/5] index_btc_reserve_risk__hodl_bank__pct1\n",
      "  [2/5] gold__trend_aroon_up\n",
      "  [2/5] gold__trend_stc\n",
      "  [2/5] gold__trend_kst_diff\n",
      "  [2/5] index_btc_active_addresses__aa_z180\n",
      "  [1/5] sp500__volatility_dch\n",
      "  [1/5] sp500__volume__pct1__lag3\n",
      "  [1/5] spot_price_history__volatility_bbl\n",
      "  [1/5] futures_open_interest_aggregated_history__close\n",
      "  [1/5] gold__volume_vpt\n",
      "  [1/5] gold__volume__lag5\n",
      "  [1/5] spot_price_history__volume_nvi\n",
      "  [1/5] sp500__volume__diff1__lag3\n",
      "  [1/5] gold__momentum_rsi\n",
      "  [1/5] sp500__close__diff1__lag7\n",
      "  [1/5] gold__low__diff1__lag15\n",
      "  [1/5] index_btc_lth_supply__lth_supply\n",
      "  [1/5] sp500__trend_kst_diff\n",
      "  [1/5] spot_price_history__volatility_kcli\n",
      "  [1/5] sp500__volatility_bbw\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Сводка результатов Walk-Forward CV\n",
    "# =============================================================================\n",
    "print(\"=\" * 70)\n",
    "print(\"СВОДКА ПО FOLD'АМ\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "results_df = pd.DataFrame(fold_results)\n",
    "display_cols = ['fold', 'train_size', 'test_size', 'n_features', 'train_acc', 'test_acc', 'gap', 'auc', 'f1', 'precision', 'recall']\n",
    "print(results_df[display_cols].to_string(index=False))\n",
    "\n",
    "print(f\"\\n{'─'*40}\")\n",
    "print(f\"Средний test acc:  {results_df['test_acc'].mean():.4f} +/- {results_df['test_acc'].std():.4f}\")\n",
    "print(f\"Средний AUC:       {results_df['auc'].mean():.4f} +/- {results_df['auc'].std():.4f}\")\n",
    "print(f\"Средний F1:        {results_df['f1'].mean():.4f} +/- {results_df['f1'].std():.4f}\")\n",
    "print(f\"Средний gap:       {results_df['gap'].mean():+.4f}\")\n",
    "print(f\"{'─'*40}\")\n",
    "\n",
    "# Стабильность фичей: какие повторяются в разных fold'ах\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"СТАБИЛЬНОСТЬ ФИЧЕЙ\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "if len(all_feature_sets) > 1:\n",
    "    from collections import Counter\n",
    "    feat_counter = Counter()\n",
    "    for fs in all_feature_sets:\n",
    "        feat_counter.update(fs)\n",
    "\n",
    "    common_features = set.intersection(*all_feature_sets)\n",
    "    all_unique = set.union(*all_feature_sets)\n",
    "\n",
    "    print(f\"Фичей, общих для ВСЕХ fold'ов: {len(common_features)}\")\n",
    "    print(f\"Всего уникальных фичей: {len(all_unique)}\")\n",
    "\n",
    "    print(f\"\\nФичи по частоте появления в fold'ах:\")\n",
    "    for feat, count in feat_counter.most_common():\n",
    "        marker = \" ***\" if count == N_SPLITS else \"\"\n",
    "        print(f\"  [{count}/{N_SPLITS}] {feat}{marker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9aea2ec-72e2-414a-9df4-6f83661fd5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Финальная модель: Fold 5\n",
      "Features (12):\n",
      "  - gold__volume_sma_em\n",
      "  - sp500__volatility_bbw\n",
      "  - gold__volatility_dcp\n",
      "  - gold__low__diff1__lag15\n",
      "  - spot_price_history__volatility_kcli\n",
      "  - gold__trend_aroon_up\n",
      "  - sp500__trend_kst_diff\n",
      "  - gold__trend_kst_diff\n",
      "  - index_btc_lth_supply__lth_supply\n",
      "  - index_btc_active_addresses__aa_z180\n",
      "  - gold__trend_stc\n",
      "  - sp500__close__diff1__lag7\n",
      "\n",
      "Permutation Importance (n_repeats=30) на holdout (178 samples)...\n",
      "\n",
      "Permutation Importance (все 12 фичей):\n",
      "                            feature  importance      std       snr\n",
      "index_btc_active_addresses__aa_z180    0.003371 0.013183  0.255686\n",
      "               gold__trend_kst_diff    0.002996 0.012456  0.240554\n",
      "spot_price_history__volatility_kcli    0.002996 0.008425  0.355643\n",
      "              sp500__volatility_bbw    0.000936 0.018973  0.049350\n",
      "                    gold__trend_stc   -0.001498 0.011956 -0.125306\n",
      "               gold__trend_aroon_up   -0.002809 0.006446 -0.435745\n",
      "                gold__volume_sma_em   -0.002996 0.016135 -0.185695\n",
      "          sp500__close__diff1__lag7   -0.004869 0.010022 -0.485833\n",
      "            gold__low__diff1__lag15   -0.008614 0.016649 -0.517409\n",
      "               gold__volatility_dcp   -0.010112 0.015784 -0.640682\n",
      "   index_btc_lth_supply__lth_supply   -0.013109 0.018876 -0.694466\n",
      "              sp500__trend_kst_diff   -0.020974 0.009505 -2.206709\n",
      "\n",
      "Фич с importance > 0: 4\n",
      "Фич со значимым importance (> 2*std): 0\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Финальная оценка: holdout test (последний fold) + Permutation Importance\n",
    "# =============================================================================\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Берём последний fold (самый свежий OOS-период)\n",
    "best = fold_results[-1]\n",
    "best_model = best['model']\n",
    "best_scaler = best['scaler']\n",
    "best_features = best['features']\n",
    "\n",
    "print(f\"Финальная модель: Fold {best['fold']}\")\n",
    "print(f\"Features ({len(best_features)}):\")\n",
    "for f in best_features:\n",
    "    print(f\"  - {f}\")\n",
    "\n",
    "# Holdout-данные последнего fold\n",
    "last_train_idx, last_test_idx = list(tscv.split(X_all))[-1]\n",
    "X_holdout = X_all.iloc[last_test_idx][best_features]\n",
    "y_holdout = y_all.iloc[last_test_idx]\n",
    "X_holdout_scaled = best_scaler.transform(X_holdout)\n",
    "\n",
    "# Permutation Importance на holdout\n",
    "print(f\"\\nPermutation Importance (n_repeats=30) на holdout ({len(y_holdout)} samples)...\")\n",
    "r = permutation_importance(\n",
    "    best_model,\n",
    "    X_holdout_scaled,\n",
    "    y_holdout,\n",
    "    n_repeats=30,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "perm_df = pd.DataFrame({\n",
    "    'feature': best_features,\n",
    "    'importance': r.importances_mean,\n",
    "    'std': r.importances_std,\n",
    "    'snr': r.importances_mean / (r.importances_std + 1e-10)\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nPermutation Importance (все {len(perm_df)} фичей):\")\n",
    "print(perm_df.to_string(index=False))\n",
    "\n",
    "significant_perm = perm_df[perm_df['importance'] > 2 * perm_df['std']]\n",
    "positive_perm = perm_df[perm_df['importance'] > 0]\n",
    "\n",
    "print(f\"\\nФич с importance > 0: {len(positive_perm)}\")\n",
    "print(f\"Фич со значимым importance (> 2*std): {len(significant_perm)}\")\n",
    "\n",
    "if len(significant_perm) > 0:\n",
    "    print(\"\\nСтатистически значимые фичи:\")\n",
    "    for _, row in significant_perm.iterrows():\n",
    "        print(f\"  {row['feature']}: {row['importance']:.4f} (snr={row['snr']:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a03bcb0-3e02-4c7f-8b47-98a878db0839",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027dbb57-030c-41fe-8b89-0d12cae07be3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
