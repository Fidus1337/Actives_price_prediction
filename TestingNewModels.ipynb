{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3e31034-f4fb-481e-b6f0-4dc10bce5dc6",
   "metadata": {},
   "source": [
    "# Собираем датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67986054-41c4-4890-bbf4-a47dd27d6769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ta\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def add_ta_features_for_asset(df: pd.DataFrame, prefix: str, volume_col_override: str = None) -> pd.DataFrame:\n",
    "    \"\"\"Добавляет TA-индикаторы для актива с заданным префиксом.\n",
    "    \n",
    "    Parameters:\n",
    "        prefix: префикс колонок актива (e.g. \"gold\", \"sp500\", \"spot_price_history\")\n",
    "        volume_col_override: полное имя volume-колонки, если оно не {prefix}__volume\n",
    "                             (e.g. \"spot_price_history__volume_usd\" для BTC)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    required = ['open', 'close', 'high', 'low', 'volume']\n",
    "    col_map = {col: f\"{prefix}__{col}\" for col in required}\n",
    "\n",
    "    # Позволяем переопределить имя volume-колонки\n",
    "    if volume_col_override:\n",
    "        col_map['volume'] = volume_col_override\n",
    "\n",
    "    missing = [col_map[c] for c in required if col_map[c] not in df.columns]\n",
    "    if missing:\n",
    "        print(f\"  Пропущены колонки для {prefix}: {missing}\")\n",
    "        return df\n",
    "\n",
    "    temp_df = pd.DataFrame({\n",
    "        'open': df[col_map['open']].values,\n",
    "        'high': df[col_map['high']].values,\n",
    "        'low': df[col_map['low']].values,\n",
    "        'close': df[col_map['close']].values,\n",
    "        'volume': df[col_map['volume']].values\n",
    "    })\n",
    "\n",
    "    temp_with_ta = ta.add_all_ta_features(\n",
    "        temp_df,\n",
    "        open=\"open\", high=\"high\", low=\"low\", close=\"close\", volume=\"volume\",\n",
    "        fillna=False\n",
    "    )\n",
    "\n",
    "    original_cols = {'open', 'high', 'low', 'close', 'volume'}\n",
    "    ta_cols = [c for c in temp_with_ta.columns if c not in original_cols]\n",
    "\n",
    "    for col in ta_cols:\n",
    "        df.loc[df.index, f\"{prefix}__{col}\"] = temp_with_ta[col].values\n",
    "\n",
    "    print(f\"  Добавлено {len(ta_cols)} TA-фичей для {prefix}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def add_lags(df: pd.DataFrame, cols: list, lags: tuple) -> pd.DataFrame:\n",
    "    \"\"\"Добавляет лаговые признаки для указанных колонок.\"\"\"\n",
    "    df = df.copy()\n",
    "    for col in cols:\n",
    "        for lag in lags:\n",
    "            df[f\"{col}__lag{lag}\"] = df[col].shift(lag)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48bdddf3-781e-4d4a-9562-100aa492946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "from LoggingSystem.LoggingSystem import LoggingSystem\n",
    "from FeaturesGetterModule.FeaturesGetter import FeaturesGetter\n",
    "from get_features_from_API import get_features\n",
    "from FeaturesGetterModule.helpers._merge_features_by_date import merge_by_date\n",
    "from FeaturesEngineer.FeaturesEngineer import FeaturesEngineer\n",
    "\n",
    "# =============================================================================\n",
    "# Конфигурация\n",
    "# =============================================================================\n",
    "load_dotenv(\"dev.env\")\n",
    "api_key = os.getenv(\"COINGLASS_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"COINGLASS_API_KEY not found in dev.env\")\n",
    "\n",
    "N_DAYS = 3\n",
    "TARGET_COLUMN_NAME = f\"y_up_{N_DAYS}d\"\n",
    "EXTERNAL_LAGS = (1, 3, 5, 7, 10, 15)\n",
    "\n",
    "# Инициализация\n",
    "getter = FeaturesGetter(api_key=api_key)\n",
    "features_engineer = FeaturesEngineer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "411911f4-9e9c-4791-95f6-fd5a940808a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "1. Gathering features from API...\n",
      "   Raw data shape: (5659, 112)\n",
      "============================================================\n",
      "2. Normalizing spot columns & Applying ffill...\n",
      "   Remaining NaN after ffill: 400195\n",
      "============================================================\n",
      "3. Engineering features & Adding lags...\n",
      "   Shape before feature engineering: (5659, 112)\n",
      "  Добавлено 86 TA-фичей для gold\n",
      "  Добавлено 86 TA-фичей для sp500\n",
      "  Добавлено 86 TA-фичей для spot_price_history\n",
      "   Added 1212 lag features\n",
      "============================================================\n",
      "4. Filtering last 1500 days...\n",
      "   Rows kept: 1501 (from 5659)\n",
      "============================================================\n",
      "5. Final cleanup...\n",
      "   Dropping 211 columns with >30% NaN\n",
      "   Final Dropna: removed 495 rows.\n",
      "============================================================\n",
      "FINAL DATASET SHAPE: (1006, 1598)\n",
      "Date range: 2022-11-26 00:00:00 to 2026-02-12 00:00:00\n",
      "Target distribution: {np.int64(1): 535, np.int64(0): 471}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>futures_open_interest_history__open</th>\n",
       "      <th>futures_open_interest_history__high</th>\n",
       "      <th>futures_open_interest_history__low</th>\n",
       "      <th>futures_open_interest_history__close</th>\n",
       "      <th>date</th>\n",
       "      <th>futures_open_interest_aggregated_history__open</th>\n",
       "      <th>futures_open_interest_aggregated_history__high</th>\n",
       "      <th>futures_open_interest_aggregated_history__low</th>\n",
       "      <th>futures_open_interest_aggregated_history__close</th>\n",
       "      <th>futures_funding_rate_history__open</th>\n",
       "      <th>...</th>\n",
       "      <th>sp500__others_dr__lag7</th>\n",
       "      <th>sp500__others_dr__lag10</th>\n",
       "      <th>sp500__others_dr__lag15</th>\n",
       "      <th>sp500__others_dlr__lag1</th>\n",
       "      <th>sp500__others_dlr__lag3</th>\n",
       "      <th>sp500__others_dlr__lag5</th>\n",
       "      <th>sp500__others_dlr__lag7</th>\n",
       "      <th>sp500__others_dlr__lag10</th>\n",
       "      <th>sp500__others_dlr__lag15</th>\n",
       "      <th>y_up_3d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.071097e+09</td>\n",
       "      <td>2.098987e+09</td>\n",
       "      <td>2.060349e+09</td>\n",
       "      <td>2.074905e+09</td>\n",
       "      <td>2022-11-26</td>\n",
       "      <td>9.841010e+09</td>\n",
       "      <td>9.985549e+09</td>\n",
       "      <td>9.841010e+09</td>\n",
       "      <td>9.904054e+09</td>\n",
       "      <td>0.003810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.825205</td>\n",
       "      <td>0.924075</td>\n",
       "      <td>-0.028308</td>\n",
       "      <td>0.589727</td>\n",
       "      <td>-0.389125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.828628</td>\n",
       "      <td>0.919831</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.074905e+09</td>\n",
       "      <td>2.118137e+09</td>\n",
       "      <td>2.062621e+09</td>\n",
       "      <td>2.081465e+09</td>\n",
       "      <td>2022-11-27</td>\n",
       "      <td>9.904054e+09</td>\n",
       "      <td>1.002793e+10</td>\n",
       "      <td>9.868134e+09</td>\n",
       "      <td>9.946130e+09</td>\n",
       "      <td>0.001088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.308932</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.348861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.309410</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.081465e+09</td>\n",
       "      <td>2.090258e+09</td>\n",
       "      <td>1.970674e+09</td>\n",
       "      <td>2.025418e+09</td>\n",
       "      <td>2022-11-28</td>\n",
       "      <td>9.946130e+09</td>\n",
       "      <td>1.000509e+10</td>\n",
       "      <td>9.699231e+09</td>\n",
       "      <td>9.894938e+09</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.388369</td>\n",
       "      <td>0.475858</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.028308</td>\n",
       "      <td>0.589727</td>\n",
       "      <td>-0.389125</td>\n",
       "      <td>0.474730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.025418e+09</td>\n",
       "      <td>2.131462e+09</td>\n",
       "      <td>2.001265e+09</td>\n",
       "      <td>2.095082e+09</td>\n",
       "      <td>2022-11-29</td>\n",
       "      <td>9.894938e+09</td>\n",
       "      <td>1.029943e+10</td>\n",
       "      <td>8.754260e+09</td>\n",
       "      <td>9.991988e+09</td>\n",
       "      <td>0.004760</td>\n",
       "      <td>...</td>\n",
       "      <td>1.357999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.893578</td>\n",
       "      <td>-1.556470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.348861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.897594</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.095082e+09</td>\n",
       "      <td>2.189434e+09</td>\n",
       "      <td>2.082092e+09</td>\n",
       "      <td>2.179708e+09</td>\n",
       "      <td>2022-11-30</td>\n",
       "      <td>9.991988e+09</td>\n",
       "      <td>1.035248e+10</td>\n",
       "      <td>8.399971e+09</td>\n",
       "      <td>1.025955e+10</td>\n",
       "      <td>0.003404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.591469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.871312</td>\n",
       "      <td>-0.159313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.028308</td>\n",
       "      <td>0.589727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.867538</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1598 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   futures_open_interest_history__open  futures_open_interest_history__high  futures_open_interest_history__low  futures_open_interest_history__close       date  futures_open_interest_aggregated_history__open  futures_open_interest_aggregated_history__high  futures_open_interest_aggregated_history__low  futures_open_interest_aggregated_history__close  futures_funding_rate_history__open  ...  sp500__others_dr__lag7  sp500__others_dr__lag10  sp500__others_dr__lag15  sp500__others_dlr__lag1  sp500__others_dlr__lag3  sp500__others_dlr__lag5  sp500__others_dlr__lag7  sp500__others_dlr__lag10  sp500__others_dlr__lag15  y_up_3d\n",
       "0                         2.071097e+09                         2.098987e+09                        2.060349e+09                          2.074905e+09 2022-11-26                                    9.841010e+09                                    9.985549e+09                                   9.841010e+09                                     9.904054e+09                            0.003810  ...                0.000000                -0.825205                 0.924075                -0.028308                 0.589727                -0.389125                 0.000000                 -0.828628                  0.919831        0\n",
       "1                         2.074905e+09                         2.118137e+09                        2.062621e+09                          2.081465e+09 2022-11-27                                    9.904054e+09                                    1.002793e+10                                   9.868134e+09                                     9.946130e+09                            0.001088  ...                0.000000                -0.308932                 0.000000                 0.000000                 0.000000                 1.348861                 0.000000                 -0.309410                  0.000000        1\n",
       "2                         2.081465e+09                         2.090258e+09                        1.970674e+09                          2.025418e+09 2022-11-28                                    9.946130e+09                                    1.000509e+10                                   9.699231e+09                                     9.894938e+09                            0.002267  ...               -0.388369                 0.475858                 0.000000                 0.000000                -0.028308                 0.589727                -0.389125                  0.474730                  0.000000        1\n",
       "3                         2.025418e+09                         2.131462e+09                        2.001265e+09                          2.095082e+09 2022-11-29                                    9.894938e+09                                    1.029943e+10                                   8.754260e+09                                     9.991988e+09                            0.004760  ...                1.357999                 0.000000                -0.893578                -1.556470                 0.000000                 0.000000                 1.348861                  0.000000                 -0.897594        1\n",
       "4                         2.095082e+09                         2.189434e+09                        2.082092e+09                          2.179708e+09 2022-11-30                                    9.991988e+09                                    1.035248e+10                                   8.399971e+09                                     1.025955e+10                            0.003404  ...                0.591469                 0.000000                 0.871312                -0.159313                 0.000000                -0.028308                 0.589727                  0.000000                  0.867538        0\n",
       "\n",
       "[5 rows x 1598 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 1. Сбор данных из API\n",
    "# =============================================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"1. Gathering features from API...\")\n",
    "dfs = get_features(getter, api_key)\n",
    "df_all = merge_by_date(dfs, how=\"outer\", dedupe=\"last\")\n",
    "df_all = df_all.sort_values('date').reset_index(drop=True)\n",
    "print(f\"   Raw data shape: {df_all.shape}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Нормализация и первичное заполнение (ffill)\n",
    "# =============================================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"2. Normalizing spot columns & Applying ffill...\")\n",
    "df_all = features_engineer.ensure_spot_prefix(df_all)\n",
    "\n",
    "# Заполняем пропуски вперед (чтобы не было дырок в выходные/праздники перед генерацией фичей)\n",
    "feature_cols = [c for c in df_all.columns if c != \"date\"]\n",
    "df_all[feature_cols] = df_all[feature_cols].ffill()\n",
    "print(f\"   Remaining NaN after ffill: {df_all[feature_cols].isna().sum().sum()}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Генерация фичей (ДО обрезки даты!)\n",
    "# =============================================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"3. Engineering features & Adding lags...\")\n",
    "\n",
    "# --- 3.1 Инженерные фичи ---\n",
    "print(f\"   Shape before feature engineering: {df_all.shape}\")\n",
    "df_all = features_engineer.add_engineered_features(df_all, horizon=N_DAYS)\n",
    "\n",
    "# --- 3.2 TA-фичи ---\n",
    "df_all = add_ta_features_for_asset(df_all, prefix=\"gold\")\n",
    "df_all = add_ta_features_for_asset(df_all, prefix=\"sp500\")\n",
    "df_all = add_ta_features_for_asset(df_all, prefix=\"spot_price_history\",\n",
    "                                    volume_col_override=\"spot_price_history__volume_usd\")\n",
    "\n",
    "# --- 3.3 Лаги для внешних рынков ---\n",
    "gold_cols = [c for c in df_all.columns if c.startswith(\"gold__\") and \"__lag\" not in c]\n",
    "sp500_cols = [c for c in df_all.columns if c.startswith(\"sp500__\") and \"__lag\" not in c]\n",
    "external_market_cols = gold_cols + sp500_cols\n",
    "\n",
    "if external_market_cols:\n",
    "    df_all = add_lags(df_all, cols=external_market_cols, lags=EXTERNAL_LAGS)\n",
    "    print(f\"   Added {len(external_market_cols) * len(EXTERNAL_LAGS)} lag features\")\n",
    "\n",
    "# --- 3.4 Целевая колонка ---\n",
    "# Добавляем таргет на полном датасете\n",
    "df_all = features_engineer.add_y_up_custom(df_all, horizon=N_DAYS, close_col=\"spot_price_history__close\")\n",
    "\n",
    "# =============================================================================\n",
    "# 4. Фильтрация по дате (Оставляем последние 1500 дней — увеличено с 1250 для компенсации dropna)\n",
    "# =============================================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"4. Filtering last 1500 days...\")\n",
    "\n",
    "df_all['date'] = pd.to_datetime(df_all['date'])\n",
    "max_date = df_all['date'].max()\n",
    "cutoff_date = max_date - pd.Timedelta(days=1500)\n",
    "\n",
    "rows_total = len(df_all)\n",
    "df_all = df_all[df_all['date'] >= cutoff_date]\n",
    "print(f\"   Rows kept: {len(df_all)} (from {rows_total})\")\n",
    "\n",
    "# =============================================================================\n",
    "# 5. Очистка колонок и строк\n",
    "# =============================================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"5. Final cleanup...\")\n",
    "\n",
    "# Удаляем строки, где нет таргета (это последние N дней будущего, для которых мы не знаем исход)\n",
    "df_all = df_all.dropna(subset=[TARGET_COLUMN_NAME])\n",
    "\n",
    "# Удаляем колонки с >30% NaN\n",
    "nan_threshold = 0.3\n",
    "nan_ratio = df_all.isna().mean()\n",
    "cols_to_drop = [\n",
    "    c for c in nan_ratio[nan_ratio > nan_threshold].index\n",
    "    if not c.startswith(\"y_up_\")\n",
    "]\n",
    "if cols_to_drop:\n",
    "    print(f\"   Dropping {len(cols_to_drop)} columns with >30% NaN\")\n",
    "    df_all = df_all.drop(columns=cols_to_drop)\n",
    "\n",
    "# Финальная очистка оставшихся NaN (теперь это безопасно)\n",
    "rows_before_final = len(df_all)\n",
    "df_all = df_all.dropna().reset_index(drop=True)\n",
    "print(f\"   Final Dropna: removed {rows_before_final - len(df_all)} rows.\")\n",
    "\n",
    "# =============================================================================\n",
    "# Итоговый результат\n",
    "# =============================================================================\n",
    "print(\"=\" * 60)\n",
    "print(f\"FINAL DATASET SHAPE: {df_all.shape}\")\n",
    "print(f\"Date range: {df_all['date'].min()} to {df_all['date'].max()}\")\n",
    "print(f\"Target distribution: {df_all[TARGET_COLUMN_NAME].value_counts().to_dict()}\")\n",
    "\n",
    "# Сохраняем в df2 для совместимости с кодом обучения\n",
    "df2 = df_all\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bef6f240-e0df-45c2-bd5e-9df40a3cc8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold фичей: 658\n",
      "S&P500 фичей: 658\n",
      "\n",
      "Примеры gold фичей: ['gold__open', 'gold__close', 'gold__high', 'gold__low', 'gold__volume', 'gold__open__diff1', 'gold__open__pct1', 'gold__close__diff1', 'gold__close__pct1', 'gold__high__diff1', 'gold__high__pct1', 'gold__low__diff1', 'gold__low__pct1', 'gold__volume__diff1', 'gold__volume__pct1', 'gold__volume_adi', 'gold__volume_obv', 'gold__volume_cmf', 'gold__volume_fi', 'gold__volume_em', 'gold__volume_sma_em', 'gold__volume_vpt', 'gold__volume_vwap', 'gold__volume_mfi', 'gold__volume_nvi', 'gold__volatility_bbm', 'gold__volatility_bbh', 'gold__volatility_bbl', 'gold__volatility_bbw', 'gold__volatility_bbp', 'gold__volatility_bbhi', 'gold__volatility_bbli', 'gold__volatility_kcc', 'gold__volatility_kch', 'gold__volatility_kcl', 'gold__volatility_kcw', 'gold__volatility_kcp', 'gold__volatility_kchi', 'gold__volatility_kcli', 'gold__volatility_dcl', 'gold__volatility_dch', 'gold__volatility_dcm', 'gold__volatility_dcw', 'gold__volatility_dcp', 'gold__volatility_ui', 'gold__trend_macd', 'gold__trend_macd_signal', 'gold__trend_macd_diff', 'gold__trend_sma_fast', 'gold__trend_sma_slow', 'gold__trend_ema_fast', 'gold__trend_ema_slow', 'gold__trend_vortex_ind_pos', 'gold__trend_vortex_ind_neg', 'gold__trend_vortex_ind_diff', 'gold__trend_trix', 'gold__trend_mass_index', 'gold__trend_dpo', 'gold__trend_kst', 'gold__trend_kst_sig', 'gold__trend_kst_diff', 'gold__trend_ichimoku_conv', 'gold__trend_ichimoku_base', 'gold__trend_ichimoku_a', 'gold__trend_ichimoku_b', 'gold__trend_stc', 'gold__trend_cci', 'gold__trend_visual_ichimoku_a', 'gold__trend_visual_ichimoku_b', 'gold__trend_aroon_up', 'gold__trend_aroon_down', 'gold__trend_aroon_ind', 'gold__trend_psar_up_indicator', 'gold__trend_psar_down_indicator', 'gold__momentum_rsi', 'gold__momentum_stoch_rsi', 'gold__momentum_stoch_rsi_k', 'gold__momentum_stoch_rsi_d', 'gold__momentum_tsi', 'gold__momentum_uo', 'gold__momentum_stoch', 'gold__momentum_stoch_signal', 'gold__momentum_wr', 'gold__momentum_ao', 'gold__momentum_roc', 'gold__momentum_ppo', 'gold__momentum_ppo_signal', 'gold__momentum_ppo_hist', 'gold__momentum_pvo', 'gold__momentum_pvo_signal', 'gold__momentum_pvo_hist', 'gold__momentum_kama', 'gold__others_dr', 'gold__others_dlr', 'gold__open__lag1', 'gold__open__lag3', 'gold__open__lag5', 'gold__open__lag7', 'gold__open__lag10', 'gold__open__lag15']\n",
      "\n",
      "Примеры sp500 фичей: ['sp500__open', 'sp500__close', 'sp500__high', 'sp500__low', 'sp500__volume', 'sp500__open__diff1', 'sp500__open__pct1', 'sp500__close__diff1', 'sp500__close__pct1', 'sp500__high__diff1', 'sp500__high__pct1', 'sp500__low__diff1', 'sp500__low__pct1', 'sp500__volume__diff1', 'sp500__volume__pct1', 'sp500__volume_adi', 'sp500__volume_obv', 'sp500__volume_cmf', 'sp500__volume_fi', 'sp500__volume_em', 'sp500__volume_sma_em', 'sp500__volume_vpt', 'sp500__volume_vwap', 'sp500__volume_mfi', 'sp500__volume_nvi']\n"
     ]
    }
   ],
   "source": [
    "# Проверка внешних рыночных фичей\n",
    "gold_cols = [c for c in df2.columns if c.startswith(\"gold__\")]\n",
    "sp500_cols = [c for c in df2.columns if c.startswith(\"sp500__\")]\n",
    "\n",
    "print(f\"Gold фичей: {len(gold_cols)}\")\n",
    "print(f\"S&P500 фичей: {len(sp500_cols)}\")\n",
    "\n",
    "if gold_cols:\n",
    "    print(f\"\\nПримеры gold фичей: {gold_cols[:100]}\")\n",
    "if sp500_cols:\n",
    "    print(f\"\\nПримеры sp500 фичей: {sp500_cols[:25]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af6e1a1e-74c2-4454-bc88-cca3ed27a6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 801 rows (2022-11-26 to 2025-04-05)\n",
      "Gap:   3 rows (purge zone — не используется ни в train, ни в test)\n",
      "Test:  202 rows (2025-04-09 to 2026-02-12)\n",
      "\n",
      "Features: 1596\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>futures_open_interest_history__open</th>\n",
       "      <th>futures_open_interest_history__high</th>\n",
       "      <th>futures_open_interest_history__low</th>\n",
       "      <th>futures_open_interest_history__close</th>\n",
       "      <th>date</th>\n",
       "      <th>futures_open_interest_aggregated_history__open</th>\n",
       "      <th>futures_open_interest_aggregated_history__high</th>\n",
       "      <th>futures_open_interest_aggregated_history__low</th>\n",
       "      <th>futures_open_interest_aggregated_history__close</th>\n",
       "      <th>futures_funding_rate_history__open</th>\n",
       "      <th>...</th>\n",
       "      <th>sp500__others_dr__lag7</th>\n",
       "      <th>sp500__others_dr__lag10</th>\n",
       "      <th>sp500__others_dr__lag15</th>\n",
       "      <th>sp500__others_dlr__lag1</th>\n",
       "      <th>sp500__others_dlr__lag3</th>\n",
       "      <th>sp500__others_dlr__lag5</th>\n",
       "      <th>sp500__others_dlr__lag7</th>\n",
       "      <th>sp500__others_dlr__lag10</th>\n",
       "      <th>sp500__others_dlr__lag15</th>\n",
       "      <th>y_up_3d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.071097e+09</td>\n",
       "      <td>2.098987e+09</td>\n",
       "      <td>2.060349e+09</td>\n",
       "      <td>2.074905e+09</td>\n",
       "      <td>2022-11-26</td>\n",
       "      <td>9.841010e+09</td>\n",
       "      <td>9.985549e+09</td>\n",
       "      <td>9.841010e+09</td>\n",
       "      <td>9.904054e+09</td>\n",
       "      <td>0.003810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.825205</td>\n",
       "      <td>0.924075</td>\n",
       "      <td>-0.028308</td>\n",
       "      <td>0.589727</td>\n",
       "      <td>-0.389125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.828628</td>\n",
       "      <td>0.919831</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.074905e+09</td>\n",
       "      <td>2.118137e+09</td>\n",
       "      <td>2.062621e+09</td>\n",
       "      <td>2.081465e+09</td>\n",
       "      <td>2022-11-27</td>\n",
       "      <td>9.904054e+09</td>\n",
       "      <td>1.002793e+10</td>\n",
       "      <td>9.868134e+09</td>\n",
       "      <td>9.946130e+09</td>\n",
       "      <td>0.001088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.308932</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.348861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.309410</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.081465e+09</td>\n",
       "      <td>2.090258e+09</td>\n",
       "      <td>1.970674e+09</td>\n",
       "      <td>2.025418e+09</td>\n",
       "      <td>2022-11-28</td>\n",
       "      <td>9.946130e+09</td>\n",
       "      <td>1.000509e+10</td>\n",
       "      <td>9.699231e+09</td>\n",
       "      <td>9.894938e+09</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.388369</td>\n",
       "      <td>0.475858</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.028308</td>\n",
       "      <td>0.589727</td>\n",
       "      <td>-0.389125</td>\n",
       "      <td>0.474730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.025418e+09</td>\n",
       "      <td>2.131462e+09</td>\n",
       "      <td>2.001265e+09</td>\n",
       "      <td>2.095082e+09</td>\n",
       "      <td>2022-11-29</td>\n",
       "      <td>9.894938e+09</td>\n",
       "      <td>1.029943e+10</td>\n",
       "      <td>8.754260e+09</td>\n",
       "      <td>9.991988e+09</td>\n",
       "      <td>0.004760</td>\n",
       "      <td>...</td>\n",
       "      <td>1.357999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.893578</td>\n",
       "      <td>-1.556470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.348861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.897594</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.095082e+09</td>\n",
       "      <td>2.189434e+09</td>\n",
       "      <td>2.082092e+09</td>\n",
       "      <td>2.179708e+09</td>\n",
       "      <td>2022-11-30</td>\n",
       "      <td>9.991988e+09</td>\n",
       "      <td>1.035248e+10</td>\n",
       "      <td>8.399971e+09</td>\n",
       "      <td>1.025955e+10</td>\n",
       "      <td>0.003404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.591469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.871312</td>\n",
       "      <td>-0.159313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.028308</td>\n",
       "      <td>0.589727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.867538</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1598 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   futures_open_interest_history__open  futures_open_interest_history__high  futures_open_interest_history__low  futures_open_interest_history__close       date  futures_open_interest_aggregated_history__open  futures_open_interest_aggregated_history__high  futures_open_interest_aggregated_history__low  futures_open_interest_aggregated_history__close  futures_funding_rate_history__open  ...  sp500__others_dr__lag7  sp500__others_dr__lag10  sp500__others_dr__lag15  sp500__others_dlr__lag1  sp500__others_dlr__lag3  sp500__others_dlr__lag5  sp500__others_dlr__lag7  sp500__others_dlr__lag10  sp500__others_dlr__lag15  y_up_3d\n",
       "0                         2.071097e+09                         2.098987e+09                        2.060349e+09                          2.074905e+09 2022-11-26                                    9.841010e+09                                    9.985549e+09                                   9.841010e+09                                     9.904054e+09                            0.003810  ...                0.000000                -0.825205                 0.924075                -0.028308                 0.589727                -0.389125                 0.000000                 -0.828628                  0.919831        0\n",
       "1                         2.074905e+09                         2.118137e+09                        2.062621e+09                          2.081465e+09 2022-11-27                                    9.904054e+09                                    1.002793e+10                                   9.868134e+09                                     9.946130e+09                            0.001088  ...                0.000000                -0.308932                 0.000000                 0.000000                 0.000000                 1.348861                 0.000000                 -0.309410                  0.000000        1\n",
       "2                         2.081465e+09                         2.090258e+09                        1.970674e+09                          2.025418e+09 2022-11-28                                    9.946130e+09                                    1.000509e+10                                   9.699231e+09                                     9.894938e+09                            0.002267  ...               -0.388369                 0.475858                 0.000000                 0.000000                -0.028308                 0.589727                -0.389125                  0.474730                  0.000000        1\n",
       "3                         2.025418e+09                         2.131462e+09                        2.001265e+09                          2.095082e+09 2022-11-29                                    9.894938e+09                                    1.029943e+10                                   8.754260e+09                                     9.991988e+09                            0.004760  ...                1.357999                 0.000000                -0.893578                -1.556470                 0.000000                 0.000000                 1.348861                  0.000000                 -0.897594        1\n",
       "4                         2.095082e+09                         2.189434e+09                        2.082092e+09                          2.179708e+09 2022-11-30                                    9.991988e+09                                    1.035248e+10                                   8.399971e+09                                     1.025955e+10                            0.003404  ...                0.591469                 0.000000                 0.871312                -0.159313                 0.000000                -0.028308                 0.589727                  0.000000                  0.867538        0\n",
       "\n",
       "[5 rows x 1598 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. Делим на трейн и тест с purge gap (без shuffle для временных рядов!)\n",
    "gap = N_DAYS  # 7 — purge gap: предотвращает target leakage\n",
    "              # (таргет последних train-строк зависит от цен в test-периоде)\n",
    "\n",
    "train_size = int(len(df2) * 0.8)\n",
    "train = df2.iloc[:train_size - gap]  # убираем gap строк из конца train\n",
    "test = df2.iloc[train_size:]          # test начинается после gap\n",
    "\n",
    "print(f\"Train: {len(train)} rows ({train['date'].min().date()} to {train['date'].max().date()})\")\n",
    "print(f\"Gap:   {gap} rows (purge zone — не используется ни в train, ни в test)\")\n",
    "print(f\"Test:  {len(test)} rows ({test['date'].min().date()} to {test['date'].max().date()})\")\n",
    "\n",
    "X_train = train.drop([TARGET_COLUMN_NAME, 'date'], axis=1)\n",
    "X_test = test.drop([TARGET_COLUMN_NAME, 'date'], axis=1)\n",
    "\n",
    "y_train = train[TARGET_COLUMN_NAME]\n",
    "y_test = test[TARGET_COLUMN_NAME]\n",
    "\n",
    "# 2. Масштабируем\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\nFeatures: {X_train.shape[1]}\")\n",
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d8c1cac-c08b-4053-8a12-6241a227ba16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Порог корреляции: 0.75\n",
      "Удаляем 1251 фичей из 1596\n",
      "Осталось фичей: 345\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Удаление сильно коррелированных фичей (дедупликация)\n",
    "# =============================================================================\n",
    "# 1. Создаем матрицу корреляций\n",
    "corr_matrix = X_train.corr().abs()\n",
    "\n",
    "# 2. Выбираем верхний треугольник матрицы\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# 3. Находим колонки с корреляцией > 0.75 (снижено с 0.9 — агрессивнее убираем дубликаты)\n",
    "#    При 1500+ фичах огромное количество — лаги, diff/pct одного ряда — почти идентичны\n",
    "CORR_THRESHOLD = 0.75\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > CORR_THRESHOLD)]\n",
    "\n",
    "print(f\"Порог корреляции: {CORR_THRESHOLD}\")\n",
    "print(f\"Удаляем {len(to_drop)} фичей из {len(X_train.columns)}\")\n",
    "\n",
    "# 4. Удаляем их из обоих датасетов\n",
    "X_train_reduced = X_train.drop(columns=to_drop)\n",
    "X_test_reduced = X_test.drop(columns=to_drop)\n",
    "\n",
    "print(f\"Осталось фичей: {len(X_train_reduced.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "v2zgtmov8bq",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Считаем корреляции с таргетом (Spearman + p-value)...\n",
      "\n",
      "Всего фичей после удаления дублей: 345\n",
      "Статистически значимых (p < 0.05): 45\n",
      "Отобрано top-15 для обучения модели\n",
      "\n",
      "Топ-15 лидеров по корреляции с таргетом (из значимых):\n",
      "  gold__volume_sma_em: 0.1447\n",
      "  index_btc_lth_supply__lth_supply: 0.1242\n",
      "  sp500__volatility_kcli__lag3: 0.1146\n",
      "  gold__volatility_kcw__lag15: 0.1138\n",
      "  index_btc_active_addresses__aa_z180: 0.1084\n",
      "  sp500__volatility_kchi__lag1: 0.1069\n",
      "  index_btc_active_addresses__aa_pct7: 0.1067\n",
      "  gold__volatility_kchi__lag1: 0.1046\n",
      "  gold__volatility_kcli__lag5: 0.1039\n",
      "  gold__volatility_kchi__lag3: 0.1023\n",
      "  gold__low__diff1__lag15: 0.1017\n",
      "  sp500__volatility_kcli__lag1: 0.1000\n",
      "  sp500__close__diff1__lag7: 0.0992\n",
      "  index_btc_active_addresses__active_address_count: 0.0954\n",
      "  spot_price_history__volatility_kcli: 0.0938\n",
      "\n",
      "Финальный X_train shape: (801, 15)\n",
      "Финальный X_test shape: (202, 15)\n",
      "Ratio samples/features: 53.4:1\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Анализ корреляции с целевой переменной (на очищенных данных)\n",
    "# =============================================================================\n",
    "from scipy.stats import spearmanr\n",
    "import pandas as pd\n",
    "\n",
    "MAX_FEATURES = 15  # Снижено с 50 — жёсткий отбор, только самые сильные сигналы\n",
    "\n",
    "correlations = {}\n",
    "significant_features = []\n",
    "suspicious_features = []\n",
    "\n",
    "print(\"Считаем корреляции с таргетом (Spearman + p-value)...\")\n",
    "\n",
    "for col in X_train_reduced.columns:\n",
    "    corr, p_val = spearmanr(X_train_reduced[col], y_train)\n",
    "    corr_abs = abs(corr)\n",
    "    correlations[col] = corr_abs\n",
    "    \n",
    "    # Проверка на Data Leakage (слишком хорошая корреляция)\n",
    "    if p_val < 0.05 and corr_abs > 0.95:\n",
    "        suspicious_features.append((col, corr_abs))\n",
    "    \n",
    "    # Оставляем только статистически значимые (p < 0.05)\n",
    "    if p_val < 0.05:\n",
    "        significant_features.append((col, corr_abs))\n",
    "\n",
    "# Выводим предупреждение о возможной утечке\n",
    "if suspicious_features:\n",
    "    print(f\"\\n  ВНИМАНИЕ! Найдено {len(suspicious_features)} подозрительных фичей (corr > 0.95, p < 0.05).\")\n",
    "    print(\"  Возможно, это утечка данных (заглядывание в будущее):\")\n",
    "    for f, c in suspicious_features:\n",
    "        print(f\"    - {f}: {c:.4f}\")\n",
    "\n",
    "# Сортируем значимые фичи по силе корреляции\n",
    "significant_features.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Отбираем top MAX_FEATURES из значимых\n",
    "top_features_list = [f[0] for f in significant_features[:MAX_FEATURES]]\n",
    "\n",
    "# Также показываем ВСЕ фичи для справки\n",
    "sorted_features = sorted(correlations.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(f\"\\nВсего фичей после удаления дублей: {len(X_train_reduced.columns)}\")\n",
    "print(f\"Статистически значимых (p < 0.05): {len(significant_features)}\")\n",
    "print(f\"Отобрано top-{len(top_features_list)} для обучения модели\")\n",
    "\n",
    "print(\"\\nТоп-15 лидеров по корреляции с таргетом (из значимых):\")\n",
    "for f, c in significant_features[:15]:\n",
    "    print(f\"  {f}: {c:.4f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# Формируем финальные датасеты для модели\n",
    "# =============================================================================\n",
    "X_train_final = X_train_reduced[top_features_list]\n",
    "X_test_final = X_test_reduced[top_features_list]\n",
    "\n",
    "print(f\"\\nФинальный X_train shape: {X_train_final.shape}\")\n",
    "print(f\"Финальный X_test shape: {X_test_final.shape}\")\n",
    "print(f\"Ratio samples/features: {len(X_train_final) / X_train_final.shape[1]:.1f}:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9aea2ec-72e2-414a-9df4-6f83661fd5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучаем RandomForest для оценки важности (сильная регуляризация)...\n",
      "Train accuracy: 0.6841\n",
      "Test accuracy:  0.4851\n",
      "  Разрыв train-test = 0.1990 — переобучение!\n",
      "\n",
      "Считаем Permutation Importance (n_repeats=30)...\n",
      "\n",
      "Все 15 фичей по Permutation Importance:\n",
      "                                             feature  importance       std       snr\n",
      "13  index_btc_active_addresses__active_address_count    0.007591  0.011626  0.652893\n",
      "4                index_btc_active_addresses__aa_z180    0.004455  0.018406  0.242067\n",
      "9                        gold__volatility_kchi__lag3    0.004125  0.006528  0.631950\n",
      "14               spot_price_history__volatility_kcli    0.003795  0.009278  0.409087\n",
      "7                        gold__volatility_kchi__lag1    0.000660  0.008453  0.078087\n",
      "0                                gold__volume_sma_em   -0.000825  0.025884 -0.031876\n",
      "5                       sp500__volatility_kchi__lag1   -0.001650  0.012013 -0.137361\n",
      "12                         sp500__close__diff1__lag7   -0.001650  0.012013 -0.137361\n",
      "8                        gold__volatility_kcli__lag5   -0.003135  0.006822 -0.459603\n",
      "2                       sp500__volatility_kcli__lag3   -0.003135  0.008992 -0.348697\n",
      "11                      sp500__volatility_kcli__lag1   -0.004290  0.005678 -0.755610\n",
      "10                           gold__low__diff1__lag15   -0.004785  0.013374 -0.357807\n",
      "1                   index_btc_lth_supply__lth_supply   -0.011881  0.018239 -0.651430\n",
      "3                        gold__volatility_kcw__lag15   -0.012376  0.016555 -0.747574\n",
      "6                index_btc_active_addresses__aa_pct7   -0.014026  0.017295 -0.810996\n",
      "\n",
      "Фич с importance > 0: 5\n",
      "Фич со значимым importance (> 2*std): 0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# =============================================================================\n",
    "# 1. Обучение модели для отбора фичей (жёсткая регуляризация!)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Обучаем RandomForest для оценки важности (сильная регуляризация)...\")\n",
    "\n",
    "model_selector = RandomForestClassifier(\n",
    "    n_estimators=200,       # больше деревьев = стабильнее оценка\n",
    "    max_depth=3,            # СНИЖЕНО с 5 → 3: деревья мельче, сложнее переобучиться\n",
    "    min_samples_leaf=20,    # ДОБАВЛЕНО: лист должен содержать ≥20 сэмплов\n",
    "    min_samples_split=40,   # ДОБАВЛЕНО: для сплита нужно ≥40 сэмплов\n",
    "    max_features='sqrt',    # каждое дерево видит √N фич — снижает корреляцию деревьев\n",
    "    random_state=42, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model_selector.fit(X_train_final, y_train)\n",
    "\n",
    "train_acc = model_selector.score(X_train_final, y_train)\n",
    "test_acc = model_selector.score(X_test_final, y_test)\n",
    "print(f\"Train accuracy: {train_acc:.4f}\")\n",
    "print(f\"Test accuracy:  {test_acc:.4f}\")\n",
    "gap_acc = train_acc - test_acc\n",
    "if gap_acc > 0.10:\n",
    "    print(f\"  Разрыв train-test = {gap_acc:.4f} — переобучение!\")\n",
    "elif gap_acc > 0.05:\n",
    "    print(f\"  Разрыв train-test = {gap_acc:.4f} — умеренный, ок для feature selection\")\n",
    "else:\n",
    "    print(f\"  Разрыв train-test = {gap_acc:.4f} — хорошая генерализация\")\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Считаем Permutation Importance\n",
    "# =============================================================================\n",
    "print(\"\\nСчитаем Permutation Importance (n_repeats=30)...\")\n",
    "\n",
    "r = permutation_importance(\n",
    "    model_selector,\n",
    "    X_test_final,\n",
    "    y_test, \n",
    "    n_repeats=30,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Собираем и анализируем результаты\n",
    "# =============================================================================\n",
    "\n",
    "perm_importance = pd.DataFrame({\n",
    "    'feature': X_train_final.columns,\n",
    "    'importance': r.importances_mean,\n",
    "    'std': r.importances_std,\n",
    "    'snr': r.importances_mean / (r.importances_std + 1e-10)\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nВсе {len(perm_importance)} фичей по Permutation Importance:\")\n",
    "print(perm_importance.to_string())\n",
    "\n",
    "# =============================================================================\n",
    "# 4. Фильтр по статистической значимости (importance > 2*std)\n",
    "# =============================================================================\n",
    "significant_mask = perm_importance['importance'] > 2 * perm_importance['std']\n",
    "significant_perm = perm_importance[significant_mask].copy()\n",
    "\n",
    "positive_mask = perm_importance['importance'] > 0\n",
    "positive_perm = perm_importance[positive_mask].copy()\n",
    "\n",
    "print(f\"\\nФич с importance > 0: {len(positive_perm)}\")\n",
    "print(f\"Фич со значимым importance (> 2*std): {len(significant_perm)}\")\n",
    "\n",
    "if len(significant_perm) > 0:\n",
    "    print(\"\\nСтатистически значимые фичи:\")\n",
    "    print(significant_perm.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe45adcf-7418-41e3-86df-1e93ec1edf9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-20 фичей по Permutation Importance:\n",
      "                                             feature  importance       std       snr\n",
      "13  index_btc_active_addresses__active_address_count    0.007591  0.011626  0.652893\n",
      "4                index_btc_active_addresses__aa_z180    0.004455  0.018406  0.242067\n",
      "9                        gold__volatility_kchi__lag3    0.004125  0.006528  0.631950\n",
      "14               spot_price_history__volatility_kcli    0.003795  0.009278  0.409087\n",
      "7                        gold__volatility_kchi__lag1    0.000660  0.008453  0.078087\n",
      "0                                gold__volume_sma_em   -0.000825  0.025884 -0.031876\n",
      "5                       sp500__volatility_kchi__lag1   -0.001650  0.012013 -0.137361\n",
      "12                         sp500__close__diff1__lag7   -0.001650  0.012013 -0.137361\n",
      "8                        gold__volatility_kcli__lag5   -0.003135  0.006822 -0.459603\n",
      "2                       sp500__volatility_kcli__lag3   -0.003135  0.008992 -0.348697\n",
      "11                      sp500__volatility_kcli__lag1   -0.004290  0.005678 -0.755610\n",
      "10                           gold__low__diff1__lag15   -0.004785  0.013374 -0.357807\n",
      "1                   index_btc_lth_supply__lth_supply   -0.011881  0.018239 -0.651430\n",
      "3                        gold__volatility_kcw__lag15   -0.012376  0.016555 -0.747574\n",
      "6                index_btc_active_addresses__aa_pct7   -0.014026  0.017295 -0.810996\n"
     ]
    }
   ],
   "source": [
    "# Убираем ограничение на ширину колонки (None означает \"без лимита\")\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Если таблица разъезжается, можно расширить и общую ширину вывода\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(\"Топ-20 фичей по Permutation Importance:\")\n",
    "print(perm_importance.head(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b046cf7-fe94-41b0-8666-9863042a65b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e97b1f-5930-4faa-bee1-bb0d2c693f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822ea431-a228-413c-adcc-8a931d01253d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
