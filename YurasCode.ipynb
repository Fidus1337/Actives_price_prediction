{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PqaqHrvGfKAZ"
   },
   "outputs": [],
   "source": [
    "## FUTURES descriptions list\n",
    "# KEYS = \"8b16782a668f4eb48397ddf3d97020bd\"\n",
    "\n",
    "# futures open interest DONE\n",
    "# https://open-api-v4.coinglass.com/api/futures/open-interest/history?exchange=Binance&symbol=BTCUSDT&interval=1d\n",
    "\n",
    "# {\n",
    "#   \"code\": \"0\",\n",
    "#   \"msg\": \"success\",\n",
    "#   \"data\": [\n",
    "#     {\n",
    "#       \"time\": 2644845344000, // Timestamp (ms)\n",
    "#       \"open\": \"2644845344\",   // Open interest at interval start\n",
    "#       \"high\": \"2692643311\",   // Highest open interest during interval\n",
    "#       \"low\": \"2576975597\",    // Lowest open interest during interval\n",
    "#       \"close\": \"2608846475\"   // Open interest at interval end\n",
    "#     },\n",
    "#     {\n",
    "#       \"time\": 2608846475000, // Timestamp (ms)\n",
    "#       \"open\": \"2608846475\",  // Open interest at interval start\n",
    "#       \"high\": \"2620807645\",  // Highest open interest during interval\n",
    "#       \"low\": \"2327236202\",   // Lowest open interest during interval\n",
    "#       \"close\": \"2340177420\"  // Open interest at interval end\n",
    "#     },\n",
    "#     ....\n",
    "#   ]\n",
    "# }\n",
    "\n",
    "# futures aggregated history open interest DONE\n",
    "# https://open-api-v4.coinglass.com/api/futures/open-interest/aggregated-history?symbol=BTC&interval=1d\n",
    "\n",
    "# {\n",
    "#   \"code\": \"0\",\n",
    "#   \"msg\": \"success\",\n",
    "#   \"data\": [\n",
    "#     {\n",
    "#       \"time\": 2644845344000, // Timestamp (ms)\n",
    "#       \"open\": \"2644845344\",   // Open interest at interval start\n",
    "#       \"high\": \"2692643311\",   // Highest open interest during interval\n",
    "#       \"low\": \"2576975597\",    // Lowest open interest during interval\n",
    "#       \"close\": \"2608846475\"   // Open interest at interval end\n",
    "#     },\n",
    "#     {\n",
    "#       \"time\": 2608846475000, // Timestamp (ms)\n",
    "#       \"open\": \"2608846475\",  // Open interest at interval start\n",
    "#       \"high\": \"2620807645\",  // Highest open interest during interval\n",
    "#       \"low\": \"2327236202\",   // Lowest open interest during interval\n",
    "#       \"close\": \"2340177420\"  // Open interest at interval end\n",
    "#     },\n",
    "#     ....\n",
    "#   ]\n",
    "# }\n",
    "\n",
    "# aggregated stablecoin-margined open interest data DONE\n",
    "# https://open-api-v4.coinglass.com/api/futures/open-interest/aggregated-stablecoin-history?exchange_list=Binance&symbol=BTC&interval=1d\n",
    "# {\n",
    "#   \"code\": \"0\",\n",
    "#   \"msg\": \"success\",\n",
    "#   \"data\": [\n",
    "#     {\n",
    "#       \"time\": 2644845344000, // Timestamp (ms)\n",
    "#       \"open\": \"2644845344\",   // Open interest at interval start\n",
    "#       \"high\": \"2692643311\",   // Highest open interest during interval\n",
    "#       \"low\": \"2576975597\",    // Lowest open interest during interval\n",
    "#       \"close\": \"2608846475\"   // Open interest at interval end\n",
    "#     },\n",
    "#     {\n",
    "#       \"time\": 2608846475000, // Timestamp (ms)\n",
    "#       \"open\": \"2608846475\",  // Open interest at interval start\n",
    "#       \"high\": \"2620807645\",  // Highest open interest during interval\n",
    "#       \"low\": \"2327236202\",   // Lowest open interest during interval\n",
    "#       \"close\": \"2340177420\"  // Open interest at interval end\n",
    "#     },\n",
    "#     ....\n",
    "#   ]\n",
    "# }\n",
    "\n",
    "# Aggregated Coin Margin History DONE\n",
    "# https://open-api-v4.coinglass.com/api/futures/open-interest/aggregated-coin-margin-history?exchange_list=Binance&symbol=BTC&interval=1d\n",
    "# {\n",
    "#   \"code\": \"0\",\n",
    "#   \"msg\": \"success\",\n",
    "#   \"data\": [\n",
    "#     {\n",
    "#       \"time\": 2644845344000, // Timestamp (ms)\n",
    "#       \"open\": \"2644845344\",   // Open interest at interval start\n",
    "#       \"high\": \"2692643311\",   // Highest open interest during interval\n",
    "#       \"low\": \"2576975597\",    // Lowest open interest during interval\n",
    "#       \"close\": \"2608846475\"   // Open interest at interval end\n",
    "#     },\n",
    "#     {\n",
    "#       \"time\": 2608846475000, // Timestamp (ms)\n",
    "#       \"open\": \"2608846475\",  // Open interest at interval start\n",
    "#       \"high\": \"2620807645\",  // Highest open interest during interval\n",
    "#       \"low\": \"2327236202\",   // Lowest open interest during interval\n",
    "#       \"close\": \"2340177420\"  // Open interest at interval end\n",
    "#     },\n",
    "#     ....\n",
    "#   ]\n",
    "# }\n",
    "\n",
    "# funding rate data in OHLC (open, high, low, close) candlestick format for futures trading pairs. DONE\n",
    "# https://open-api-v4.coinglass.com/api/futures/funding-rate/history?exchange=Binance&symbol=BTCUSDT&interval=1d\n",
    "# {\n",
    "#   \"code\": \"0\",\n",
    "#   \"msg\": \"success\",\n",
    "#   \"data\": [\n",
    "#     {\n",
    "#       \"time\": 1658880000000, // Timestamp (milliseconds)\n",
    "#       \"open\": \"0.004603\",     // Opening funding rate\n",
    "#       \"high\": \"0.009388\",     // Highest funding rate\n",
    "#       \"low\": \"-0.005063\",     // Lowest funding rate\n",
    "#       \"close\": \"0.009229\"     // Closing funding rate\n",
    "#     },\n",
    "#     {\n",
    "#       \"time\": 1658966400000, // Timestamp (milliseconds)\n",
    "#       \"open\": \"0.009229\",     // Opening funding rate\n",
    "#       \"high\": \"0.01\",         // Highest funding rate\n",
    "#       \"low\": \"0.007794\",      // Lowest funding rate\n",
    "#       \"close\": \"0.01\"         // Closing funding rate\n",
    "#     }\n",
    "#   ]\n",
    "# }\n",
    "\n",
    "# open interest-weighted funding rate data in OHLC DONE\n",
    "# https://open-api-v4.coinglass.com/api/futures/funding-rate/oi-weight-history?symbol=BTC&interval=1d\n",
    "# {\n",
    "#   \"code\": \"0\",\n",
    "#   \"msg\": \"success\",\n",
    "#   \"data\": [\n",
    "#     {\n",
    "#       \"time\": 1658880000000, // Timestamp (milliseconds)\n",
    "#       \"open\": \"0.004603\",     // Opening funding rate\n",
    "#       \"high\": \"0.009388\",     // Highest funding rate\n",
    "#       \"low\": \"-0.005063\",     // Lowest funding rate\n",
    "#       \"close\": \"0.009229\"     // Closing funding rate\n",
    "#     },\n",
    "#     {\n",
    "#       \"time\": 1658966400000, // Timestamp (milliseconds)\n",
    "#       \"open\": \"0.009229\",     // Opening funding rate\n",
    "#       \"high\": \"0.01\",         // Highest funding rate\n",
    "#       \"low\": \"0.007794\",      // Lowest funding rate\n",
    "#       \"close\": \"0.01\"         // Closing funding rate\n",
    "#     }\n",
    "#   ]\n",
    "# }\n",
    "\n",
    "# volume-weighted funding rate data in OHLC  DONE\n",
    "# https://open-api-v4.coinglass.com/api/futures/funding-rate/vol-weight-history?symbol=BTC&interval=1d\n",
    "# {\n",
    "#   \"code\": \"0\",\n",
    "#   \"msg\": \"success\",\n",
    "#   \"data\": [\n",
    "#     {\n",
    "#       \"time\": 1658880000000, // Timestamp (milliseconds)\n",
    "#       \"open\": \"0.004603\",     // Opening funding rate\n",
    "#       \"high\": \"0.009388\",     // Highest funding rate\n",
    "#       \"low\": \"-0.005063\",     // Lowest funding rate\n",
    "#       \"close\": \"0.009229\"     // Closing funding rate\n",
    "#     },\n",
    "#     {\n",
    "#       \"time\": 1658966400000, // Timestamp (milliseconds)\n",
    "#       \"open\": \"0.009229\",     // Opening funding rate\n",
    "#       \"high\": \"0.01\",         // Highest funding rate\n",
    "#       \"low\": \"0.007794\",      // Lowest funding rate\n",
    "#       \"close\": \"0.01\"         // Closing funding rate\n",
    "#     }\n",
    "#   ]\n",
    "# }\n",
    "\n",
    "# long/short account ratio history for trading pairs on a specific exchange. DONE\n",
    "# https://open-api-v4.coinglass.com/api/futures/global-long-short-account-ratio/history?exchange=Binance&symbol=BTCUSDT&interval=1d\n",
    "# {\n",
    "#   \"code\": \"0\",\n",
    "#   \"msg\": \"success\",\n",
    "#   \"data\": [\n",
    "#     {\n",
    "#       \"time\": 1741604400000, // Timestamp (in milliseconds)\n",
    "#       \"global_account_long_percent\": 73.88, // Long position percentage of accounts (%)\n",
    "#       \"global_account_short_percent\": 26.12, // Short position percentage of accounts (%)\n",
    "#       \"global_account_long_short_ratio\": 2.83 // Long/Short ratio of accounts\n",
    "#     },\n",
    "#     {\n",
    "#       \"time\": 1741608000000, // Timestamp (in milliseconds)\n",
    "#       \"global_account_long_percent\": 73.24, // Long position percentage of accounts (%)\n",
    "#       \"global_account_short_percent\": 26.76, // Short position percentage of accounts (%)\n",
    "#       \"global_account_long_short_ratio\": 2.74 // Long/Short ratio of accounts\n",
    "#     }\n",
    "#   ]\n",
    "# }\n",
    "\n",
    "#  historical data for the long/short account ratio of top traders. DONE\n",
    "# https://open-api-v4.coinglass.com/api/futures/top-long-short-account-ratio/history?exchange=Binance&symbol=BTCUSDT&interval=1d\n",
    "# {\n",
    "#   \"code\": \"0\",\n",
    "#   \"msg\": \"success\",\n",
    "#   \"data\": [\n",
    "#     {\n",
    "#       \"time\": 1741615200000, // Timestamp (in milliseconds)\n",
    "#       \"top_account_long_percent\": 73.3, // Long position percentage of top accounts (%)\n",
    "#       \"top_account_short_percent\": 26.7, // Short position percentage of top accounts (%)\n",
    "#       \"top_account_long_short_ratio\": 2.75 // Long/Short ratio of top accounts\n",
    "#     },\n",
    "#     {\n",
    "#       \"time\": 1741618800000, // Timestamp (in milliseconds)\n",
    "#       \"top_account_long_percent\": 74.18, // Long position percentage of top accounts (%)\n",
    "#       \"top_account_short_percent\": 25.82, // Short position percentage of top accounts (%)\n",
    "#       \"top_account_long_short_ratio\": 2.87 // Long/Short ratio of top accounts\n",
    "#     }\n",
    "#   ]\n",
    "# }\n",
    "\n",
    "#  long/short position ratio of top traders. DONE\n",
    "# https://open-api-v4.coinglass.com/api/futures/top-long-short-position-ratio/history?exchange=Binance&symbol=BTCUSDT&interval=1d\n",
    "# {\n",
    "#   \"code\": \"0\",\n",
    "#   \"msg\": \"success\",\n",
    "#   \"data\": [\n",
    "#     {\n",
    "#       \"time\": 1741615200000, // Timestamp (in milliseconds)\n",
    "#       \"top_position_long_percent\": 64.99, // Long position percentage of top positions (%)\n",
    "#       \"top_position_short_percent\": 35.01, // Short position percentage of top positions (%)\n",
    "#       \"top_position_long_short_ratio\": 1.86 // Long/Short ratio of top positions\n",
    "#     },\n",
    "#     {\n",
    "#       \"time\": 1741618800000, // Timestamp (in milliseconds)\n",
    "#       \"top_position_long_percent\": 64.99, // Long position percentage of top positions (%)\n",
    "#       \"top_position_short_percent\": 35.01, // Short position percentage of top positions (%)\n",
    "#       \"top_position_long_short_ratio\": 1.86 // Long/Short ratio of top positions\n",
    "#     }\n",
    "#   ]\n",
    "# }\n",
    "\n",
    "# historical net position data for futures, including the net_long_change and net_short_change values. DONE\n",
    "# https://open-api-v4.coinglass.com/api/futures/v2/net-position/history?exchange=Binance&symbol=BTCUSDT&interval=1d\n",
    "# {\n",
    "#   \"code\": \"0\",\n",
    "#   \"data\": [\n",
    "#     {\n",
    "#       \"net_long_change\": -478.43,\n",
    "#       \"net_short_change\": 0,\n",
    "#       \"time\": 1751652000000\n",
    "#     },\n",
    "#     {\n",
    "#       \"net_long_change\": -776.79,\n",
    "#       \"net_short_change\": 0,\n",
    "#       \"time\": 1751655600000\n",
    "#     },\n",
    "# }\n",
    "\n",
    "# historical data for long and short liquidations of a trading pair on the exchange. DONE\n",
    "# https://open-api-v4.coinglass.com/api/futures/liquidation/history?exchange=Binance&symbol=BTCUSDT&interval=1d\n",
    "# {\n",
    "#   \"code\": \"0\",\n",
    "#   \"msg\": \"success\",\n",
    "#   \"data\": [\n",
    "#     {\n",
    "#       \"time\": 1658880000000, // Timestamp (milliseconds)\n",
    "#       \"long_liquidation_usd\": \"2369935.19562\", // Long position liquidation amount (USD)\n",
    "#       \"short_liquidation_usd\": \"6947459.43674\" // Short position liquidation amount (USD)\n",
    "#     },\n",
    "#     {\n",
    "#       \"time\": 1658966400000, // Timestamp (milliseconds)\n",
    "#       \"long_liquidation_usd\": \"5118407.85124\", // Long position liquidation amount (USD)\n",
    "#       \"short_liquidation_usd\": \"8517330.44192\" // Short position liquidation amount (USD)\n",
    "#     }\n",
    "#   ]\n",
    "# }\n",
    "\n",
    "# aggregated historical data for both long and short liquidations of a coin across multiple exchanges. DONE\n",
    "# https://open-api-v4.coinglass.com/api/futures/liquidation/aggregated-history?exchange_list=Binance&symbol=BTC&interval=1d\n",
    "# {\n",
    "#   \"code\": \"0\",\n",
    "#   \"msg\": \"success\",\n",
    "#   \"data\": [\n",
    "#     {\n",
    "#       \"time\": 1658966400000, // Timestamp (milliseconds)\n",
    "#       \"aggregated_long_liquidation_usd\": 5916885.14234,//aggregated Long position liquidation amount (USD)\n",
    "#       \"aggregated_short_liquidation_usd\": 12969583.87632 //aggregated Short position liquidation amount (USD)\n",
    "#     },\n",
    "#     {\n",
    "#       \"time\": 1659052800000,  // Timestamp (milliseconds)\n",
    "#       \"aggregated_long_liquidation_usd\": 5345708.23191, //aggregated Long position liquidation amount (USD)\n",
    "#       \"aggregated_short_liquidation_usd\": 6454875.54909 //aggregated Short position liquidation amount (USD)\n",
    "#     },\n",
    "#   ]\n",
    "# }\n",
    "\n",
    "# historical data of the order book for futures trading, including total bid/ask volumes within a specific price range. DONE\n",
    "# https://open-api-v4.coinglass.com/api/futures/orderbook/ask-bids-history?exchange=Binance&symbol=BTCUSDT&interval=1d\n",
    "# {\n",
    "#   \"code\": \"0\",\n",
    "#   \"msg\": \"success\",\n",
    "#   \"data\": [\n",
    "#     {\n",
    "#       \"bids_usd\": 81639959.9338,        // Total long position amount (USD)\n",
    "#       \"bids_quantity\": 1276.645,        // Total long quantity\n",
    "#       \"asks_usd\": 78533053.6862,        // Total short position amount (USD)\n",
    "#       \"asks_quantity\": 1217.125,        // Total short quantity\n",
    "#       \"time\": 1714003200000             // Timestamp (in milliseconds)\n",
    "#     },\n",
    "#     {\n",
    "#       \"bids_usd\": 62345879.8821,\n",
    "#       \"bids_quantity\": 980.473,\n",
    "#       \"asks_usd\": 65918423.4715,\n",
    "#       \"asks_quantity\": 1021.644,\n",
    "#       \"time\": 1714089600000\n",
    "#     }\n",
    "#   ]\n",
    "# }\n",
    "\n",
    "#  historical data of the aggregated order book for futures trading, including total bid/ask volumes within a specific price range. DONE\n",
    "# https://open-api-v4.coinglass.com/api/futures/orderbook/aggregated-ask-bids-history?exchange_list=Binance&symbol=BTC&interval=1d\n",
    "# {\n",
    "#   \"code\": \"0\",\n",
    "#   \"msg\": \"success\",\n",
    "#   \"data\": [\n",
    "#     {\n",
    "#       \"aggregated_bids_usd\": 12679537.0806,         // Aggregated long amount (USD)\n",
    "#       \"aggregated_bids_quantity\": 197.99861,        // Aggregated long quantity\n",
    "#       \"aggregated_asks_usd\": 10985519.9268,         // Aggregated short amount (USD)\n",
    "#       \"aggregated_asks_quantity\": 170.382,          // Aggregated short quantity\n",
    "#       \"time\": 1714003200000                         // Timestamp (milliseconds)\n",
    "#     },\n",
    "#     {\n",
    "#       \"aggregated_bids_usd\": 18423845.1947,\n",
    "#       \"aggregated_bids_quantity\": 265.483,\n",
    "#       \"aggregated_asks_usd\": 17384271.5521,\n",
    "#       \"aggregated_asks_quantity\": 240.785,\n",
    "#       \"time\": 1714089600000\n",
    "#     }\n",
    "#   ]\n",
    "# }\n",
    "\n",
    "# historical data for the long/short ratio of taker buy and sell volumes in futures markets. DONE\n",
    "# https://open-api-v4.coinglass.com/api/futures/v2/taker-buy-sell-volume/history?exchange=Binance&symbol=BTCUSDT&interval=1d\n",
    "# {\n",
    "#   \"code\": \"0\",\n",
    "#   \"data\": [\n",
    "#     {\n",
    "#       \"time\": 1750183200000,\n",
    "#       \"taker_buy_volume_usd\": \"414120141.0714\",\n",
    "#       \"taker_sell_volume_usd\": \"350417509.655\"\n",
    "#     },\n",
    "#     {\n",
    "#       \"time\": 1750186800000,\n",
    "#       \"taker_buy_volume_usd\": \"882509979.6914\",\n",
    "#       \"taker_sell_volume_usd\": \"808715578.4428\"\n",
    "#     },\n",
    "#     {\n",
    "#       \"time\": 1750190400000,\n",
    "#       \"taker_buy_volume_usd\": \"572589140.5759\",\n",
    "#       \"taker_sell_volume_usd\": \"571005164.3247\"\n",
    "#     },\n",
    "# }\n",
    "\n",
    "# historical data for the long/short ratio of aggregated taker buy and sell volumes for futures cryptocurrencies. DONE\n",
    "# https://open-api-v4.coinglass.com/api/futures/aggregated-taker-buy-sell-volume/history?exchange_list=Binance&symbol=BTC&interval=1d\n",
    "# {\n",
    "#   \"code\": \"0\",\n",
    "#   \"msg\": \"success\",\n",
    "#   \"data\": [\n",
    "#     {\n",
    "#       \"time\": 1741622400000, // Timestamp in milliseconds\n",
    "#       \"aggregated_buy_volume_usd\": 968834542.3787, // Aggregated buy volume (USD)\n",
    "#       \"aggregated_sell_volume_usd\": 1054582654.8138 // Aggregated sell volume (USD)\n",
    "#     },\n",
    "#     {\n",
    "#       \"time\": 1741626000000,\n",
    "#       \"aggregated_buy_volume_usd\": 1430620763.2041,\n",
    "#       \"aggregated_sell_volume_usd\": 1559166911.2821\n",
    "#     },\n",
    "#     {\n",
    "#       \"time\": 1741629600000,\n",
    "#       \"aggregated_buy_volume_usd\": 1897261721.0129,\n",
    "#       \"aggregated_sell_volume_usd\": 2003812276.7812\n",
    "#     }\n",
    "#   ]\n",
    "# }\n",
    "\n",
    "# historical Cumulative Volume Delta (CVD) data for a single futures exchange trading pair, including taker buy and sell volumes over time.\n",
    "# https://open-api-v4.coinglass.com/api/futures/cvd/history?exchange=Binance&symbol=BTCUSDT&interval=1d\n",
    "# {\n",
    "#   \"code\": \"0\",\n",
    "#   \"data\": [\n",
    "#     {\n",
    "#       \"time\": 1762254000000,\n",
    "#       \"taker_buy_vol\": 350281007.0211,\n",
    "#       \"taker_sell_vol\": 325339470.9493,\n",
    "#       \"cum_vol_delta\": 24941536.0718\n",
    "#     },\n",
    "#     {\n",
    "#       \"time\": 1762257600,\n",
    "#       \"taker_buy_vol\": 286399814.1275,\n",
    "#       \"taker_sell_vol\": 347409544.4937,\n",
    "#       \"cum_vol_delta\": -36068194.2944\n",
    "#     },\n",
    "#     {\n",
    "#       \"time\": 1762261200,\n",
    "#       \"taker_buy_vol\": 299952362.4807,\n",
    "#       \"taker_sell_vol\": 323978642.5934,\n",
    "#       \"cum_vol_delta\": -60094474.4071\n",
    "#     },\n",
    "#   ]\n",
    "# }\n",
    "\n",
    "# historical CVD data for a single cryptocurrency within one futures exchange, aggregated across multiple trading pairs.\n",
    "# https://open-api-v4.coinglass.com/api/futures/aggregated-cvd/history?exchange_list=Binance&symbol=BTC&interval=1d\n",
    "# {\n",
    "#   \"code\": \"0\",\n",
    "#   \"data\": [\n",
    "#     {\n",
    "#       \"time\": 1762254000000,\n",
    "#       \"agg_taker_buy_vol\": 461937243.0899,\n",
    "#       \"agg_taker_sell_vol\": 415687343.2719,\n",
    "#       \"cum_vol_delta\": 46249899.818\n",
    "#     },\n",
    "#     {\n",
    "#       \"time\": 1762257600,\n",
    "#       \"agg_taker_buy_vol\": 390296231.4588,\n",
    "#       \"agg_taker_sell_vol\": 469137635.9107,\n",
    "#       \"cum_vol_delta\": -32591504.6339\n",
    "#     },\n",
    "#     {\n",
    "#       \"time\": 1762261200,\n",
    "#       \"agg_taker_buy_vol\": 461378798.1884,\n",
    "#       \"agg_taker_sell_vol\": 450407935.7885,\n",
    "#       \"cum_vol_delta\": -21620642.234\n",
    "#     },\n",
    "#   ]\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "EGfzsIGQ_YDd"
   },
   "outputs": [],
   "source": [
    "# Loading env vars and libraries\n",
    "\n",
    "import pandas as pd\n",
    "from FeaturesGetterModule.helpers._coinglass_normalize_time_to_date import _coinglass_normalize_time_to_date\n",
    "from FeaturesGetterModule.helpers._coinglass_get_dataframe import _coinglass_get_dataframe\n",
    "from FeaturesGetterModule.helpers._prefix_columns import _prefix_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_futures_open_interest_history(\n",
    "    api_key: str,\n",
    "    exchange: str = \"Binance\",\n",
    "    symbol: str = \"BTCUSDT\",\n",
    "    interval: str = \"1d\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Endpoint:\n",
    "    /api/futures/open-interest/history\n",
    "    \"\"\"\n",
    "    endpoint_slug = \"futures_open_interest_history\"\n",
    "\n",
    "    df = _coinglass_get_dataframe(\n",
    "        endpoint=\"/futures/open-interest/history\",\n",
    "        api_key=api_key,\n",
    "        params={\"exchange\": exchange, \"symbol\": symbol, \"interval\": interval},\n",
    "    )\n",
    "\n",
    "    # time -> date\n",
    "    if \"time\" in df.columns:\n",
    "        df[\"date\"] = _coinglass_normalize_time_to_date(df[\"time\"])\n",
    "        df = df.drop(columns=[\"time\"])\n",
    "    else:\n",
    "        df[\"date\"] = pd.NA\n",
    "\n",
    "    # numeric fields (до префикса, чтобы не усложнять список)\n",
    "    for col in [\"open\", \"high\", \"low\", \"close\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # префикс для всех колонок, кроме date\n",
    "    df = _prefix_columns(df, prefix=endpoint_slug, keep=(\"date\",))\n",
    "\n",
    "    # порядок колонок: date, затем все остальное\n",
    "    cols = [\"date\"] + [c for c in df.columns if c != \"date\"]\n",
    "    df = df[cols].sort_values(\"date\", kind=\"stable\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_futures_open_interest_aggregated_history(\n",
    "    api_key: str,\n",
    "    symbol: str = \"BTC\",\n",
    "    interval: str = \"1d\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Endpoint:\n",
    "    /api/futures/open-interest/aggregated-history\n",
    "    \"\"\"\n",
    "    endpoint_slug = \"futures_open_interest_aggregated_history\"\n",
    "\n",
    "    df = _coinglass_get_dataframe(\n",
    "        endpoint=\"/futures/open-interest/aggregated-history\",\n",
    "        api_key=api_key,\n",
    "        params={\"symbol\": symbol, \"interval\": interval},\n",
    "    )\n",
    "\n",
    "    # time -> date\n",
    "    if \"time\" in df.columns:\n",
    "        df[\"date\"] = _coinglass_normalize_time_to_date(df[\"time\"])\n",
    "        df = df.drop(columns=[\"time\"])\n",
    "    else:\n",
    "        df[\"date\"] = pd.NA\n",
    "\n",
    "    # numeric fields\n",
    "    for col in [\"open\", \"high\", \"low\", \"close\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # префикс для всех колонок, кроме date\n",
    "    df = _prefix_columns(df, prefix=endpoint_slug, keep=(\"date\",))\n",
    "\n",
    "    cols = [\"date\"] + [c for c in df.columns if c != \"date\"]\n",
    "    df = df[cols].sort_values(\"date\", kind=\"stable\").reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x70ivs5M_YAr",
    "outputId": "0c162b15-becb-49a3-805a-364c4c6606e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date  futures_open_interest_history__open  \\\n",
      "995  2026-01-16                           9230232715   \n",
      "996  2026-01-17                           9097466912   \n",
      "997  2026-01-18                           9126076632   \n",
      "998  2026-01-19                           8964467547   \n",
      "999  2026-01-20                           8704286692   \n",
      "\n",
      "     futures_open_interest_history__high  futures_open_interest_history__low  \\\n",
      "995                           9273594133                          9087242640   \n",
      "996                           9132746981                          9033788566   \n",
      "997                           9325716763                          8956024533   \n",
      "998                           8964467547                          8598499594   \n",
      "999                           8942996455                          8687156405   \n",
      "\n",
      "     futures_open_interest_history__close  \n",
      "995                          9.097467e+09  \n",
      "996                          9.126077e+09  \n",
      "997                          8.964468e+09  \n",
      "998                          8.704287e+09  \n",
      "999                          8.934576e+09  \n",
      "Строк: 1000, Столбцов: 5\n"
     ]
    }
   ],
   "source": [
    "#########ЕСТЬ############## ()\n",
    "\n",
    "KEYS = \"8b16782a668f4eb48397ddf3d97020bd\"\n",
    "\n",
    "df_oi = get_futures_open_interest_history(\n",
    "    api_key=KEYS,\n",
    "    exchange=\"Binance\",\n",
    "    symbol=\"BTCUSDT\",\n",
    "    interval=\"1d\",\n",
    ")\n",
    "print(df_oi.tail())\n",
    "\n",
    "rows, cols = df_oi.shape\n",
    "print(f\"Строк: {rows}, Столбцов: {cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hvb-Y1PR_X-a",
    "outputId": "11688130-c020-45c3-e9dc-db8c94f4a2c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date  futures_open_interest_aggregated_history__open  \\\n",
      "995  2026-01-16                                     64081097965   \n",
      "996  2026-01-17                                     62931806233   \n",
      "997  2026-01-18                                     61604995533   \n",
      "998  2026-01-19                                     60884170162   \n",
      "999  2026-01-20                                     61327529392   \n",
      "\n",
      "     futures_open_interest_aggregated_history__high  \\\n",
      "995                                     64189770645   \n",
      "996                                     63054440496   \n",
      "997                                     62172764818   \n",
      "998                                     62290328855   \n",
      "999                                     62437917492   \n",
      "\n",
      "     futures_open_interest_aggregated_history__low  \\\n",
      "995                                    61941074334   \n",
      "996                                    61573790449   \n",
      "997                                    60779032221   \n",
      "998                                    59651485206   \n",
      "999                                    60693929889   \n",
      "\n",
      "     futures_open_interest_aggregated_history__close  \n",
      "995                                     6.293181e+10  \n",
      "996                                     6.160500e+10  \n",
      "997                                     6.088417e+10  \n",
      "998                                     6.132753e+10  \n",
      "999                                     6.243456e+10  \n"
     ]
    }
   ],
   "source": [
    "df_oi_agg = get_futures_open_interest_aggregated_history(\n",
    "    api_key=KEYS,\n",
    "    symbol=\"BTC\",\n",
    "    interval=\"1d\",\n",
    ")\n",
    "print(df_oi_agg.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "jjy6WpHm_XZX"
   },
   "outputs": [],
   "source": [
    "def get_futures_open_interest_aggregated_stablecoin_history(\n",
    "    api_key: str,\n",
    "    exchange_list: str = \"Binance\",\n",
    "    symbol: str = \"BTC\",\n",
    "    interval: str = \"1d\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aggregated stablecoin-margined open interest (OHLC) history.\n",
    "    Endpoint:\n",
    "    /api/futures/open-interest/aggregated-stablecoin-history?exchange_list=...&symbol=...&interval=...\n",
    "\n",
    "    Возвращает DF:\n",
    "    date (YYYY-MM-DD),\n",
    "    futures_open_interest_aggregated_stablecoin_history__open/high/low/close (float)\n",
    "    \"\"\"\n",
    "    endpoint_slug = \"futures_open_interest_aggregated_stablecoin_history\"\n",
    "\n",
    "    df = _coinglass_get_dataframe(\n",
    "        endpoint=\"/futures/open-interest/aggregated-stablecoin-history\",\n",
    "        api_key=api_key,\n",
    "        params={\"exchange_list\": exchange_list, \"symbol\": symbol, \"interval\": interval},\n",
    "    )\n",
    "\n",
    "    # time -> date\n",
    "    if \"time\" in df.columns:\n",
    "        df[\"date\"] = _coinglass_normalize_time_to_date(df[\"time\"])\n",
    "        df = df.drop(columns=[\"time\"])\n",
    "    else:\n",
    "        df[\"date\"] = pd.NA\n",
    "\n",
    "    # numeric fields\n",
    "    for col in [\"open\", \"high\", \"low\", \"close\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # prefix all except date\n",
    "    df = _prefix_columns(df, prefix=endpoint_slug, keep=(\"date\",))\n",
    "\n",
    "    cols = [\"date\"] + [c for c in df.columns if c != \"date\"]\n",
    "    df = df[cols].sort_values(\"date\", kind=\"stable\").reset_index(drop=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8eJZpbUd_XWY",
    "outputId": "aafc65fa-5ae5-4fce-c772-94b2380aab12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date  futures_open_interest_aggregated_stablecoin_history__open  \\\n",
      "995  2026-01-16                                          107270.19           \n",
      "996  2026-01-17                                          105813.00           \n",
      "997  2026-01-18                                          106476.53           \n",
      "998  2026-01-19                                          106353.50           \n",
      "999  2026-01-20                                          104802.15           \n",
      "\n",
      "     futures_open_interest_aggregated_stablecoin_history__high  \\\n",
      "995                                          108232.32           \n",
      "996                                          106586.00           \n",
      "997                                          108303.63           \n",
      "998                                          106575.11           \n",
      "999                                          109238.26           \n",
      "\n",
      "     futures_open_interest_aggregated_stablecoin_history__low  \\\n",
      "995                                          105646.17          \n",
      "996                                          105363.39          \n",
      "997                                          106193.63          \n",
      "998                                          103546.43          \n",
      "999                                          104736.67          \n",
      "\n",
      "     futures_open_interest_aggregated_stablecoin_history__close  \n",
      "995                                         105813.000           \n",
      "996                                         106476.530           \n",
      "997                                         106353.500           \n",
      "998                                         104802.150           \n",
      "999                                         109036.762           \n"
     ]
    }
   ],
   "source": [
    "#### READy\n",
    "df_stable_oi = get_futures_open_interest_aggregated_stablecoin_history(\n",
    "    api_key=KEYS,\n",
    "    exchange_list=\"Binance\",  # можно \"Binance,Bybit\" если API поддерживает список через запятую\n",
    "    symbol=\"BTC\",\n",
    "    interval=\"1d\",\n",
    ")\n",
    "\n",
    "print(df_stable_oi.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-JHsNhXu_XUG"
   },
   "outputs": [],
   "source": [
    "def get_futures_open_interest_aggregated_coin_margin_history(\n",
    "    api_key: str,\n",
    "    exchange_list: str = \"Binance\",\n",
    "    symbol: str = \"BTC\",\n",
    "    interval: str = \"1d\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aggregated coin-margined open interest (OHLC) history.\n",
    "    Endpoint:\n",
    "    /api/futures/open-interest/aggregated-coin-margin-history?exchange_list=...&symbol=...&interval=...\n",
    "\n",
    "    Возвращает DF:\n",
    "    date (YYYY-MM-DD),\n",
    "    futures_open_interest_aggregated_coin_margin_history__open/high/low/close (float)\n",
    "    \"\"\"\n",
    "    endpoint_slug = \"futures_open_interest_aggregated_coin_margin_history\"\n",
    "\n",
    "    df = _coinglass_get_dataframe(\n",
    "        endpoint=\"/futures/open-interest/aggregated-coin-margin-history\",\n",
    "        api_key=api_key,\n",
    "        params={\"exchange_list\": exchange_list, \"symbol\": symbol, \"interval\": interval},\n",
    "    )\n",
    "\n",
    "    # time -> date\n",
    "    if \"time\" in df.columns:\n",
    "        df[\"date\"] = _coinglass_normalize_time_to_date(df[\"time\"])\n",
    "        df = df.drop(columns=[\"time\"])\n",
    "    else:\n",
    "        df[\"date\"] = pd.NA\n",
    "\n",
    "    # numeric fields\n",
    "    for col in [\"open\", \"high\", \"low\", \"close\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # prefix all except date\n",
    "    df = _prefix_columns(df, prefix=endpoint_slug, keep=(\"date\",))\n",
    "\n",
    "    cols = [\"date\"] + [c for c in df.columns if c != \"date\"]\n",
    "    df = df[cols].sort_values(\"date\", kind=\"stable\").reset_index(drop=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v6RNqve2D8o9",
    "outputId": "c13a77f4-6b1b-4bc4-9079-28b5e7be9c01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date  futures_open_interest_aggregated_coin_margin_history__open  \\\n",
      "995  2026-01-16                                         2109082000            \n",
      "996  2026-01-17                                         2116094100            \n",
      "997  2026-01-18                                         2152075800            \n",
      "998  2026-01-19                                         2140944200            \n",
      "999  2026-01-20                                         2132132900            \n",
      "\n",
      "     futures_open_interest_aggregated_coin_margin_history__high  \\\n",
      "995                                         2132462600            \n",
      "996                                         2161179600            \n",
      "997                                         2159383100            \n",
      "998                                         2173865900            \n",
      "999                                         2187128700            \n",
      "\n",
      "     futures_open_interest_aggregated_coin_margin_history__low  \\\n",
      "995                                         2108337800           \n",
      "996                                         2107625400           \n",
      "997                                         2133251000           \n",
      "998                                         2126054100           \n",
      "999                                         2125406100           \n",
      "\n",
      "     futures_open_interest_aggregated_coin_margin_history__close  \n",
      "995                                         2116094100            \n",
      "996                                         2152075800            \n",
      "997                                         2140944200            \n",
      "998                                         2132132900            \n",
      "999                                         2178168600            \n"
     ]
    }
   ],
   "source": [
    "#### READy ()\n",
    "KEYS = \"8b16782a668f4eb48397ddf3d97020bd\"\n",
    "\n",
    "df_coin_margin = get_futures_open_interest_aggregated_coin_margin_history(\n",
    "    api_key=KEYS,\n",
    "    exchange_list=\"Binance\",\n",
    "    symbol=\"BTC\",\n",
    "    interval=\"1d\",\n",
    ")\n",
    "\n",
    "print(df_coin_margin.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "UGCDTIRw_XR5"
   },
   "outputs": [],
   "source": [
    "def get_futures_funding_rate_history(\n",
    "    api_key: str,\n",
    "    exchange: str = \"Binance\",\n",
    "    symbol: str = \"BTCUSDT\",\n",
    "    interval: str = \"1d\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Funding rate OHLC history for futures trading pairs.\n",
    "    Endpoint:\n",
    "    /api/futures/funding-rate/history?exchange=...&symbol=...&interval=...\n",
    "\n",
    "    Возвращает DF:\n",
    "    date (YYYY-MM-DD),\n",
    "    futures_funding_rate_history__open/high/low/close (float)\n",
    "    \"\"\"\n",
    "    endpoint_slug = \"futures_funding_rate_history\"\n",
    "\n",
    "    df = _coinglass_get_dataframe(\n",
    "        endpoint=\"/futures/funding-rate/history\",\n",
    "        api_key=api_key,\n",
    "        params={\"exchange\": exchange, \"symbol\": symbol, \"interval\": interval},\n",
    "    )\n",
    "\n",
    "    # time -> date\n",
    "    if \"time\" in df.columns:\n",
    "        df[\"date\"] = _coinglass_normalize_time_to_date(df[\"time\"])\n",
    "        df = df.drop(columns=[\"time\"])\n",
    "    else:\n",
    "        df[\"date\"] = pd.NA\n",
    "\n",
    "    # numeric fields (funding rate может быть отрицательным)\n",
    "    for col in [\"open\", \"high\", \"low\", \"close\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # prefix all except date\n",
    "    df = _prefix_columns(df, prefix=endpoint_slug, keep=(\"date\",))\n",
    "\n",
    "    cols = [\"date\"] + [c for c in df.columns if c != \"date\"]\n",
    "    df = df[cols].sort_values(\"date\", kind=\"stable\").reset_index(drop=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hD4usZH_GUsN",
    "outputId": "a942a74d-2bee-4d04-c089-d36c047db7b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date  futures_funding_rate_history__open  \\\n",
      "995  2026-01-16                            0.007373   \n",
      "996  2026-01-17                           -0.000183   \n",
      "997  2026-01-18                            0.003502   \n",
      "998  2026-01-19                            0.003523   \n",
      "999  2026-01-20                            0.010000   \n",
      "\n",
      "     futures_funding_rate_history__high  futures_funding_rate_history__low  \\\n",
      "995                            0.010000                          -0.000184   \n",
      "996                            0.006697                          -0.000930   \n",
      "997                            0.010000                           0.003461   \n",
      "998                            0.010000                          -0.003860   \n",
      "999                            0.010000                           0.005919   \n",
      "\n",
      "     futures_funding_rate_history__close  \n",
      "995                            -0.000183  \n",
      "996                             0.003502  \n",
      "997                             0.003523  \n",
      "998                             0.009816  \n",
      "999                             0.006919  \n"
     ]
    }
   ],
   "source": [
    "KEYS = \"8b16782a668f4eb48397ddf3d97020bd\"\n",
    "\n",
    "# READY ()\n",
    "df_funding = get_futures_funding_rate_history(\n",
    "    api_key=KEYS,\n",
    "    exchange=\"Binance\",\n",
    "    symbol=\"BTCUSDT\",\n",
    "    interval=\"1d\",\n",
    ")\n",
    "\n",
    "print(df_funding.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "OEEHjzNSGUph"
   },
   "outputs": [],
   "source": [
    "def get_futures_funding_rate_oi_weight_history(\n",
    "    api_key: str,\n",
    "    symbol: str = \"BTC\",\n",
    "    interval: str = \"1d\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Open interest-weighted funding rate OHLC history.\n",
    "    Endpoint:\n",
    "    /api/futures/funding-rate/oi-weight-history?symbol=...&interval=...\n",
    "\n",
    "    Возвращает DF:\n",
    "    date (YYYY-MM-DD),\n",
    "    futures_funding_rate_oi_weight_history__open/high/low/close (float)\n",
    "    \"\"\"\n",
    "    endpoint_slug = \"futures_funding_rate_oi_weight_history\"\n",
    "\n",
    "    df = _coinglass_get_dataframe(\n",
    "        endpoint=\"/futures/funding-rate/oi-weight-history\",\n",
    "        api_key=api_key,\n",
    "        params={\"symbol\": symbol, \"interval\": interval},\n",
    "    )\n",
    "\n",
    "    # time -> date\n",
    "    if \"time\" in df.columns:\n",
    "        df[\"date\"] = _coinglass_normalize_time_to_date(df[\"time\"])\n",
    "        df = df.drop(columns=[\"time\"])\n",
    "    else:\n",
    "        df[\"date\"] = pd.NA\n",
    "\n",
    "    # numeric fields\n",
    "    for col in [\"open\", \"high\", \"low\", \"close\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # prefix all except date\n",
    "    df = _prefix_columns(df, prefix=endpoint_slug, keep=(\"date\",))\n",
    "\n",
    "    cols = [\"date\"] + [c for c in df.columns if c != \"date\"]\n",
    "    df = df[cols].sort_values(\"date\", kind=\"stable\").reset_index(drop=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vdbavI1xGUoB",
    "outputId": "cf4a23bd-dfd2-47af-9a8d-17517582bf01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date  futures_funding_rate_oi_weight_history__open  \\\n",
      "995  2026-01-16                                      0.004545   \n",
      "996  2026-01-17                                      0.003044   \n",
      "997  2026-01-18                                      0.004012   \n",
      "998  2026-01-19                                      0.004201   \n",
      "999  2026-01-20                                      0.006082   \n",
      "\n",
      "     futures_funding_rate_oi_weight_history__high  \\\n",
      "995                                      0.007071   \n",
      "996                                      0.005962   \n",
      "997                                      0.008487   \n",
      "998                                      0.006803   \n",
      "999                                      0.007606   \n",
      "\n",
      "     futures_funding_rate_oi_weight_history__low  \\\n",
      "995                                     0.002580   \n",
      "996                                     0.000215   \n",
      "997                                     0.003429   \n",
      "998                                    -0.006396   \n",
      "999                                     0.002470   \n",
      "\n",
      "     futures_funding_rate_oi_weight_history__close  \n",
      "995                                       0.003044  \n",
      "996                                       0.004012  \n",
      "997                                       0.004201  \n",
      "998                                       0.006803  \n",
      "999                                       0.004983  \n"
     ]
    }
   ],
   "source": [
    "KEYS = \"8b16782a668f4eb48397ddf3d97020bd\"\n",
    "\n",
    "# READY ()\n",
    "df_oi_weight_funding = get_futures_funding_rate_oi_weight_history(\n",
    "    api_key=KEYS,\n",
    "    symbol=\"BTC\",\n",
    "    interval=\"1d\",\n",
    ")\n",
    "print(df_oi_weight_funding.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "2MGF1Yt7GUmJ"
   },
   "outputs": [],
   "source": [
    "def get_futures_funding_rate_vol_weight_history(\n",
    "    api_key: str,\n",
    "    symbol: str = \"BTC\",\n",
    "    interval: str = \"1d\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Volume-weighted funding rate OHLC history.\n",
    "    Endpoint:\n",
    "    /api/futures/funding-rate/vol-weight-history?symbol=...&interval=...\n",
    "\n",
    "    Возвращает DF:\n",
    "    date (YYYY-MM-DD),\n",
    "    futures_funding_rate_vol_weight_history__open/high/low/close (float)\n",
    "    \"\"\"\n",
    "    endpoint_slug = \"futures_funding_rate_vol_weight_history\"\n",
    "\n",
    "    df = _coinglass_get_dataframe(\n",
    "        endpoint=\"/futures/funding-rate/vol-weight-history\",\n",
    "        api_key=api_key,\n",
    "        params={\"symbol\": symbol, \"interval\": interval},\n",
    "    )\n",
    "\n",
    "    # time -> date\n",
    "    if \"time\" in df.columns:\n",
    "        df[\"date\"] = _coinglass_normalize_time_to_date(df[\"time\"])\n",
    "        df = df.drop(columns=[\"time\"])\n",
    "    else:\n",
    "        df[\"date\"] = pd.NA\n",
    "\n",
    "    # numeric fields\n",
    "    for col in [\"open\", \"high\", \"low\", \"close\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # prefix all except date\n",
    "    df = _prefix_columns(df, prefix=endpoint_slug, keep=(\"date\",))\n",
    "\n",
    "    cols = [\"date\"] + [c for c in df.columns if c != \"date\"]\n",
    "    df = df[cols].sort_values(\"date\", kind=\"stable\").reset_index(drop=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ReFL-A2XGUiq",
    "outputId": "6d9b1061-9a83-4aa6-960e-e392d7bfcab2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date  futures_funding_rate_vol_weight_history__open  \\\n",
      "995  2026-01-16                                       0.003279   \n",
      "996  2026-01-17                                       0.001963   \n",
      "997  2026-01-18                                       0.003641   \n",
      "998  2026-01-19                                       0.003413   \n",
      "999  2026-01-20                                       0.005898   \n",
      "\n",
      "     futures_funding_rate_vol_weight_history__high  \\\n",
      "995                                       0.006154   \n",
      "996                                       0.005629   \n",
      "997                                       0.008404   \n",
      "998                                       0.005898   \n",
      "999                                       0.005898   \n",
      "\n",
      "     futures_funding_rate_vol_weight_history__low  \\\n",
      "995                                      0.001963   \n",
      "996                                     -0.000284   \n",
      "997                                      0.002763   \n",
      "998                                     -0.006567   \n",
      "999                                      0.005898   \n",
      "\n",
      "     futures_funding_rate_vol_weight_history__close  \n",
      "995                                        0.001963  \n",
      "996                                        0.003641  \n",
      "997                                        0.003413  \n",
      "998                                        0.005898  \n",
      "999                                        0.005898  \n"
     ]
    }
   ],
   "source": [
    "KEYS = \"8b16782a668f4eb48397ddf3d97020bd\"\n",
    "\n",
    "# READY ()\n",
    "df_vol_weight_funding = get_futures_funding_rate_vol_weight_history(\n",
    "    api_key=KEYS,\n",
    "    symbol=\"BTC\",\n",
    "    interval=\"1d\",\n",
    ")\n",
    "\n",
    "print(df_vol_weight_funding.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "uNNSik23GUgP"
   },
   "outputs": [],
   "source": [
    "def get_futures_global_long_short_account_ratio_history(\n",
    "    api_key: str,\n",
    "    exchange: str = \"Binance\",\n",
    "    symbol: str = \"BTCUSDT\",\n",
    "    interval: str = \"1d\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Global long/short account ratio history (accounts) for a trading pair on an exchange.\n",
    "    Endpoint:\n",
    "    /api/futures/global-long-short-account-ratio/history?exchange=...&symbol=...&interval=...\n",
    "\n",
    "    Возвращает DF:\n",
    "    date (YYYY-MM-DD),\n",
    "    futures_global_long_short_account_ratio_history__global_account_long_percent\n",
    "    futures_global_long_short_account_ratio_history__global_account_short_percent\n",
    "    futures_global_long_short_account_ratio_history__global_account_long_short_ratio\n",
    "    \"\"\"\n",
    "    endpoint_slug = \"futures_global_long_short_account_ratio_history\"\n",
    "\n",
    "    df = _coinglass_get_dataframe(\n",
    "        endpoint=\"/futures/global-long-short-account-ratio/history\",\n",
    "        api_key=api_key,\n",
    "        params={\"exchange\": exchange, \"symbol\": symbol, \"interval\": interval},\n",
    "    )\n",
    "\n",
    "    # time -> date\n",
    "    if \"time\" in df.columns:\n",
    "        df[\"date\"] = _coinglass_normalize_time_to_date(df[\"time\"])\n",
    "        df = df.drop(columns=[\"time\"])\n",
    "    else:\n",
    "        df[\"date\"] = pd.NA\n",
    "\n",
    "    # numeric fields (в примере уже числа, но на всякий случай)\n",
    "    numeric_cols = [\n",
    "        \"global_account_long_percent\",\n",
    "        \"global_account_short_percent\",\n",
    "        \"global_account_long_short_ratio\",\n",
    "    ]\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # prefix all except date\n",
    "    df = _prefix_columns(df, prefix=endpoint_slug, keep=(\"date\",))\n",
    "\n",
    "    cols = [\"date\"] + [c for c in df.columns if c != \"date\"]\n",
    "    df = df[cols].sort_values(\"date\", kind=\"stable\").reset_index(drop=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "id": "6rSoo9IKGUeL",
    "outputId": "6a9f3c1d-df73-4dca-94a8-65447a35a6bc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>futures_global_long_short_account_ratio_history__global_account_long_percent</th>\n",
       "      <th>futures_global_long_short_account_ratio_history__global_account_short_percent</th>\n",
       "      <th>futures_global_long_short_account_ratio_history__global_account_long_short_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2026-01-16</td>\n",
       "      <td>53.32</td>\n",
       "      <td>46.68</td>\n",
       "      <td>1.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2026-01-17</td>\n",
       "      <td>56.43</td>\n",
       "      <td>43.57</td>\n",
       "      <td>1.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2026-01-18</td>\n",
       "      <td>57.65</td>\n",
       "      <td>42.35</td>\n",
       "      <td>1.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>60.20</td>\n",
       "      <td>39.80</td>\n",
       "      <td>1.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2026-01-20</td>\n",
       "      <td>70.57</td>\n",
       "      <td>29.43</td>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  \\\n",
       "995  2026-01-16   \n",
       "996  2026-01-17   \n",
       "997  2026-01-18   \n",
       "998  2026-01-19   \n",
       "999  2026-01-20   \n",
       "\n",
       "     futures_global_long_short_account_ratio_history__global_account_long_percent  \\\n",
       "995                                              53.32                              \n",
       "996                                              56.43                              \n",
       "997                                              57.65                              \n",
       "998                                              60.20                              \n",
       "999                                              70.57                              \n",
       "\n",
       "     futures_global_long_short_account_ratio_history__global_account_short_percent  \\\n",
       "995                                              46.68                               \n",
       "996                                              43.57                               \n",
       "997                                              42.35                               \n",
       "998                                              39.80                               \n",
       "999                                              29.43                               \n",
       "\n",
       "     futures_global_long_short_account_ratio_history__global_account_long_short_ratio  \n",
       "995                                               1.14                                 \n",
       "996                                               1.30                                 \n",
       "997                                               1.36                                 \n",
       "998                                               1.51                                 \n",
       "999                                               2.40                                 "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KEYS = \"8b16782a668f4eb48397ddf3d97020bd\"\n",
    "\n",
    "# READY ()\n",
    "df_ls_accounts = get_futures_global_long_short_account_ratio_history(\n",
    "    api_key=KEYS,\n",
    "    exchange=\"Binance\",\n",
    "    symbol=\"BTCUSDT\",\n",
    "    interval=\"1d\",\n",
    ")\n",
    "\n",
    "df_ls_accounts.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "-5oqJRznGUb7"
   },
   "outputs": [],
   "source": [
    "def get_futures_top_long_short_account_ratio_history(\n",
    "    api_key: str,\n",
    "    exchange: str = \"Binance\",\n",
    "    symbol: str = \"BTCUSDT\",\n",
    "    interval: str = \"1d\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Top traders long/short account ratio history for a trading pair on an exchange.\n",
    "    Endpoint:\n",
    "    /api/futures/top-long-short-account-ratio/history?exchange=...&symbol=...&interval=...\n",
    "\n",
    "    Возвращает DF:\n",
    "    date (YYYY-MM-DD),\n",
    "    futures_top_long_short_account_ratio_history__top_account_long_percent\n",
    "    futures_top_long_short_account_ratio_history__top_account_short_percent\n",
    "    futures_top_long_short_account_ratio_history__top_account_long_short_ratio\n",
    "    \"\"\"\n",
    "    endpoint_slug = \"futures_top_long_short_account_ratio_history\"\n",
    "\n",
    "    df = _coinglass_get_dataframe(\n",
    "        endpoint=\"/futures/top-long-short-account-ratio/history\",\n",
    "        api_key=api_key,\n",
    "        params={\"exchange\": exchange, \"symbol\": symbol, \"interval\": interval},\n",
    "    )\n",
    "\n",
    "    # time -> date\n",
    "    if \"time\" in df.columns:\n",
    "        df[\"date\"] = _coinglass_normalize_time_to_date(df[\"time\"])\n",
    "        df = df.drop(columns=[\"time\"])\n",
    "    else:\n",
    "        df[\"date\"] = pd.NA\n",
    "\n",
    "    # numeric fields (в примере числа, но нормализуем на всякий случай)\n",
    "    numeric_cols = [\n",
    "        \"top_account_long_percent\",\n",
    "        \"top_account_short_percent\",\n",
    "        \"top_account_long_short_ratio\",\n",
    "    ]\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # prefix all except date\n",
    "    df = _prefix_columns(df, prefix=endpoint_slug, keep=(\"date\",))\n",
    "\n",
    "    cols = [\"date\"] + [c for c in df.columns if c != \"date\"]\n",
    "    df = df[cols].sort_values(\"date\", kind=\"stable\").reset_index(drop=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "2DCqE5jkJ4SU",
    "outputId": "ff6fa1bf-f122-4024-ee7b-3c131e2e2093"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>futures_top_long_short_account_ratio_history__top_account_long_percent</th>\n",
       "      <th>futures_top_long_short_account_ratio_history__top_account_short_percent</th>\n",
       "      <th>futures_top_long_short_account_ratio_history__top_account_long_short_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2026-01-16</td>\n",
       "      <td>57.11</td>\n",
       "      <td>42.89</td>\n",
       "      <td>1.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2026-01-17</td>\n",
       "      <td>59.43</td>\n",
       "      <td>40.57</td>\n",
       "      <td>1.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2026-01-18</td>\n",
       "      <td>60.62</td>\n",
       "      <td>39.38</td>\n",
       "      <td>1.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>63.32</td>\n",
       "      <td>36.68</td>\n",
       "      <td>1.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2026-01-20</td>\n",
       "      <td>73.20</td>\n",
       "      <td>26.80</td>\n",
       "      <td>2.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  \\\n",
       "995  2026-01-16   \n",
       "996  2026-01-17   \n",
       "997  2026-01-18   \n",
       "998  2026-01-19   \n",
       "999  2026-01-20   \n",
       "\n",
       "     futures_top_long_short_account_ratio_history__top_account_long_percent  \\\n",
       "995                                              57.11                        \n",
       "996                                              59.43                        \n",
       "997                                              60.62                        \n",
       "998                                              63.32                        \n",
       "999                                              73.20                        \n",
       "\n",
       "     futures_top_long_short_account_ratio_history__top_account_short_percent  \\\n",
       "995                                              42.89                         \n",
       "996                                              40.57                         \n",
       "997                                              39.38                         \n",
       "998                                              36.68                         \n",
       "999                                              26.80                         \n",
       "\n",
       "     futures_top_long_short_account_ratio_history__top_account_long_short_ratio  \n",
       "995                                               1.33                           \n",
       "996                                               1.47                           \n",
       "997                                               1.54                           \n",
       "998                                               1.73                           \n",
       "999                                               2.73                           "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KEYS = \"8b16782a668f4eb48397ddf3d97020bd\"\n",
    "\n",
    "# READY\n",
    "df_top_ls_accounts = get_futures_top_long_short_account_ratio_history(\n",
    "    api_key=KEYS,\n",
    "    exchange=\"Binance\",\n",
    "    symbol=\"BTCUSDT\",\n",
    "    interval=\"1d\",\n",
    ")\n",
    "\n",
    "df_top_ls_accounts.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "44gKpZ_oJ4Ph"
   },
   "outputs": [],
   "source": [
    "def get_futures_top_long_short_position_ratio_history(\n",
    "    api_key: str,\n",
    "    exchange: str = \"Binance\",\n",
    "    symbol: str = \"BTCUSDT\",\n",
    "    interval: str = \"1d\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Top traders long/short POSITION ratio history for a trading pair on an exchange.\n",
    "    Endpoint:\n",
    "    /api/futures/top-long-short-position-ratio/history?exchange=...&symbol=...&interval=...\n",
    "\n",
    "    Возвращает DF:\n",
    "    date (YYYY-MM-DD),\n",
    "    futures_top_long_short_position_ratio_history__top_position_long_percent\n",
    "    futures_top_long_short_position_ratio_history__top_position_short_percent\n",
    "    futures_top_long_short_position_ratio_history__top_position_long_short_ratio\n",
    "    \"\"\"\n",
    "    endpoint_slug = \"futures_top_long_short_position_ratio_history\"\n",
    "\n",
    "    df = _coinglass_get_dataframe(\n",
    "        endpoint=\"/futures/top-long-short-position-ratio/history\",\n",
    "        api_key=api_key,\n",
    "        params={\"exchange\": exchange, \"symbol\": symbol, \"interval\": interval},\n",
    "    )\n",
    "\n",
    "    # time -> date\n",
    "    if \"time\" in df.columns:\n",
    "        df[\"date\"] = _coinglass_normalize_time_to_date(df[\"time\"])\n",
    "        df = df.drop(columns=[\"time\"])\n",
    "    else:\n",
    "        df[\"date\"] = pd.NA\n",
    "\n",
    "    # numeric fields\n",
    "    numeric_cols = [\n",
    "        \"top_position_long_percent\",\n",
    "        \"top_position_short_percent\",\n",
    "        \"top_position_long_short_ratio\",\n",
    "    ]\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # prefix all except date\n",
    "    df = _prefix_columns(df, prefix=endpoint_slug, keep=(\"date\",))\n",
    "\n",
    "    cols = [\"date\"] + [c for c in df.columns if c != \"date\"]\n",
    "    df = df[cols].sort_values(\"date\", kind=\"stable\").reset_index(drop=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "UvE-LzAxJ4NZ",
    "outputId": "ed71dd8d-f58e-4748-eb2a-da16045846d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>futures_top_long_short_position_ratio_history__top_position_long_percent</th>\n",
       "      <th>futures_top_long_short_position_ratio_history__top_position_short_percent</th>\n",
       "      <th>futures_top_long_short_position_ratio_history__top_position_long_short_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2026-01-16</td>\n",
       "      <td>66.62</td>\n",
       "      <td>33.38</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2026-01-17</td>\n",
       "      <td>66.23</td>\n",
       "      <td>33.77</td>\n",
       "      <td>1.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2026-01-18</td>\n",
       "      <td>67.15</td>\n",
       "      <td>32.85</td>\n",
       "      <td>2.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>68.10</td>\n",
       "      <td>31.90</td>\n",
       "      <td>2.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2026-01-20</td>\n",
       "      <td>68.85</td>\n",
       "      <td>31.15</td>\n",
       "      <td>2.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  \\\n",
       "995  2026-01-16   \n",
       "996  2026-01-17   \n",
       "997  2026-01-18   \n",
       "998  2026-01-19   \n",
       "999  2026-01-20   \n",
       "\n",
       "     futures_top_long_short_position_ratio_history__top_position_long_percent  \\\n",
       "995                                              66.62                          \n",
       "996                                              66.23                          \n",
       "997                                              67.15                          \n",
       "998                                              68.10                          \n",
       "999                                              68.85                          \n",
       "\n",
       "     futures_top_long_short_position_ratio_history__top_position_short_percent  \\\n",
       "995                                              33.38                           \n",
       "996                                              33.77                           \n",
       "997                                              32.85                           \n",
       "998                                              31.90                           \n",
       "999                                              31.15                           \n",
       "\n",
       "     futures_top_long_short_position_ratio_history__top_position_long_short_ratio  \n",
       "995                                               2.00                             \n",
       "996                                               1.96                             \n",
       "997                                               2.04                             \n",
       "998                                               2.14                             \n",
       "999                                               2.21                             "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KEYS = \"8b16782a668f4eb48397ddf3d97020bd\"\n",
    "\n",
    "# READY ()\n",
    "df_top_ls_positions = get_futures_top_long_short_position_ratio_history(\n",
    "    api_key=KEYS,\n",
    "    exchange=\"Binance\",\n",
    "    symbol=\"BTCUSDT\",\n",
    "    interval=\"1d\",\n",
    ")\n",
    "\n",
    "rows, cols = df_top_ls_positions.shape\n",
    "print(rows)\n",
    "df_top_ls_positions.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "iAaDOmx7J4K1"
   },
   "outputs": [],
   "source": [
    "def get_futures_v2_net_position_history(\n",
    "    api_key: str,\n",
    "    exchange: str = \"Binance\",\n",
    "    symbol: str = \"BTCUSDT\",\n",
    "    interval: str = \"1d\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Futures v2 net position history (net long/short change).\n",
    "    Endpoint:\n",
    "    /api/futures/v2/net-position/history?exchange=...&symbol=...&interval=...\n",
    "\n",
    "    Возвращает DF:\n",
    "    date (YYYY-MM-DD),\n",
    "    futures_v2_net_position_history__net_long_change\n",
    "    futures_v2_net_position_history__net_short_change\n",
    "    \"\"\"\n",
    "    endpoint_slug = \"futures_v2_net_position_history\"\n",
    "\n",
    "    df = _coinglass_get_dataframe(\n",
    "        endpoint=\"/futures/v2/net-position/history\",\n",
    "        api_key=api_key,\n",
    "        params={\"exchange\": exchange, \"symbol\": symbol, \"interval\": interval},\n",
    "    )\n",
    "\n",
    "    # time -> date\n",
    "    if \"time\" in df.columns:\n",
    "        df[\"date\"] = _coinglass_normalize_time_to_date(df[\"time\"])\n",
    "        df = df.drop(columns=[\"time\"])\n",
    "    else:\n",
    "        df[\"date\"] = pd.NA\n",
    "\n",
    "    # numeric fields\n",
    "    for col in [\"net_long_change\", \"net_short_change\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # prefix all except date\n",
    "    df = _prefix_columns(df, prefix=endpoint_slug, keep=(\"date\",))\n",
    "\n",
    "    cols = [\"date\"] + [c for c in df.columns if c != \"date\"]\n",
    "    df = df[cols].sort_values(\"date\", kind=\"stable\").reset_index(drop=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "7BofIzUwJ4Ii",
    "outputId": "f679e1a4-631f-4460-c51f-33703f1e8b98"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>futures_v2_net_position_history__net_long_change</th>\n",
       "      <th>futures_v2_net_position_history__net_short_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2026-01-16</td>\n",
       "      <td>-3606.1295</td>\n",
       "      <td>932.6695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2026-01-17</td>\n",
       "      <td>108.8350</td>\n",
       "      <td>1290.0250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2026-01-18</td>\n",
       "      <td>-926.4995</td>\n",
       "      <td>555.5795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>-2106.0650</td>\n",
       "      <td>-1406.7950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2026-01-20</td>\n",
       "      <td>1943.4345</td>\n",
       "      <td>5869.3655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  futures_v2_net_position_history__net_long_change  \\\n",
       "995  2026-01-16                                        -3606.1295   \n",
       "996  2026-01-17                                          108.8350   \n",
       "997  2026-01-18                                         -926.4995   \n",
       "998  2026-01-19                                        -2106.0650   \n",
       "999  2026-01-20                                         1943.4345   \n",
       "\n",
       "     futures_v2_net_position_history__net_short_change  \n",
       "995                                           932.6695  \n",
       "996                                          1290.0250  \n",
       "997                                           555.5795  \n",
       "998                                         -1406.7950  \n",
       "999                                          5869.3655  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KEYS = \"8b16782a668f4eb48397ddf3d97020bd\"\n",
    "\n",
    "# READY ()\n",
    "df_net_pos = get_futures_v2_net_position_history(\n",
    "    api_key=KEYS,\n",
    "    exchange=\"Binance\",\n",
    "    symbol=\"BTCUSDT\",\n",
    "    interval=\"1d\",\n",
    ")\n",
    "\n",
    "df_net_pos.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "NILvcO8afJ7s"
   },
   "outputs": [],
   "source": [
    "def get_futures_liquidation_history(\n",
    "    api_key: str,\n",
    "    exchange: str = \"Binance\",\n",
    "    symbol: str = \"BTCUSDT\",\n",
    "    interval: str = \"1d\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Futures liquidation history (long/short liquidation in USD).\n",
    "    Endpoint:\n",
    "    /api/futures/liquidation/history?exchange=...&symbol=...&interval=...\n",
    "\n",
    "    Возвращает DF:\n",
    "    date (YYYY-MM-DD),\n",
    "    futures_liquidation_history__long_liquidation_usd\n",
    "    futures_liquidation_history__short_liquidation_usd\n",
    "    \"\"\"\n",
    "    endpoint_slug = \"futures_liquidation_history\"\n",
    "\n",
    "    df = _coinglass_get_dataframe(\n",
    "        endpoint=\"/futures/liquidation/history\",\n",
    "        api_key=api_key,\n",
    "        params={\"exchange\": exchange, \"symbol\": symbol, \"interval\": interval},\n",
    "    )\n",
    "\n",
    "    # time -> date\n",
    "    if \"time\" in df.columns:\n",
    "        df[\"date\"] = _coinglass_normalize_time_to_date(df[\"time\"])\n",
    "        df = df.drop(columns=[\"time\"])\n",
    "    else:\n",
    "        df[\"date\"] = pd.NA\n",
    "\n",
    "    # numeric fields (строки -> float)\n",
    "    for col in [\"long_liquidation_usd\", \"short_liquidation_usd\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # prefix all except date\n",
    "    df = _prefix_columns(df, prefix=endpoint_slug, keep=(\"date\",))\n",
    "\n",
    "    cols = [\"date\"] + [c for c in df.columns if c != \"date\"]\n",
    "    df = df[cols].sort_values(\"date\", kind=\"stable\").reset_index(drop=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "uUCeM0yDLv_H",
    "outputId": "2d1cd4f6-c276-4c9c-92b7-90c92bfb6540"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>futures_liquidation_history__long_liquidation_usd</th>\n",
       "      <th>futures_liquidation_history__short_liquidation_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2026-01-16</td>\n",
       "      <td>2.941486e+06</td>\n",
       "      <td>1.762504e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2026-01-17</td>\n",
       "      <td>8.299577e+05</td>\n",
       "      <td>9.511745e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2026-01-18</td>\n",
       "      <td>6.942629e+06</td>\n",
       "      <td>9.089290e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>8.867374e+06</td>\n",
       "      <td>2.163143e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2026-01-20</td>\n",
       "      <td>7.764482e+06</td>\n",
       "      <td>6.270925e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  futures_liquidation_history__long_liquidation_usd  \\\n",
       "995  2026-01-16                                       2.941486e+06   \n",
       "996  2026-01-17                                       8.299577e+05   \n",
       "997  2026-01-18                                       6.942629e+06   \n",
       "998  2026-01-19                                       8.867374e+06   \n",
       "999  2026-01-20                                       7.764482e+06   \n",
       "\n",
       "     futures_liquidation_history__short_liquidation_usd  \n",
       "995                                       1.762504e+06   \n",
       "996                                       9.511745e+05   \n",
       "997                                       9.089290e+05   \n",
       "998                                       2.163143e+06   \n",
       "999                                       6.270925e+05   "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KEYS = \"8b16782a668f4eb48397ddf3d97020bd\"\n",
    "\n",
    "# READY ()\n",
    "df_liq = get_futures_liquidation_history(\n",
    "    api_key=KEYS,\n",
    "    exchange=\"Binance\",\n",
    "    symbol=\"BTCUSDT\",\n",
    "    interval=\"1d\",\n",
    ")\n",
    "\n",
    "df_liq.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Xju7Oz0XLwBM"
   },
   "outputs": [],
   "source": [
    "def get_futures_liquidation_aggregated_history(\n",
    "    api_key: str,\n",
    "    exchange_list: str = \"Binance\",\n",
    "    symbol: str = \"BTC\",\n",
    "    interval: str = \"1d\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aggregated liquidation history across multiple exchanges (long/short, USD).\n",
    "    Endpoint:\n",
    "    /api/futures/liquidation/aggregated-history?exchange_list=...&symbol=...&interval=...\n",
    "\n",
    "    Возвращает DF:\n",
    "    date (YYYY-MM-DD),\n",
    "    futures_liquidation_aggregated_history__aggregated_long_liquidation_usd\n",
    "    futures_liquidation_aggregated_history__aggregated_short_liquidation_usd\n",
    "    \"\"\"\n",
    "    endpoint_slug = \"futures_liquidation_aggregated_history\"\n",
    "\n",
    "    df = _coinglass_get_dataframe(\n",
    "        endpoint=\"/futures/liquidation/aggregated-history\",\n",
    "        api_key=api_key,\n",
    "        params={\"exchange_list\": exchange_list, \"symbol\": symbol, \"interval\": interval},\n",
    "    )\n",
    "\n",
    "    # time -> date\n",
    "    if \"time\" in df.columns:\n",
    "        df[\"date\"] = _coinglass_normalize_time_to_date(df[\"time\"])\n",
    "        df = df.drop(columns=[\"time\"])\n",
    "    else:\n",
    "        df[\"date\"] = pd.NA\n",
    "\n",
    "    # numeric fields (в примере числа, но приводим на всякий случай)\n",
    "    for col in [\"aggregated_long_liquidation_usd\", \"aggregated_short_liquidation_usd\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # prefix all except date\n",
    "    df = _prefix_columns(df, prefix=endpoint_slug, keep=(\"date\",))\n",
    "\n",
    "    cols = [\"date\"] + [c for c in df.columns if c != \"date\"]\n",
    "    df = df[cols].sort_values(\"date\", kind=\"stable\").reset_index(drop=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "KNGRuJW7LwDI",
    "outputId": "ff02f575-2f17-47b1-b1ac-acfa1edc2b69"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>futures_liquidation_aggregated_history__aggregated_long_liquidation_usd</th>\n",
       "      <th>futures_liquidation_aggregated_history__aggregated_short_liquidation_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2026-01-16</td>\n",
       "      <td>3.380796e+06</td>\n",
       "      <td>1.874804e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2026-01-17</td>\n",
       "      <td>8.898883e+05</td>\n",
       "      <td>1.008533e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2026-01-18</td>\n",
       "      <td>8.002196e+06</td>\n",
       "      <td>1.085174e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>1.217485e+07</td>\n",
       "      <td>2.571681e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2026-01-20</td>\n",
       "      <td>1.023435e+07</td>\n",
       "      <td>6.988309e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  \\\n",
       "995  2026-01-16   \n",
       "996  2026-01-17   \n",
       "997  2026-01-18   \n",
       "998  2026-01-19   \n",
       "999  2026-01-20   \n",
       "\n",
       "     futures_liquidation_aggregated_history__aggregated_long_liquidation_usd  \\\n",
       "995                                       3.380796e+06                         \n",
       "996                                       8.898883e+05                         \n",
       "997                                       8.002196e+06                         \n",
       "998                                       1.217485e+07                         \n",
       "999                                       1.023435e+07                         \n",
       "\n",
       "     futures_liquidation_aggregated_history__aggregated_short_liquidation_usd  \n",
       "995                                       1.874804e+06                         \n",
       "996                                       1.008533e+06                         \n",
       "997                                       1.085174e+06                         \n",
       "998                                       2.571681e+06                         \n",
       "999                                       6.988309e+05                         "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KEYS = \"8b16782a668f4eb48397ddf3d97020bd\"\n",
    "\n",
    "# READY ()\n",
    "df_liq_agg = get_futures_liquidation_aggregated_history(\n",
    "    api_key=KEYS,\n",
    "    exchange_list=\"Binance\",\n",
    "    symbol=\"BTC\",\n",
    "    interval=\"1d\",\n",
    ")\n",
    "\n",
    "df_liq_agg.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "clJFKJvMLwE_"
   },
   "outputs": [],
   "source": [
    "def get_futures_orderbook_ask_bids_history(\n",
    "    api_key: str,\n",
    "    exchange: str = \"Binance\",\n",
    "    symbol: str = \"BTCUSDT\",\n",
    "    interval: str = \"1d\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Futures orderbook ask/bids history (total bid/ask volumes + quantities).\n",
    "    Endpoint:\n",
    "    /api/futures/orderbook/ask-bids-history?exchange=...&symbol=...&interval=...\n",
    "\n",
    "    Возвращает DF:\n",
    "    date (YYYY-MM-DD),\n",
    "    futures_orderbook_ask_bids_history__bids_usd\n",
    "    futures_orderbook_ask_bids_history__bids_quantity\n",
    "    futures_orderbook_ask_bids_history__asks_usd\n",
    "    futures_orderbook_ask_bids_history__asks_quantity\n",
    "    \"\"\"\n",
    "    endpoint_slug = \"futures_orderbook_ask_bids_history\"\n",
    "\n",
    "    df = _coinglass_get_dataframe(\n",
    "        endpoint=\"/futures/orderbook/ask-bids-history\",\n",
    "        api_key=api_key,\n",
    "        params={\"exchange\": exchange, \"symbol\": symbol, \"interval\": interval},\n",
    "    )\n",
    "\n",
    "    # time -> date\n",
    "    if \"time\" in df.columns:\n",
    "        df[\"date\"] = _coinglass_normalize_time_to_date(df[\"time\"])\n",
    "        df = df.drop(columns=[\"time\"])\n",
    "    else:\n",
    "        df[\"date\"] = pd.NA\n",
    "\n",
    "    # numeric fields (на всякий случай приводим все 4 поля)\n",
    "    for col in [\"bids_usd\", \"bids_quantity\", \"asks_usd\", \"asks_quantity\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # prefix all except date\n",
    "    df = _prefix_columns(df, prefix=endpoint_slug, keep=(\"date\",))\n",
    "\n",
    "    cols = [\"date\"] + [c for c in df.columns if c != \"date\"]\n",
    "    df = df[cols].sort_values(\"date\", kind=\"stable\").reset_index(drop=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "2grt8RClMg6_",
    "outputId": "e4f01288-6c6a-43e4-b422-1f0ca4d8919d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>futures_orderbook_ask_bids_history__bids_usd</th>\n",
       "      <th>futures_orderbook_ask_bids_history__bids_quantity</th>\n",
       "      <th>futures_orderbook_ask_bids_history__asks_usd</th>\n",
       "      <th>futures_orderbook_ask_bids_history__asks_quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>2026-01-16</td>\n",
       "      <td>1.784007e+08</td>\n",
       "      <td>1875.911</td>\n",
       "      <td>1.296571e+08</td>\n",
       "      <td>1351.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>2026-01-17</td>\n",
       "      <td>1.276909e+08</td>\n",
       "      <td>1342.669</td>\n",
       "      <td>1.883437e+08</td>\n",
       "      <td>1964.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>2026-01-18</td>\n",
       "      <td>2.543666e+08</td>\n",
       "      <td>2688.808</td>\n",
       "      <td>1.764464e+08</td>\n",
       "      <td>1846.565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>2.297797e+08</td>\n",
       "      <td>2464.993</td>\n",
       "      <td>1.390454e+08</td>\n",
       "      <td>1480.272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>2026-01-20</td>\n",
       "      <td>3.144600e+08</td>\n",
       "      <td>3463.554</td>\n",
       "      <td>2.055919e+08</td>\n",
       "      <td>2244.440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  futures_orderbook_ask_bids_history__bids_usd  \\\n",
       "631  2026-01-16                                  1.784007e+08   \n",
       "632  2026-01-17                                  1.276909e+08   \n",
       "633  2026-01-18                                  2.543666e+08   \n",
       "634  2026-01-19                                  2.297797e+08   \n",
       "635  2026-01-20                                  3.144600e+08   \n",
       "\n",
       "     futures_orderbook_ask_bids_history__bids_quantity  \\\n",
       "631                                           1875.911   \n",
       "632                                           1342.669   \n",
       "633                                           2688.808   \n",
       "634                                           2464.993   \n",
       "635                                           3463.554   \n",
       "\n",
       "     futures_orderbook_ask_bids_history__asks_usd  \\\n",
       "631                                  1.296571e+08   \n",
       "632                                  1.883437e+08   \n",
       "633                                  1.764464e+08   \n",
       "634                                  1.390454e+08   \n",
       "635                                  2.055919e+08   \n",
       "\n",
       "     futures_orderbook_ask_bids_history__asks_quantity  \n",
       "631                                           1351.176  \n",
       "632                                           1964.155  \n",
       "633                                           1846.565  \n",
       "634                                           1480.272  \n",
       "635                                           2244.440  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KEYS = \"8b16782a668f4eb48397ddf3d97020bd\"\n",
    "\n",
    "# REEADY ()\n",
    "df_ob = get_futures_orderbook_ask_bids_history(\n",
    "    api_key=KEYS,\n",
    "    exchange=\"Binance\",\n",
    "    symbol=\"BTCUSDT\",\n",
    "    interval=\"1d\",\n",
    ")\n",
    "\n",
    "df_ob.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "ymn52yuyLwG4"
   },
   "outputs": [],
   "source": [
    "def get_futures_orderbook_aggregated_ask_bids_history(\n",
    "    api_key: str,\n",
    "    exchange_list: str = \"Binance\",\n",
    "    symbol: str = \"BTC\",\n",
    "    interval: str = \"1d\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aggregated futures orderbook ask/bids history (total bid/ask volumes + quantities).\n",
    "    Endpoint:\n",
    "    /api/futures/orderbook/aggregated-ask-bids-history?exchange_list=...&symbol=...&interval=...\n",
    "\n",
    "    Возвращает DF:\n",
    "    date (YYYY-MM-DD),\n",
    "    futures_orderbook_aggregated_ask_bids_history__aggregated_bids_usd\n",
    "    futures_orderbook_aggregated_ask_bids_history__aggregated_bids_quantity\n",
    "    futures_orderbook_aggregated_ask_bids_history__aggregated_asks_usd\n",
    "    futures_orderbook_aggregated_ask_bids_history__aggregated_asks_quantity\n",
    "    \"\"\"\n",
    "    endpoint_slug = \"futures_orderbook_aggregated_ask_bids_history\"\n",
    "\n",
    "    df = _coinglass_get_dataframe(\n",
    "        endpoint=\"/futures/orderbook/aggregated-ask-bids-history\",\n",
    "        api_key=api_key,\n",
    "        params={\"exchange_list\": exchange_list, \"symbol\": symbol, \"interval\": interval},\n",
    "    )\n",
    "\n",
    "    # time -> date\n",
    "    if \"time\" in df.columns:\n",
    "        df[\"date\"] = _coinglass_normalize_time_to_date(df[\"time\"])\n",
    "        df = df.drop(columns=[\"time\"])\n",
    "    else:\n",
    "        df[\"date\"] = pd.NA\n",
    "\n",
    "    # numeric fields\n",
    "    numeric_cols = [\n",
    "        \"aggregated_bids_usd\",\n",
    "        \"aggregated_bids_quantity\",\n",
    "        \"aggregated_asks_usd\",\n",
    "        \"aggregated_asks_quantity\",\n",
    "    ]\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # prefix all except date\n",
    "    df = _prefix_columns(df, prefix=endpoint_slug, keep=(\"date\",))\n",
    "\n",
    "    cols = [\"date\"] + [c for c in df.columns if c != \"date\"]\n",
    "    df = df[cols].sort_values(\"date\", kind=\"stable\").reset_index(drop=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "Pj-CoSf3LwI0",
    "outputId": "3ddb186f-1790-4268-8fc3-de261ef3cc82"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>futures_orderbook_aggregated_ask_bids_history__aggregated_bids_usd</th>\n",
       "      <th>futures_orderbook_aggregated_ask_bids_history__aggregated_bids_quantity</th>\n",
       "      <th>futures_orderbook_aggregated_ask_bids_history__aggregated_asks_usd</th>\n",
       "      <th>futures_orderbook_aggregated_ask_bids_history__aggregated_asks_quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>2026-01-16</td>\n",
       "      <td>1.784007e+08</td>\n",
       "      <td>1875.911</td>\n",
       "      <td>1.296571e+08</td>\n",
       "      <td>1351.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>2026-01-17</td>\n",
       "      <td>1.276909e+08</td>\n",
       "      <td>1342.669</td>\n",
       "      <td>1.883437e+08</td>\n",
       "      <td>1964.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>2026-01-18</td>\n",
       "      <td>2.543666e+08</td>\n",
       "      <td>2688.808</td>\n",
       "      <td>1.764464e+08</td>\n",
       "      <td>1846.565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>2.297797e+08</td>\n",
       "      <td>2464.993</td>\n",
       "      <td>1.390454e+08</td>\n",
       "      <td>1480.272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>2026-01-20</td>\n",
       "      <td>2.894159e+08</td>\n",
       "      <td>3187.331</td>\n",
       "      <td>1.784938e+08</td>\n",
       "      <td>1949.266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  \\\n",
       "631  2026-01-16   \n",
       "632  2026-01-17   \n",
       "633  2026-01-18   \n",
       "634  2026-01-19   \n",
       "635  2026-01-20   \n",
       "\n",
       "     futures_orderbook_aggregated_ask_bids_history__aggregated_bids_usd  \\\n",
       "631                                       1.784007e+08                    \n",
       "632                                       1.276909e+08                    \n",
       "633                                       2.543666e+08                    \n",
       "634                                       2.297797e+08                    \n",
       "635                                       2.894159e+08                    \n",
       "\n",
       "     futures_orderbook_aggregated_ask_bids_history__aggregated_bids_quantity  \\\n",
       "631                                           1875.911                         \n",
       "632                                           1342.669                         \n",
       "633                                           2688.808                         \n",
       "634                                           2464.993                         \n",
       "635                                           3187.331                         \n",
       "\n",
       "     futures_orderbook_aggregated_ask_bids_history__aggregated_asks_usd  \\\n",
       "631                                       1.296571e+08                    \n",
       "632                                       1.883437e+08                    \n",
       "633                                       1.764464e+08                    \n",
       "634                                       1.390454e+08                    \n",
       "635                                       1.784938e+08                    \n",
       "\n",
       "     futures_orderbook_aggregated_ask_bids_history__aggregated_asks_quantity  \n",
       "631                                           1351.176                        \n",
       "632                                           1964.155                        \n",
       "633                                           1846.565                        \n",
       "634                                           1480.272                        \n",
       "635                                           1949.266                        "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KEYS = \"8b16782a668f4eb48397ddf3d97020bd\"\n",
    "\n",
    "# READY ()\n",
    "df_ob_agg = get_futures_orderbook_aggregated_ask_bids_history(\n",
    "    api_key=KEYS,\n",
    "    exchange_list=\"Binance\",\n",
    "    symbol=\"BTC\",\n",
    "    interval=\"1d\",\n",
    ")\n",
    "\n",
    "df_ob_agg.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "7KNluiz2LwKd"
   },
   "outputs": [],
   "source": [
    "def get_futures_v2_taker_buy_sell_volume_history(\n",
    "    api_key: str,\n",
    "    exchange: str = \"Binance\",\n",
    "    symbol: str = \"BTCUSDT\",\n",
    "    interval: str = \"1d\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Futures v2 taker buy/sell volume history (USD).\n",
    "    Endpoint:\n",
    "    /api/futures/v2/taker-buy-sell-volume/history?exchange=...&symbol=...&interval=...\n",
    "\n",
    "    Возвращает DF:\n",
    "    date (YYYY-MM-DD),\n",
    "    futures_v2_taker_buy_sell_volume_history__taker_buy_volume_usd\n",
    "    futures_v2_taker_buy_sell_volume_history__taker_sell_volume_usd\n",
    "    \"\"\"\n",
    "    endpoint_slug = \"futures_v2_taker_buy_sell_volume_history\"\n",
    "\n",
    "    df = _coinglass_get_dataframe(\n",
    "        endpoint=\"/futures/v2/taker-buy-sell-volume/history\",\n",
    "        api_key=api_key,\n",
    "        params={\"exchange\": exchange, \"symbol\": symbol, \"interval\": interval},\n",
    "    )\n",
    "\n",
    "    # time -> date\n",
    "    if \"time\" in df.columns:\n",
    "        df[\"date\"] = _coinglass_normalize_time_to_date(df[\"time\"])\n",
    "        df = df.drop(columns=[\"time\"])\n",
    "    else:\n",
    "        df[\"date\"] = pd.NA\n",
    "\n",
    "    # numeric fields (строки -> float)\n",
    "    for col in [\"taker_buy_volume_usd\", \"taker_sell_volume_usd\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # prefix all except date\n",
    "    df = _prefix_columns(df, prefix=endpoint_slug, keep=(\"date\",))\n",
    "\n",
    "    cols = [\"date\"] + [c for c in df.columns if c != \"date\"]\n",
    "    df = df[cols].sort_values(\"date\", kind=\"stable\").reset_index(drop=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "AAJxJqQ5LwMZ",
    "outputId": "60a28687-17b4-429d-ba01-a76af021c0e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>futures_v2_taker_buy_sell_volume_history__taker_buy_volume_usd</th>\n",
       "      <th>futures_v2_taker_buy_sell_volume_history__taker_sell_volume_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2026-01-16</td>\n",
       "      <td>4.600541e+09</td>\n",
       "      <td>5.031243e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2026-01-17</td>\n",
       "      <td>1.799159e+09</td>\n",
       "      <td>1.911601e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2026-01-18</td>\n",
       "      <td>2.897470e+09</td>\n",
       "      <td>3.035915e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>4.986798e+09</td>\n",
       "      <td>5.051363e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2026-01-20</td>\n",
       "      <td>2.931993e+09</td>\n",
       "      <td>3.290754e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  \\\n",
       "995  2026-01-16   \n",
       "996  2026-01-17   \n",
       "997  2026-01-18   \n",
       "998  2026-01-19   \n",
       "999  2026-01-20   \n",
       "\n",
       "     futures_v2_taker_buy_sell_volume_history__taker_buy_volume_usd  \\\n",
       "995                                       4.600541e+09                \n",
       "996                                       1.799159e+09                \n",
       "997                                       2.897470e+09                \n",
       "998                                       4.986798e+09                \n",
       "999                                       2.931993e+09                \n",
       "\n",
       "     futures_v2_taker_buy_sell_volume_history__taker_sell_volume_usd  \n",
       "995                                       5.031243e+09                \n",
       "996                                       1.911601e+09                \n",
       "997                                       3.035915e+09                \n",
       "998                                       5.051363e+09                \n",
       "999                                       3.290754e+09                "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KEYS = \"8b16782a668f4eb48397ddf3d97020bd\"\n",
    "\n",
    "# READY ()\n",
    "df_taker = get_futures_v2_taker_buy_sell_volume_history(\n",
    "    api_key=KEYS,\n",
    "    exchange=\"Binance\",\n",
    "    symbol=\"BTCUSDT\",\n",
    "    interval=\"1d\",\n",
    ")\n",
    "\n",
    "df_taker.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "ODNOrrdl1ITn",
    "outputId": "8a853020-40d5-461b-9ed6-c07d62797fa2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>index_btc_lth_supply__price</th>\n",
       "      <th>index_btc_lth_supply__lth_supply</th>\n",
       "      <th>index_btc_lth_supply__supply_pct30</th>\n",
       "      <th>index_btc_lth_supply__supply_z180</th>\n",
       "      <th>index_btc_lth_supply__supply_slope14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5263</th>\n",
       "      <td>2026-01-15</td>\n",
       "      <td>95585.0</td>\n",
       "      <td>1.409609e+07</td>\n",
       "      <td>0.005179</td>\n",
       "      <td>-1.396726</td>\n",
       "      <td>1489.770476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5264</th>\n",
       "      <td>2026-01-16</td>\n",
       "      <td>95516.0</td>\n",
       "      <td>1.412253e+07</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>-1.338588</td>\n",
       "      <td>2853.429168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5265</th>\n",
       "      <td>2026-01-17</td>\n",
       "      <td>95100.0</td>\n",
       "      <td>1.414097e+07</td>\n",
       "      <td>0.007259</td>\n",
       "      <td>-1.294035</td>\n",
       "      <td>3263.027330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5266</th>\n",
       "      <td>2026-01-18</td>\n",
       "      <td>93753.0</td>\n",
       "      <td>1.414158e+07</td>\n",
       "      <td>0.006081</td>\n",
       "      <td>-1.278217</td>\n",
       "      <td>3299.893078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5267</th>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>92558.0</td>\n",
       "      <td>1.414760e+07</td>\n",
       "      <td>0.007116</td>\n",
       "      <td>-1.254125</td>\n",
       "      <td>4084.215355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  index_btc_lth_supply__price  \\\n",
       "5263 2026-01-15                      95585.0   \n",
       "5264 2026-01-16                      95516.0   \n",
       "5265 2026-01-17                      95100.0   \n",
       "5266 2026-01-18                      93753.0   \n",
       "5267 2026-01-19                      92558.0   \n",
       "\n",
       "      index_btc_lth_supply__lth_supply  index_btc_lth_supply__supply_pct30  \\\n",
       "5263                      1.409609e+07                            0.005179   \n",
       "5264                      1.412253e+07                            0.007060   \n",
       "5265                      1.414097e+07                            0.007259   \n",
       "5266                      1.414158e+07                            0.006081   \n",
       "5267                      1.414760e+07                            0.007116   \n",
       "\n",
       "      index_btc_lth_supply__supply_z180  index_btc_lth_supply__supply_slope14  \n",
       "5263                          -1.396726                           1489.770476  \n",
       "5264                          -1.338588                           2853.429168  \n",
       "5265                          -1.294035                           3263.027330  \n",
       "5266                          -1.278217                           3299.893078  \n",
       "5267                          -1.254125                           4084.215355  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# READY\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "BTC_LTH_SUPPLY_URL = \"https://open-api-v4.coinglass.com/api/index/bitcoin-long-term-holder-supply\"\n",
    "\n",
    "\n",
    "def _get_coinglass_key(KEYS) -> str:\n",
    "    if isinstance(KEYS, str) and KEYS.strip():\n",
    "        return KEYS.strip()\n",
    "    if isinstance(KEYS, dict):\n",
    "        for k in (\"CG_API_KEY\", \"COINGLASS_API_KEY\", \"CG-API-KEY\", \"COINGLASS_KEY\", \"coinglass\"):\n",
    "            v = KEYS.get(k)\n",
    "            if isinstance(v, str) and v.strip():\n",
    "                return v.strip()\n",
    "    raise ValueError(\"CoinGlass API key not found. Set KEYS to API key string or dict containing it.\")\n",
    "\n",
    "\n",
    "def _parse_ms_or_s_to_date(ts: pd.Series) -> pd.Series:\n",
    "    t = pd.to_numeric(ts, errors=\"coerce\").astype(\"float64\")\n",
    "    is_seconds = t < 10_000_000_000\n",
    "    dt = pd.Series(pd.NaT, index=t.index, dtype=\"datetime64[ns]\")\n",
    "\n",
    "    if is_seconds.any():\n",
    "        dt.loc[is_seconds] = pd.to_datetime(t.loc[is_seconds], unit=\"s\", errors=\"coerce\")\n",
    "    if (~is_seconds).any():\n",
    "        dt.loc[~is_seconds] = pd.to_datetime(t.loc[~is_seconds], unit=\"ms\", errors=\"coerce\")\n",
    "\n",
    "    return dt.dt.normalize()\n",
    "\n",
    "\n",
    "def fetch_bitcoin_lth_supply_table(\n",
    "    KEYS,\n",
    "    pct_window: int = 30,\n",
    "    z_window: int = 180,\n",
    "    slope_window: int = 14,\n",
    "    timeout: int = 20,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch Bitcoin Long-Term Holder Supply + add 3 forecast-useful features.\n",
    "\n",
    "    Output columns:\n",
    "      - date\n",
    "      - index_btc_lth_supply__price\n",
    "      - index_btc_lth_supply__lth_supply\n",
    "      - index_btc_lth_supply__supply_pct{pct_window}\n",
    "      - index_btc_lth_supply__supply_z{z_window}\n",
    "      - index_btc_lth_supply__supply_slope{slope_window}\n",
    "    \"\"\"\n",
    "    api_key = _get_coinglass_key(KEYS)\n",
    "    headers = {\"accept\": \"application/json\", \"CG-API-KEY\": api_key}\n",
    "\n",
    "    r = requests.get(BTC_LTH_SUPPLY_URL, headers=headers, timeout=timeout)\n",
    "    r.raise_for_status()\n",
    "    j = r.json()\n",
    "\n",
    "    if str(j.get(\"code\")) != \"0\":\n",
    "        raise RuntimeError(f\"CoinGlass error: code={j.get('code')}, msg={j.get('msg')}\")\n",
    "\n",
    "    rows = j.get(\"data\") or []\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    cols = [\n",
    "        \"date\",\n",
    "        \"index_btc_lth_supply__price\",\n",
    "        \"index_btc_lth_supply__lth_supply\",\n",
    "        f\"index_btc_lth_supply__supply_pct{pct_window}\",\n",
    "        f\"index_btc_lth_supply__supply_z{z_window}\",\n",
    "        f\"index_btc_lth_supply__supply_slope{slope_window}\",\n",
    "    ]\n",
    "    if df.empty:\n",
    "        return pd.DataFrame(columns=cols)\n",
    "\n",
    "    df[\"date\"] = _parse_ms_or_s_to_date(df.get(\"timestamp\"))\n",
    "    df[\"index_btc_lth_supply__price\"] = pd.to_numeric(df.get(\"price\"), errors=\"coerce\")\n",
    "    df[\"index_btc_lth_supply__lth_supply\"] = pd.to_numeric(df.get(\"long_term_holder_supply\"), errors=\"coerce\")\n",
    "\n",
    "    out = (\n",
    "        df[[\"date\", \"index_btc_lth_supply__price\", \"index_btc_lth_supply__lth_supply\"]]\n",
    "        .dropna(subset=[\"date\"])\n",
    "        .sort_values(\"date\", kind=\"stable\")\n",
    "        .drop_duplicates(subset=[\"date\"], keep=\"last\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    s = out[\"index_btc_lth_supply__lth_supply\"].astype(float)\n",
    "\n",
    "    # Feature 1: pct change over N days (supply expansion/contraction proxy)\n",
    "    out[f\"index_btc_lth_supply__supply_pct{pct_window}\"] = s / s.shift(pct_window) - 1.0\n",
    "\n",
    "    # Feature 2: rolling z-score (regime-normalized supply)\n",
    "    minp = max(30, z_window // 3)\n",
    "    roll = s.rolling(z_window, min_periods=minp)\n",
    "    mu = roll.mean()\n",
    "    sd = roll.std(ddof=0).replace(0.0, np.nan)\n",
    "    out[f\"index_btc_lth_supply__supply_z{z_window}\"] = (s - mu) / sd\n",
    "\n",
    "    # Feature 3: slope / velocity\n",
    "    out[f\"index_btc_lth_supply__supply_slope{slope_window}\"] = s.diff(slope_window) / float(slope_window)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# Usage:\n",
    "# READY ()\n",
    "df_lth_supply = fetch_bitcoin_lth_supply_table(KEYS)\n",
    "df_lth_supply.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "2qJbq4HN1ih9",
    "outputId": "47fbe5a7-73aa-4822-9e0a-9acee5e5a1b2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>index_btc_active_addresses__price</th>\n",
       "      <th>index_btc_active_addresses__active_address_count</th>\n",
       "      <th>index_btc_active_addresses__aa_pct7</th>\n",
       "      <th>index_btc_active_addresses__aa_z180</th>\n",
       "      <th>index_btc_active_addresses__aa_slope14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5630</th>\n",
       "      <td>2026-01-15</td>\n",
       "      <td>96931.291383</td>\n",
       "      <td>727968</td>\n",
       "      <td>0.160745</td>\n",
       "      <td>0.314819</td>\n",
       "      <td>9929.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5631</th>\n",
       "      <td>2026-01-16</td>\n",
       "      <td>95554.099561</td>\n",
       "      <td>692650</td>\n",
       "      <td>0.016694</td>\n",
       "      <td>-0.213695</td>\n",
       "      <td>218.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5632</th>\n",
       "      <td>2026-01-17</td>\n",
       "      <td>95525.156843</td>\n",
       "      <td>604794</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>-1.500666</td>\n",
       "      <td>-2437.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5633</th>\n",
       "      <td>2026-01-18</td>\n",
       "      <td>95101.178945</td>\n",
       "      <td>551983</td>\n",
       "      <td>-0.001413</td>\n",
       "      <td>-2.236083</td>\n",
       "      <td>-5124.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5634</th>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>93655.672835</td>\n",
       "      <td>639528</td>\n",
       "      <td>-0.018707</td>\n",
       "      <td>-0.948688</td>\n",
       "      <td>-5316.857143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  index_btc_active_addresses__price  \\\n",
       "5630 2026-01-15                       96931.291383   \n",
       "5631 2026-01-16                       95554.099561   \n",
       "5632 2026-01-17                       95525.156843   \n",
       "5633 2026-01-18                       95101.178945   \n",
       "5634 2026-01-19                       93655.672835   \n",
       "\n",
       "      index_btc_active_addresses__active_address_count  \\\n",
       "5630                                            727968   \n",
       "5631                                            692650   \n",
       "5632                                            604794   \n",
       "5633                                            551983   \n",
       "5634                                            639528   \n",
       "\n",
       "      index_btc_active_addresses__aa_pct7  \\\n",
       "5630                             0.160745   \n",
       "5631                             0.016694   \n",
       "5632                             0.001892   \n",
       "5633                            -0.001413   \n",
       "5634                            -0.018707   \n",
       "\n",
       "      index_btc_active_addresses__aa_z180  \\\n",
       "5630                             0.314819   \n",
       "5631                            -0.213695   \n",
       "5632                            -1.500666   \n",
       "5633                            -2.236083   \n",
       "5634                            -0.948688   \n",
       "\n",
       "      index_btc_active_addresses__aa_slope14  \n",
       "5630                             9929.500000  \n",
       "5631                              218.571429  \n",
       "5632                            -2437.714286  \n",
       "5633                            -5124.000000  \n",
       "5634                            -5316.857143  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# READY\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "BTC_ACTIVE_ADDRESSES_URL = \"https://open-api-v4.coinglass.com/api/index/bitcoin-active-addresses\"\n",
    "\n",
    "\n",
    "def _get_coinglass_key(KEYS) -> str:\n",
    "    if isinstance(KEYS, str) and KEYS.strip():\n",
    "        return KEYS.strip()\n",
    "    if isinstance(KEYS, dict):\n",
    "        for k in (\"CG_API_KEY\", \"COINGLASS_API_KEY\", \"CG-API-KEY\", \"COINGLASS_KEY\", \"coinglass\"):\n",
    "            v = KEYS.get(k)\n",
    "            if isinstance(v, str) and v.strip():\n",
    "                return v.strip()\n",
    "    raise ValueError(\"CoinGlass API key not found. Set KEYS to API key string or dict containing it.\")\n",
    "\n",
    "\n",
    "def _parse_ms_or_s_to_date(ts: pd.Series) -> pd.Series:\n",
    "    t = pd.to_numeric(ts, errors=\"coerce\").astype(\"float64\")\n",
    "    is_seconds = t < 10_000_000_000\n",
    "    dt = pd.Series(pd.NaT, index=t.index, dtype=\"datetime64[ns]\")\n",
    "\n",
    "    if is_seconds.any():\n",
    "        dt.loc[is_seconds] = pd.to_datetime(t.loc[is_seconds], unit=\"s\", errors=\"coerce\")\n",
    "    if (~is_seconds).any():\n",
    "        dt.loc[~is_seconds] = pd.to_datetime(t.loc[~is_seconds], unit=\"ms\", errors=\"coerce\")\n",
    "\n",
    "    return dt.dt.normalize()\n",
    "\n",
    "\n",
    "def fetch_bitcoin_active_addresses_table(\n",
    "    KEYS,\n",
    "    pct_window: int = 7,\n",
    "    z_window: int = 180,\n",
    "    slope_window: int = 14,\n",
    "    timeout: int = 20,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch Bitcoin Active Addresses + add 3 forecast-useful features.\n",
    "\n",
    "    Output columns:\n",
    "      - date\n",
    "      - index_btc_active_addresses__price\n",
    "      - index_btc_active_addresses__active_address_count\n",
    "      - index_btc_active_addresses__aa_pct{pct_window}\n",
    "      - index_btc_active_addresses__aa_z{z_window}\n",
    "      - index_btc_active_addresses__aa_slope{slope_window}\n",
    "    \"\"\"\n",
    "    api_key = _get_coinglass_key(KEYS)\n",
    "    headers = {\"accept\": \"application/json\", \"CG-API-KEY\": api_key}\n",
    "\n",
    "    r = requests.get(BTC_ACTIVE_ADDRESSES_URL, headers=headers, timeout=timeout)\n",
    "    r.raise_for_status()\n",
    "    j = r.json()\n",
    "\n",
    "    if str(j.get(\"code\")) != \"0\":\n",
    "        raise RuntimeError(f\"CoinGlass error: code={j.get('code')}, msg={j.get('msg')}\")\n",
    "\n",
    "    rows = j.get(\"data\") or []\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    cols = [\n",
    "        \"date\",\n",
    "        \"index_btc_active_addresses__price\",\n",
    "        \"index_btc_active_addresses__active_address_count\",\n",
    "        f\"index_btc_active_addresses__aa_pct{pct_window}\",\n",
    "        f\"index_btc_active_addresses__aa_z{z_window}\",\n",
    "        f\"index_btc_active_addresses__aa_slope{slope_window}\",\n",
    "    ]\n",
    "    if df.empty:\n",
    "        return pd.DataFrame(columns=cols)\n",
    "\n",
    "    df[\"date\"] = _parse_ms_or_s_to_date(df.get(\"timestamp\"))\n",
    "    df[\"index_btc_active_addresses__price\"] = pd.to_numeric(df.get(\"price\"), errors=\"coerce\")\n",
    "    df[\"index_btc_active_addresses__active_address_count\"] = pd.to_numeric(df.get(\"active_address_count\"), errors=\"coerce\")\n",
    "\n",
    "    out = (\n",
    "        df[[\"date\", \"index_btc_active_addresses__price\", \"index_btc_active_addresses__active_address_count\"]]\n",
    "        .dropna(subset=[\"date\"])\n",
    "        .sort_values(\"date\", kind=\"stable\")\n",
    "        .drop_duplicates(subset=[\"date\"], keep=\"last\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    aa = out[\"index_btc_active_addresses__active_address_count\"].astype(float)\n",
    "\n",
    "    # Feature 1: short-horizon pct change (activity impulse)\n",
    "    out[f\"index_btc_active_addresses__aa_pct{pct_window}\"] = aa / aa.shift(pct_window) - 1.0\n",
    "\n",
    "    # Feature 2: rolling z-score (regime normalized activity)\n",
    "    minp = max(30, z_window // 3)\n",
    "    roll = aa.rolling(z_window, min_periods=minp)\n",
    "    mu = roll.mean()\n",
    "    sd = roll.std(ddof=0).replace(0.0, np.nan)\n",
    "    out[f\"index_btc_active_addresses__aa_z{z_window}\"] = (aa - mu) / sd\n",
    "\n",
    "    # Feature 3: slope / velocity\n",
    "    out[f\"index_btc_active_addresses__aa_slope{slope_window}\"] = aa.diff(slope_window) / float(slope_window)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# Usage: \n",
    "# READY ()\n",
    "df_aa = fetch_bitcoin_active_addresses_table(KEYS)\n",
    "df_aa.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "R_GZ2Ri-2Czh",
    "outputId": "4774f6a0-f271-4f9b-97e7-6ea882d82dff"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>index_btc_sth_supply__price</th>\n",
       "      <th>index_btc_sth_supply__sth_supply</th>\n",
       "      <th>index_btc_sth_supply__supply_pct30</th>\n",
       "      <th>index_btc_sth_supply__supply_z180</th>\n",
       "      <th>index_btc_sth_supply__supply_slope14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5263</th>\n",
       "      <td>2026-01-15</td>\n",
       "      <td>95585.0</td>\n",
       "      <td>5.880261e+06</td>\n",
       "      <td>-0.009992</td>\n",
       "      <td>1.411186</td>\n",
       "      <td>-1054.279405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5264</th>\n",
       "      <td>2026-01-16</td>\n",
       "      <td>95516.0</td>\n",
       "      <td>5.854234e+06</td>\n",
       "      <td>-0.014436</td>\n",
       "      <td>1.354913</td>\n",
       "      <td>-2421.063097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5265</th>\n",
       "      <td>2026-01-17</td>\n",
       "      <td>95100.0</td>\n",
       "      <td>5.836255e+06</td>\n",
       "      <td>-0.014960</td>\n",
       "      <td>1.311860</td>\n",
       "      <td>-2832.000544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5266</th>\n",
       "      <td>2026-01-18</td>\n",
       "      <td>93753.0</td>\n",
       "      <td>5.836088e+06</td>\n",
       "      <td>-0.012225</td>\n",
       "      <td>1.296515</td>\n",
       "      <td>-2869.982364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5267</th>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>92558.0</td>\n",
       "      <td>5.830535e+06</td>\n",
       "      <td>-0.014652</td>\n",
       "      <td>1.273229</td>\n",
       "      <td>-3650.323140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  index_btc_sth_supply__price  \\\n",
       "5263 2026-01-15                      95585.0   \n",
       "5264 2026-01-16                      95516.0   \n",
       "5265 2026-01-17                      95100.0   \n",
       "5266 2026-01-18                      93753.0   \n",
       "5267 2026-01-19                      92558.0   \n",
       "\n",
       "      index_btc_sth_supply__sth_supply  index_btc_sth_supply__supply_pct30  \\\n",
       "5263                      5.880261e+06                           -0.009992   \n",
       "5264                      5.854234e+06                           -0.014436   \n",
       "5265                      5.836255e+06                           -0.014960   \n",
       "5266                      5.836088e+06                           -0.012225   \n",
       "5267                      5.830535e+06                           -0.014652   \n",
       "\n",
       "      index_btc_sth_supply__supply_z180  index_btc_sth_supply__supply_slope14  \n",
       "5263                           1.411186                          -1054.279405  \n",
       "5264                           1.354913                          -2421.063097  \n",
       "5265                           1.311860                          -2832.000544  \n",
       "5266                           1.296515                          -2869.982364  \n",
       "5267                           1.273229                          -3650.323140  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# READY\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "BTC_STH_SUPPLY_URL = \"https://open-api-v4.coinglass.com/api/index/bitcoin-short-term-holder-supply\"\n",
    "\n",
    "\n",
    "def _get_coinglass_key(KEYS) -> str:\n",
    "    if isinstance(KEYS, str) and KEYS.strip():\n",
    "        return KEYS.strip()\n",
    "    if isinstance(KEYS, dict):\n",
    "        for k in (\"CG_API_KEY\", \"COINGLASS_API_KEY\", \"CG-API-KEY\", \"COINGLASS_KEY\", \"coinglass\"):\n",
    "            v = KEYS.get(k)\n",
    "            if isinstance(v, str) and v.strip():\n",
    "                return v.strip()\n",
    "    raise ValueError(\"CoinGlass API key not found. Set KEYS to API key string or dict containing it.\")\n",
    "\n",
    "\n",
    "def _parse_ms_or_s_to_date(ts: pd.Series) -> pd.Series:\n",
    "    t = pd.to_numeric(ts, errors=\"coerce\").astype(\"float64\")\n",
    "    is_seconds = t < 10_000_000_000\n",
    "    dt = pd.Series(pd.NaT, index=t.index, dtype=\"datetime64[ns]\")\n",
    "\n",
    "    if is_seconds.any():\n",
    "        dt.loc[is_seconds] = pd.to_datetime(t.loc[is_seconds], unit=\"s\", errors=\"coerce\")\n",
    "    if (~is_seconds).any():\n",
    "        dt.loc[~is_seconds] = pd.to_datetime(t.loc[~is_seconds], unit=\"ms\", errors=\"coerce\")\n",
    "\n",
    "    return dt.dt.normalize()\n",
    "\n",
    "\n",
    "def fetch_bitcoin_sth_supply_table(\n",
    "    KEYS,\n",
    "    pct_window: int = 30,\n",
    "    z_window: int = 180,\n",
    "    slope_window: int = 14,\n",
    "    timeout: int = 20,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch Bitcoin Short-Term Holder Supply + add 3 forecast-useful features.\n",
    "\n",
    "    Output columns:\n",
    "      - date\n",
    "      - index_btc_sth_supply__price\n",
    "      - index_btc_sth_supply__sth_supply\n",
    "      - index_btc_sth_supply__supply_pct{pct_window}\n",
    "      - index_btc_sth_supply__supply_z{z_window}\n",
    "      - index_btc_sth_supply__supply_slope{slope_window}\n",
    "    \"\"\"\n",
    "    api_key = _get_coinglass_key(KEYS)\n",
    "    headers = {\"accept\": \"application/json\", \"CG-API-KEY\": api_key}\n",
    "\n",
    "    r = requests.get(BTC_STH_SUPPLY_URL, headers=headers, timeout=timeout)\n",
    "    r.raise_for_status()\n",
    "    j = r.json()\n",
    "\n",
    "    if str(j.get(\"code\")) != \"0\":\n",
    "        raise RuntimeError(f\"CoinGlass error: code={j.get('code')}, msg={j.get('msg')}\")\n",
    "\n",
    "    rows = j.get(\"data\") or []\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    cols = [\n",
    "        \"date\",\n",
    "        \"index_btc_sth_supply__price\",\n",
    "        \"index_btc_sth_supply__sth_supply\",\n",
    "        f\"index_btc_sth_supply__supply_pct{pct_window}\",\n",
    "        f\"index_btc_sth_supply__supply_z{z_window}\",\n",
    "        f\"index_btc_sth_supply__supply_slope{slope_window}\",\n",
    "    ]\n",
    "    if df.empty:\n",
    "        return pd.DataFrame(columns=cols)\n",
    "\n",
    "    df[\"date\"] = _parse_ms_or_s_to_date(df.get(\"timestamp\"))\n",
    "    df[\"index_btc_sth_supply__price\"] = pd.to_numeric(df.get(\"price\"), errors=\"coerce\")\n",
    "    df[\"index_btc_sth_supply__sth_supply\"] = pd.to_numeric(df.get(\"short_term_holder_supply\"), errors=\"coerce\")\n",
    "\n",
    "    out = (\n",
    "        df[[\"date\", \"index_btc_sth_supply__price\", \"index_btc_sth_supply__sth_supply\"]]\n",
    "        .dropna(subset=[\"date\"])\n",
    "        .sort_values(\"date\", kind=\"stable\")\n",
    "        .drop_duplicates(subset=[\"date\"], keep=\"last\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    s = out[\"index_btc_sth_supply__sth_supply\"].astype(float)\n",
    "\n",
    "    # Feature 1: pct change over N days (distribution / accumulation proxy)\n",
    "    out[f\"index_btc_sth_supply__supply_pct{pct_window}\"] = s / s.shift(pct_window) - 1.0\n",
    "\n",
    "    # Feature 2: rolling z-score (regime-normalized supply)\n",
    "    minp = max(30, z_window // 3)\n",
    "    roll = s.rolling(z_window, min_periods=minp)\n",
    "    mu = roll.mean()\n",
    "    sd = roll.std(ddof=0).replace(0.0, np.nan)\n",
    "    out[f\"index_btc_sth_supply__supply_z{z_window}\"] = (s - mu) / sd\n",
    "\n",
    "    # Feature 3: slope / velocity\n",
    "    out[f\"index_btc_sth_supply__supply_slope{slope_window}\"] = s.diff(slope_window) / float(slope_window)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# Usage:\n",
    "# READY ()\n",
    "df_sth_supply = fetch_bitcoin_sth_supply_table(KEYS)\n",
    "df_sth_supply.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "QNOxUaWDNlx1"
   },
   "outputs": [],
   "source": [
    "# READY\n",
    "\n",
    "def get_futures_aggregated_taker_buy_sell_volume_history(\n",
    "    api_key: str,\n",
    "    exchange_list: str = \"Binance\",\n",
    "    symbol: str = \"BTC\",\n",
    "    interval: str = \"1d\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aggregated taker buy/sell volume history (USD) across multiple exchanges.\n",
    "    Endpoint:\n",
    "    /api/futures/aggregated-taker-buy-sell-volume/history?exchange_list=...&symbol=...&interval=...\n",
    "\n",
    "    Возвращает DF:\n",
    "    date (YYYY-MM-DD),\n",
    "    futures_aggregated_taker_buy_sell_volume_history__aggregated_buy_volume_usd\n",
    "    futures_aggregated_taker_buy_sell_volume_history__aggregated_sell_volume_usd\n",
    "    \"\"\"\n",
    "    endpoint_slug = \"futures_aggregated_taker_buy_sell_volume_history\"\n",
    "\n",
    "    df = _coinglass_get_dataframe(\n",
    "        endpoint=\"/futures/aggregated-taker-buy-sell-volume/history\",\n",
    "        api_key=api_key,\n",
    "        params={\"exchange_list\": exchange_list, \"symbol\": symbol, \"interval\": interval},\n",
    "    )\n",
    "\n",
    "    # time -> date\n",
    "    if \"time\" in df.columns:\n",
    "        df[\"date\"] = _coinglass_normalize_time_to_date(df[\"time\"])\n",
    "        df = df.drop(columns=[\"time\"])\n",
    "    else:\n",
    "        df[\"date\"] = pd.NA\n",
    "\n",
    "    # numeric fields (в примере числа, но приводим на всякий случай)\n",
    "    for col in [\"aggregated_buy_volume_usd\", \"aggregated_sell_volume_usd\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # prefix all except date\n",
    "    df = _prefix_columns(df, prefix=endpoint_slug, keep=(\"date\",))\n",
    "\n",
    "    cols = [\"date\"] + [c for c in df.columns if c != \"date\"]\n",
    "    df = df[cols].sort_values(\"date\", kind=\"stable\").reset_index(drop=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "sww3LPcONluq",
    "outputId": "5c223d7d-51d9-401a-adf7-a0953a4cc495"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>futures_aggregated_taker_buy_sell_volume_history__aggregated_buy_volume_usd</th>\n",
       "      <th>futures_aggregated_taker_buy_sell_volume_history__aggregated_sell_volume_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2026-01-16</td>\n",
       "      <td>5.880402e+09</td>\n",
       "      <td>6.402439e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2026-01-17</td>\n",
       "      <td>2.291735e+09</td>\n",
       "      <td>2.457957e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2026-01-18</td>\n",
       "      <td>3.624064e+09</td>\n",
       "      <td>3.810049e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>6.580171e+09</td>\n",
       "      <td>6.591515e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2026-01-20</td>\n",
       "      <td>3.855566e+09</td>\n",
       "      <td>4.246766e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  \\\n",
       "995  2026-01-16   \n",
       "996  2026-01-17   \n",
       "997  2026-01-18   \n",
       "998  2026-01-19   \n",
       "999  2026-01-20   \n",
       "\n",
       "     futures_aggregated_taker_buy_sell_volume_history__aggregated_buy_volume_usd  \\\n",
       "995                                       5.880402e+09                             \n",
       "996                                       2.291735e+09                             \n",
       "997                                       3.624064e+09                             \n",
       "998                                       6.580171e+09                             \n",
       "999                                       3.855566e+09                             \n",
       "\n",
       "     futures_aggregated_taker_buy_sell_volume_history__aggregated_sell_volume_usd  \n",
       "995                                       6.402439e+09                             \n",
       "996                                       2.457957e+09                             \n",
       "997                                       3.810049e+09                             \n",
       "998                                       6.591515e+09                             \n",
       "999                                       4.246766e+09                             "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KEYS = \"8b16782a668f4eb48397ddf3d97020bd\"\n",
    "\n",
    "df_taker_agg = get_futures_aggregated_taker_buy_sell_volume_history(\n",
    "    api_key=KEYS,\n",
    "    exchange_list=\"Binance\",\n",
    "    symbol=\"BTC\",\n",
    "    interval=\"1d\",\n",
    ")\n",
    "\n",
    "df_taker_agg.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZY2oOx1nNlln",
    "outputId": "a0133918-0562-4fb0-f1ad-6ded815353dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date  long_quantity  short_quantity  bfx_margin_total_qty  \\\n",
      "995  2026-01-16       70723.03          175.76              70898.79   \n",
      "996  2026-01-17       70649.62          187.18              70836.80   \n",
      "997  2026-01-18       70638.44          175.87              70814.31   \n",
      "998  2026-01-19       70698.63          190.37              70889.00   \n",
      "999  2026-01-20       70726.78          240.82              70967.60   \n",
      "\n",
      "     bfx_margin_long_share  bfx_margin_log_long_short  \n",
      "995               0.997521                   5.997407  \n",
      "996               0.997358                   5.933417  \n",
      "997               0.997516                   5.995585  \n",
      "998               0.997315                   5.917212  \n",
      "999               0.996607                   5.682530  \n"
     ]
    }
   ],
   "source": [
    "# provides data on margin long and short positions from Bitfinex.\n",
    "# https://open-api-v4.coinglass.com/api/bitfinex-margin-long-short?symbol=BTC&interval=1d\n",
    "\n",
    "# READY\n",
    "from __future__ import annotations\n",
    "\n",
    "from typing import Optional, Dict, Any\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "\n",
    "COINGLASS_BITFINEX_MARGIN_LS_URL = \"https://open-api-v4.coinglass.com/api/bitfinex-margin-long-short\"\n",
    "\n",
    "\n",
    "class CoinglassAPIError(RuntimeError):\n",
    "    pass\n",
    "\n",
    "\n",
    "def _coinglass_time_to_date_utc(t: pd.Series, date_only: bool = True) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Robust conversion: supports timestamps in milliseconds OR seconds.\n",
    "    Heuristic:\n",
    "      - >= 1e10 -> ms\n",
    "      - <  1e10 -> seconds\n",
    "\n",
    "    Then floors to day (UTC).\n",
    "    If date_only=True -> returns python datetime.date (prints as YYYY-MM-DD).\n",
    "    Else -> returns datetime64[ns, UTC] normalized to midnight.\n",
    "    \"\"\"\n",
    "    tt = pd.to_numeric(t, errors=\"coerce\").astype(\"Int64\")\n",
    "    is_ms = tt >= 10_000_000_000\n",
    "\n",
    "    out = pd.Series(pd.NaT, index=tt.index, dtype=\"datetime64[ns, UTC]\")\n",
    "    if is_ms.any():\n",
    "        out.loc[is_ms] = pd.to_datetime(tt.loc[is_ms], unit=\"ms\", utc=True, errors=\"coerce\")\n",
    "    if (~is_ms).any():\n",
    "        out.loc[~is_ms] = pd.to_datetime(tt.loc[~is_ms], unit=\"s\", utc=True, errors=\"coerce\")\n",
    "\n",
    "    out = out.dt.floor(\"D\")\n",
    "\n",
    "    if date_only:\n",
    "        return out.dt.date\n",
    "    return out\n",
    "\n",
    "\n",
    "def fetch_bitfinex_margin_long_short_history(\n",
    "    api_key: str,\n",
    "    symbol: str = \"BTC\",\n",
    "    interval: str = \"1d\",\n",
    "    timeout: int = 20,\n",
    "    extra_params: Optional[Dict[str, Any]] = None,\n",
    "    session: Optional[requests.Session] = None,\n",
    "    date_only: bool = True,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Endpoint:\n",
    "      /api/bitfinex-margin-long-short?symbol=...&interval=...\n",
    "\n",
    "    Returns DataFrame with columns:\n",
    "      - date (date-only by default; if date_only=False -> datetime64[ns, UTC])\n",
    "      - long_quantity\n",
    "      - short_quantity\n",
    "\n",
    "    Raw 'time' is dropped.\n",
    "    \"\"\"\n",
    "    if not api_key:\n",
    "        raise ValueError(\"api_key is required\")\n",
    "\n",
    "    params = {\"symbol\": symbol, \"interval\": interval}\n",
    "    if extra_params:\n",
    "        params.update(extra_params)\n",
    "\n",
    "    headers = {\"accept\": \"application/json\", \"CG-API-KEY\": api_key}\n",
    "\n",
    "    s = session or requests.Session()\n",
    "    r = s.get(COINGLASS_BITFINEX_MARGIN_LS_URL, headers=headers, params=params, timeout=timeout)\n",
    "    r.raise_for_status()\n",
    "\n",
    "    j = r.json()\n",
    "    if str(j.get(\"code\")) != \"0\":\n",
    "        raise CoinglassAPIError(f\"Coinglass error: code={j.get('code')} msg={j.get('msg')}\")\n",
    "\n",
    "    data = j.get(\"data\") or []\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    cols = [\"date\", \"long_quantity\", \"short_quantity\"]\n",
    "    if df.empty:\n",
    "        return pd.DataFrame(columns=cols)\n",
    "\n",
    "    required = {\"time\", \"long_quantity\", \"short_quantity\"}\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise CoinglassAPIError(f\"Unexpected payload: missing columns {sorted(missing)}\")\n",
    "\n",
    "    df[\"date\"] = _coinglass_time_to_date_utc(df[\"time\"], date_only=date_only)\n",
    "    df = df.drop(columns=[\"time\"])\n",
    "\n",
    "    df[\"long_quantity\"] = pd.to_numeric(df[\"long_quantity\"], errors=\"coerce\")\n",
    "    df[\"short_quantity\"] = pd.to_numeric(df[\"short_quantity\"], errors=\"coerce\")\n",
    "\n",
    "    df = df.sort_values(\"date\", kind=\"stable\").reset_index(drop=True)\n",
    "    return df[cols]\n",
    "\n",
    "\n",
    "def add_bitfinex_margin_long_short_features(df: pd.DataFrame, eps: float = 1e-9) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds 3 potentially useful features (no extra time columns, no lags):\n",
    "\n",
    "      1) bfx_margin_total_qty:\n",
    "         long + short — общий размер маржинальных позиций\n",
    "\n",
    "      2) bfx_margin_long_share:\n",
    "         long / (long + short) — доля лонгов (0..1)\n",
    "\n",
    "      3) bfx_margin_log_long_short:\n",
    "         log((long + eps) / (short + eps)) — перекос в лог-шкале\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "\n",
    "    lng = pd.to_numeric(out[\"long_quantity\"], errors=\"coerce\")\n",
    "    sht = pd.to_numeric(out[\"short_quantity\"], errors=\"coerce\")\n",
    "    total = lng + sht\n",
    "\n",
    "    out[\"bfx_margin_total_qty\"] = total\n",
    "    out[\"bfx_margin_long_share\"] = lng / (total + eps)\n",
    "    out[\"bfx_margin_log_long_short\"] = np.log((lng + eps) / (sht + eps))\n",
    "\n",
    "    ordered = [\n",
    "        \"date\",\n",
    "        \"long_quantity\",\n",
    "        \"short_quantity\",\n",
    "        \"bfx_margin_total_qty\",\n",
    "        \"bfx_margin_long_share\",\n",
    "        \"bfx_margin_log_long_short\",\n",
    "    ]\n",
    "    return out[ordered]\n",
    "\n",
    "\n",
    "# ---- Example ----\n",
    "# READY ()\n",
    "df = fetch_bitfinex_margin_long_short_history(\n",
    "    api_key=KEYS,\n",
    "    symbol=\"BTC\",\n",
    "    interval=\"1d\",\n",
    "    date_only=True,  # <- будет выводиться как 2026-01-07\n",
    ")\n",
    "\n",
    "bitfinex_margin_ls_df = add_bitfinex_margin_long_short_features(df)\n",
    "print(bitfinex_margin_ls_df.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oTgKadSTMzdB",
    "outputId": "c30bd2af-89fc-48c2-fc56-a68d37704f99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date  cgdi_index_value  cgdi_log_level  cgdi_dev_from_base  \\\n",
      "746  2026-01-16         2172.2652        7.683526           1172.2652   \n",
      "747  2026-01-17         2159.3674        7.677571           1159.3674   \n",
      "748  2026-01-18         2171.4726        7.683161           1171.4726   \n",
      "749  2026-01-19         2122.5307        7.660364           1122.5307   \n",
      "750  2026-01-20         2062.1789        7.631518           1062.1789   \n",
      "\n",
      "     cgdi_dev_softsign  \n",
      "746           0.539651  \n",
      "747           0.536901  \n",
      "748           0.539483  \n",
      "749           0.528864  \n",
      "750           0.515076  \n"
     ]
    }
   ],
   "source": [
    "# This endpoint provides historical CGDI (CoinGlass Derivatives Index) data\n",
    "# https://open-api-v4.coinglass.com/api/futures/cgdi-index/history\n",
    "# {\n",
    "#   \"code\": \"0\",\n",
    "#   \"data\": [\n",
    "#     {\"time\": 1704067200000, \"cgdi_index_value\": 1000},\n",
    "#     {\"time\": 1704153600000, \"cgdi_index_value\": 1053.2551}\n",
    "#   ]\n",
    "# }\n",
    "\n",
    "# READY\n",
    "from __future__ import annotations\n",
    "\n",
    "from typing import Optional, Dict, Any\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "\n",
    "COINGLASS_FUTURES_CGDI_INDEX_URL = \"https://open-api-v4.coinglass.com/api/futures/cgdi-index/history\"\n",
    "\n",
    "\n",
    "class CoinglassAPIError(RuntimeError):\n",
    "    pass\n",
    "\n",
    "\n",
    "def _coinglass_time_to_date_utc(t: pd.Series, date_only: bool = True) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Robust conversion: supports timestamps in milliseconds OR seconds.\n",
    "    Heuristic:\n",
    "      - >= 1e10 -> ms\n",
    "      - <  1e10 -> seconds\n",
    "\n",
    "    Then floors to day (UTC).\n",
    "    If date_only=True -> returns python datetime.date (prints as YYYY-MM-DD).\n",
    "    Else -> returns datetime64[ns, UTC] normalized to midnight.\n",
    "    \"\"\"\n",
    "    tt = pd.to_numeric(t, errors=\"coerce\").astype(\"Int64\")\n",
    "    is_ms = tt >= 10_000_000_000\n",
    "\n",
    "    out = pd.Series(pd.NaT, index=tt.index, dtype=\"datetime64[ns, UTC]\")\n",
    "    if is_ms.any():\n",
    "        out.loc[is_ms] = pd.to_datetime(tt.loc[is_ms], unit=\"ms\", utc=True, errors=\"coerce\")\n",
    "    if (~is_ms).any():\n",
    "        out.loc[~is_ms] = pd.to_datetime(tt.loc[~is_ms], unit=\"s\", utc=True, errors=\"coerce\")\n",
    "\n",
    "    out = out.dt.floor(\"D\")\n",
    "\n",
    "    if date_only:\n",
    "        return out.dt.date\n",
    "    return out\n",
    "\n",
    "\n",
    "def fetch_futures_cgdi_index_history(\n",
    "    api_key: str,\n",
    "    interval: str = \"1d\",\n",
    "    timeout: int = 20,\n",
    "    extra_params: Optional[Dict[str, Any]] = None,\n",
    "    session: Optional[requests.Session] = None,\n",
    "    date_only: bool = True,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Endpoint:\n",
    "      /api/futures/cgdi-index/history?interval=...\n",
    "\n",
    "    Returns DataFrame with columns:\n",
    "      - date (date-only by default; if date_only=False -> datetime64[ns, UTC])\n",
    "      - cgdi_index_value\n",
    "\n",
    "    Raw 'time' is dropped.\n",
    "    \"\"\"\n",
    "    if not api_key:\n",
    "        raise ValueError(\"api_key is required\")\n",
    "\n",
    "    params = {\"interval\": interval}\n",
    "    if extra_params:\n",
    "        params.update(extra_params)\n",
    "\n",
    "    headers = {\"accept\": \"application/json\", \"CG-API-KEY\": api_key}\n",
    "\n",
    "    s = session or requests.Session()\n",
    "    r = s.get(COINGLASS_FUTURES_CGDI_INDEX_URL, headers=headers, params=params, timeout=timeout)\n",
    "    r.raise_for_status()\n",
    "\n",
    "    j = r.json()\n",
    "    if str(j.get(\"code\")) != \"0\":\n",
    "        raise CoinglassAPIError(f\"Coinglass error: code={j.get('code')} msg={j.get('msg')}\")\n",
    "\n",
    "    data = j.get(\"data\") or []\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    cols = [\"date\", \"cgdi_index_value\"]\n",
    "    if df.empty:\n",
    "        return pd.DataFrame(columns=cols)\n",
    "\n",
    "    required = {\"time\", \"cgdi_index_value\"}\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise CoinglassAPIError(f\"Unexpected payload: missing columns {sorted(missing)}\")\n",
    "\n",
    "    df[\"date\"] = _coinglass_time_to_date_utc(df[\"time\"], date_only=date_only)\n",
    "    df = df.drop(columns=[\"time\"])\n",
    "\n",
    "    df[\"cgdi_index_value\"] = pd.to_numeric(df[\"cgdi_index_value\"], errors=\"coerce\")\n",
    "\n",
    "    df = df.sort_values(\"date\", kind=\"stable\").reset_index(drop=True)\n",
    "    return df[cols]\n",
    "\n",
    "\n",
    "def add_futures_cgdi_index_features(\n",
    "    df: pd.DataFrame,\n",
    "    base_level: float = 1000.0,\n",
    "    eps: float = 1e-9,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds 3 potentially useful features (no extra time columns, no lagging):\n",
    "\n",
    "      1) cgdi_log_level:\n",
    "         log(value) — сжатие масштаба уровня индекса\n",
    "\n",
    "      2) cgdi_dev_from_base:\n",
    "         value - base_level — абсолютное отклонение от базового уровня (обычно 1000)\n",
    "\n",
    "      3) cgdi_dev_softsign:\n",
    "         (value - base) / (|value - base| + base) — устойчивый нормированный сигнал отклонения\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "\n",
    "    x = pd.to_numeric(out[\"cgdi_index_value\"], errors=\"coerce\")\n",
    "    dev = x - float(base_level)\n",
    "    adev = np.abs(dev)\n",
    "\n",
    "    out[\"cgdi_log_level\"] = np.log(x + eps)\n",
    "    out[\"cgdi_dev_from_base\"] = dev\n",
    "    out[\"cgdi_dev_softsign\"] = dev / (adev + float(base_level) + eps)\n",
    "\n",
    "    # порядок колонок (date сначала)\n",
    "    ordered = [\"date\", \"cgdi_index_value\", \"cgdi_log_level\", \"cgdi_dev_from_base\", \"cgdi_dev_softsign\"]\n",
    "    return out[ordered]\n",
    "\n",
    "\n",
    "# ---- Example ----\n",
    "# READY()\n",
    "df = fetch_futures_cgdi_index_history(\n",
    "    api_key=KEYS,\n",
    "    interval=\"1d\",\n",
    "    date_only=True,  # <- будет выводиться как 2026-01-07\n",
    ")\n",
    "\n",
    "futures_cgdi_index_df = add_futures_cgdi_index_features(df).iloc[:-1]\n",
    "print(futures_cgdi_index_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-WmYjhIVMzbF",
    "outputId": "46746926-f80d-4b07-9436-401505c688bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date  premium  premium_rate  cb_premium_abs  cb_premium_softsign  \\\n",
      "995  2026-01-16   -26.61       -0.0278           26.61            -0.963781   \n",
      "996  2026-01-17   -46.94       -0.0491           46.94            -0.979141   \n",
      "997  2026-01-18   -37.78       -0.0397           37.78            -0.974214   \n",
      "998  2026-01-19   -43.14       -0.0461           43.14            -0.977345   \n",
      "999  2026-01-20   -71.37       -0.0770           71.37            -0.986182   \n",
      "\n",
      "     cb_premium_rate_bps  cb_implied_ref_price  \n",
      "995               -278.0          95719.427904  \n",
      "996               -491.0          95600.816611  \n",
      "997               -397.0          95163.730357  \n",
      "998               -461.0          93579.177735  \n",
      "999               -770.0          92688.312892  \n"
     ]
    }
   ],
   "source": [
    "# READY\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from typing import Optional, Dict, Any\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "\n",
    "COINGLASS_COINBASE_PREMIUM_URL = \"https://open-api-v4.coinglass.com/api/coinbase-premium-index\"\n",
    "\n",
    "\n",
    "class CoinglassAPIError(RuntimeError):\n",
    "    pass\n",
    "\n",
    "\n",
    "def _coinglass_time_to_date_utc(t: pd.Series, date_only: bool = True) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Robust conversion: supports timestamps in milliseconds OR seconds.\n",
    "    Then floors to day (UTC).\n",
    "    If date_only=True -> returns python datetime.date (prints as YYYY-MM-DD).\n",
    "    Else -> returns datetime64[ns, UTC] normalized to midnight.\n",
    "    \"\"\"\n",
    "    tt = pd.to_numeric(t, errors=\"coerce\").astype(\"Int64\")\n",
    "    is_ms = tt >= 10_000_000_000\n",
    "\n",
    "    out = pd.Series(pd.NaT, index=tt.index, dtype=\"datetime64[ns, UTC]\")\n",
    "    if is_ms.any():\n",
    "        out.loc[is_ms] = pd.to_datetime(tt.loc[is_ms], unit=\"ms\", utc=True, errors=\"coerce\")\n",
    "    if (~is_ms).any():\n",
    "        out.loc[~is_ms] = pd.to_datetime(tt.loc[~is_ms], unit=\"s\", utc=True, errors=\"coerce\")\n",
    "\n",
    "    # normalize to day boundary\n",
    "    out = out.dt.floor(\"D\")\n",
    "\n",
    "    if date_only:\n",
    "        return out.dt.date  # -> prints like 2026-01-07\n",
    "    return out\n",
    "\n",
    "\n",
    "def fetch_coinbase_premium_index_history(\n",
    "    api_key: str,\n",
    "    interval: str = \"1d\",\n",
    "    timeout: int = 20,\n",
    "    extra_params: Optional[Dict[str, Any]] = None,\n",
    "    session: Optional[requests.Session] = None,\n",
    "    deduplicate: bool = True,\n",
    "    date_only: bool = True,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Endpoint:\n",
    "      /api/coinbase-premium-index?interval=...\n",
    "\n",
    "    Returns DataFrame with columns:\n",
    "      - date (date-only by default; if date_only=False -> datetime64[ns, UTC])\n",
    "      - premium\n",
    "      - premium_rate\n",
    "    \"\"\"\n",
    "    if not api_key:\n",
    "        raise ValueError(\"api_key is required\")\n",
    "\n",
    "    params = {\"interval\": interval}\n",
    "    if extra_params:\n",
    "        params.update(extra_params)\n",
    "\n",
    "    headers = {\"accept\": \"application/json\", \"CG-API-KEY\": api_key}\n",
    "\n",
    "    s = session or requests.Session()\n",
    "    r = s.get(COINGLASS_COINBASE_PREMIUM_URL, headers=headers, params=params, timeout=timeout)\n",
    "    r.raise_for_status()\n",
    "\n",
    "    j = r.json()\n",
    "    if str(j.get(\"code\")) != \"0\":\n",
    "        raise CoinglassAPIError(f\"Coinglass error: code={j.get('code')} msg={j.get('msg')}\")\n",
    "\n",
    "    data = j.get(\"data\") or []\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    cols = [\"date\", \"premium\", \"premium_rate\"]\n",
    "    if df.empty:\n",
    "        return pd.DataFrame(columns=cols)\n",
    "\n",
    "    required = {\"time\", \"premium\", \"premium_rate\"}\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise CoinglassAPIError(f\"Unexpected payload: missing columns {sorted(missing)}\")\n",
    "\n",
    "    df[\"date\"] = _coinglass_time_to_date_utc(df[\"time\"], date_only=date_only)\n",
    "    df = df.drop(columns=[\"time\"])\n",
    "\n",
    "    df[\"premium\"] = pd.to_numeric(df[\"premium\"], errors=\"coerce\")\n",
    "    df[\"premium_rate\"] = pd.to_numeric(df[\"premium_rate\"], errors=\"coerce\")\n",
    "\n",
    "    df = df.sort_values(\"date\", kind=\"stable\").reset_index(drop=True)\n",
    "\n",
    "    if deduplicate:\n",
    "        df = df.drop_duplicates(subset=[\"date\"], keep=\"last\").reset_index(drop=True)\n",
    "\n",
    "    return df[cols]\n",
    "\n",
    "\n",
    "def add_coinbase_premium_features(\n",
    "    df: pd.DataFrame,\n",
    "    eps: float = 1e-9,\n",
    "    rate_is_fraction: bool = True,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    date premium premium_rate cb_premium_abs cb_premium_softsign cb_premium_rate_bps cb_implied_ref_price\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "\n",
    "    prem = pd.to_numeric(out[\"premium\"], errors=\"coerce\")\n",
    "    rate = pd.to_numeric(out[\"premium_rate\"], errors=\"coerce\")\n",
    "\n",
    "    aprem = np.abs(prem)\n",
    "    out[\"cb_premium_abs\"] = aprem\n",
    "    out[\"cb_premium_softsign\"] = prem / (1.0 + aprem + eps)\n",
    "\n",
    "    out[\"cb_premium_rate_bps\"] = rate * 10_000.0\n",
    "\n",
    "    # ВАЖНО: твой пример (premium=-30, rate=-0.0331) даёт ~90634 именно по формуле *100/rate\n",
    "    if rate_is_fraction:\n",
    "        out[\"cb_implied_ref_price\"] = prem * 100.0 / (rate + eps)\n",
    "    else:\n",
    "        out[\"cb_implied_ref_price\"] = prem / (rate + eps)\n",
    "\n",
    "    # порядок колонок как ты хочешь\n",
    "    ordered = [\n",
    "        \"date\", \"premium\", \"premium_rate\",\n",
    "        \"cb_premium_abs\", \"cb_premium_softsign\", \"cb_premium_rate_bps\", \"cb_implied_ref_price\"\n",
    "    ]\n",
    "    return out[ordered]\n",
    "\n",
    "\n",
    "# ---- Example ----\n",
    "df = fetch_coinbase_premium_index_history(\n",
    "    api_key=KEYS,\n",
    "    interval=\"1d\",\n",
    "    date_only=True,        # <- будет выводиться как 2026-01-07\n",
    ")\n",
    "coinbase_premium_df = add_coinbase_premium_features(df, rate_is_fraction=True)\n",
    "print(coinbase_premium_df.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "nstlK7B7MzXA",
    "outputId": "2f01bec7-0208-4e71-b82f-704f6cdf3e97"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>index_btc_reserve_risk__price</th>\n",
       "      <th>index_btc_reserve_risk__reserve_risk_index</th>\n",
       "      <th>index_btc_reserve_risk__movcd</th>\n",
       "      <th>index_btc_reserve_risk__hodl_bank</th>\n",
       "      <th>index_btc_reserve_risk__vocd</th>\n",
       "      <th>index_btc_reserve_risk__log_rr</th>\n",
       "      <th>index_btc_reserve_risk__rr_z180</th>\n",
       "      <th>index_btc_reserve_risk__rr_slope14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5629</th>\n",
       "      <td>2026-01-15</td>\n",
       "      <td>95585.0</td>\n",
       "      <td>0.001866</td>\n",
       "      <td>43713.491563</td>\n",
       "      <td>5.123755e+07</td>\n",
       "      <td>44225.755630</td>\n",
       "      <td>-6.284212</td>\n",
       "      <td>-1.012497</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5630</th>\n",
       "      <td>2026-01-16</td>\n",
       "      <td>95516.0</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>43042.446490</td>\n",
       "      <td>5.129003e+07</td>\n",
       "      <td>31162.637620</td>\n",
       "      <td>-6.285958</td>\n",
       "      <td>-1.012045</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5631</th>\n",
       "      <td>2026-01-17</td>\n",
       "      <td>95100.0</td>\n",
       "      <td>0.001852</td>\n",
       "      <td>43042.446490</td>\n",
       "      <td>5.134208e+07</td>\n",
       "      <td>39486.925922</td>\n",
       "      <td>-6.291337</td>\n",
       "      <td>-1.033431</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5632</th>\n",
       "      <td>2026-01-18</td>\n",
       "      <td>93753.0</td>\n",
       "      <td>0.001824</td>\n",
       "      <td>41063.868764</td>\n",
       "      <td>5.139477e+07</td>\n",
       "      <td>19153.014936</td>\n",
       "      <td>-6.306628</td>\n",
       "      <td>-1.113849</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5633</th>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>92558.0</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>39902.666872</td>\n",
       "      <td>5.144743e+07</td>\n",
       "      <td>40318.407822</td>\n",
       "      <td>-6.320480</td>\n",
       "      <td>-1.183575</td>\n",
       "      <td>-0.000004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  index_btc_reserve_risk__price  \\\n",
       "5629 2026-01-15                        95585.0   \n",
       "5630 2026-01-16                        95516.0   \n",
       "5631 2026-01-17                        95100.0   \n",
       "5632 2026-01-18                        93753.0   \n",
       "5633 2026-01-19                        92558.0   \n",
       "\n",
       "      index_btc_reserve_risk__reserve_risk_index  \\\n",
       "5629                                    0.001866   \n",
       "5630                                    0.001862   \n",
       "5631                                    0.001852   \n",
       "5632                                    0.001824   \n",
       "5633                                    0.001799   \n",
       "\n",
       "      index_btc_reserve_risk__movcd  index_btc_reserve_risk__hodl_bank  \\\n",
       "5629                   43713.491563                       5.123755e+07   \n",
       "5630                   43042.446490                       5.129003e+07   \n",
       "5631                   43042.446490                       5.134208e+07   \n",
       "5632                   41063.868764                       5.139477e+07   \n",
       "5633                   39902.666872                       5.144743e+07   \n",
       "\n",
       "      index_btc_reserve_risk__vocd  index_btc_reserve_risk__log_rr  \\\n",
       "5629                  44225.755630                       -6.284212   \n",
       "5630                  31162.637620                       -6.285958   \n",
       "5631                  39486.925922                       -6.291337   \n",
       "5632                  19153.014936                       -6.306628   \n",
       "5633                  40318.407822                       -6.320480   \n",
       "\n",
       "      index_btc_reserve_risk__rr_z180  index_btc_reserve_risk__rr_slope14  \n",
       "5629                        -1.012497                            0.000008  \n",
       "5630                        -1.012045                            0.000006  \n",
       "5631                        -1.033431                            0.000005  \n",
       "5632                        -1.113849                            0.000002  \n",
       "5633                        -1.183575                           -0.000004  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "BTC_RESERVE_RISK_URL = \"https://open-api-v4.coinglass.com/api/index/bitcoin-reserve-risk\"\n",
    "\n",
    "\n",
    "# READY\n",
    "\n",
    "def _get_coinglass_key(KEYS) -> str:\n",
    "    if isinstance(KEYS, str) and KEYS.strip():\n",
    "        return KEYS.strip()\n",
    "    if isinstance(KEYS, dict):\n",
    "        for k in (\"CG_API_KEY\", \"COINGLASS_API_KEY\", \"CG-API-KEY\", \"COINGLASS_KEY\", \"coinglass\"):\n",
    "            v = KEYS.get(k)\n",
    "            if isinstance(v, str) and v.strip():\n",
    "                return v.strip()\n",
    "    raise ValueError(\"CoinGlass API key not found. Set KEYS to API key string or dict containing it.\")\n",
    "\n",
    "\n",
    "def _parse_ms_or_s_to_date(ts: pd.Series) -> pd.Series:\n",
    "    t = pd.to_numeric(ts, errors=\"coerce\").astype(\"float64\")\n",
    "    is_seconds = t < 10_000_000_000\n",
    "    dt = pd.Series(pd.NaT, index=t.index, dtype=\"datetime64[ns]\")\n",
    "\n",
    "    if is_seconds.any():\n",
    "        dt.loc[is_seconds] = pd.to_datetime(t.loc[is_seconds], unit=\"s\", errors=\"coerce\")\n",
    "    if (~is_seconds).any():\n",
    "        dt.loc[~is_seconds] = pd.to_datetime(t.loc[~is_seconds], unit=\"ms\", errors=\"coerce\")\n",
    "\n",
    "    return dt.dt.normalize()\n",
    "\n",
    "\n",
    "def fetch_bitcoin_reserve_risk_table(\n",
    "    KEYS,\n",
    "    z_window: int = 180,\n",
    "    slope_window: int = 14,\n",
    "    timeout: int = 20,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch Bitcoin Reserve Risk + add 3 forecast-useful features.\n",
    "\n",
    "    Output columns:\n",
    "      - date\n",
    "      - index_btc_reserve_risk__price\n",
    "      - index_btc_reserve_risk__reserve_risk_index\n",
    "      - index_btc_reserve_risk__movcd\n",
    "      - index_btc_reserve_risk__hodl_bank\n",
    "      - index_btc_reserve_risk__vocd\n",
    "      - index_btc_reserve_risk__log_rr\n",
    "      - index_btc_reserve_risk__rr_z{z_window}\n",
    "      - index_btc_reserve_risk__rr_slope{slope_window}\n",
    "    \"\"\"\n",
    "    api_key = _get_coinglass_key(KEYS)\n",
    "    headers = {\"accept\": \"application/json\", \"CG-API-KEY\": api_key}\n",
    "\n",
    "    r = requests.get(BTC_RESERVE_RISK_URL, headers=headers, timeout=timeout)\n",
    "    r.raise_for_status()\n",
    "    j = r.json()\n",
    "\n",
    "    if str(j.get(\"code\")) != \"0\":\n",
    "        raise RuntimeError(f\"CoinGlass error: code={j.get('code')}, msg={j.get('msg')}\")\n",
    "\n",
    "    rows = j.get(\"data\") or []\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    cols = [\n",
    "        \"date\",\n",
    "        \"index_btc_reserve_risk__price\",\n",
    "        \"index_btc_reserve_risk__reserve_risk_index\",\n",
    "        \"index_btc_reserve_risk__movcd\",\n",
    "        \"index_btc_reserve_risk__hodl_bank\",\n",
    "        \"index_btc_reserve_risk__vocd\",\n",
    "        \"index_btc_reserve_risk__log_rr\",\n",
    "        f\"index_btc_reserve_risk__rr_z{z_window}\",\n",
    "        f\"index_btc_reserve_risk__rr_slope{slope_window}\",\n",
    "    ]\n",
    "    if df.empty:\n",
    "        return pd.DataFrame(columns=cols)\n",
    "\n",
    "    df[\"date\"] = _parse_ms_or_s_to_date(df.get(\"timestamp\"))\n",
    "    df[\"index_btc_reserve_risk__price\"] = pd.to_numeric(df.get(\"price\"), errors=\"coerce\")\n",
    "    df[\"index_btc_reserve_risk__reserve_risk_index\"] = pd.to_numeric(df.get(\"reserve_risk_index\"), errors=\"coerce\")\n",
    "    df[\"index_btc_reserve_risk__movcd\"] = pd.to_numeric(df.get(\"movcd\"), errors=\"coerce\")\n",
    "    df[\"index_btc_reserve_risk__hodl_bank\"] = pd.to_numeric(df.get(\"hodl_bank\"), errors=\"coerce\")\n",
    "    df[\"index_btc_reserve_risk__vocd\"] = pd.to_numeric(df.get(\"vocd\"), errors=\"coerce\")\n",
    "\n",
    "    out = (\n",
    "        df[[\n",
    "            \"date\",\n",
    "            \"index_btc_reserve_risk__price\",\n",
    "            \"index_btc_reserve_risk__reserve_risk_index\",\n",
    "            \"index_btc_reserve_risk__movcd\",\n",
    "            \"index_btc_reserve_risk__hodl_bank\",\n",
    "            \"index_btc_reserve_risk__vocd\",\n",
    "        ]]\n",
    "        .dropna(subset=[\"date\"])\n",
    "        .sort_values(\"date\", kind=\"stable\")\n",
    "        .drop_duplicates(subset=[\"date\"], keep=\"last\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    rr = out[\"index_btc_reserve_risk__reserve_risk_index\"].astype(float)\n",
    "\n",
    "    # Feature 1: log transform (often spans orders of magnitude)\n",
    "    out[\"index_btc_reserve_risk__log_rr\"] = np.log(np.where(rr > 0, rr, np.nan))\n",
    "\n",
    "    # Feature 2: rolling z-score (regime-normalized)\n",
    "    minp = max(30, z_window // 3)\n",
    "    roll = rr.rolling(z_window, min_periods=minp)\n",
    "    mu = roll.mean()\n",
    "    sd = roll.std(ddof=0).replace(0.0, np.nan)\n",
    "    out[f\"index_btc_reserve_risk__rr_z{z_window}\"] = (rr - mu) / sd\n",
    "\n",
    "    # Feature 3: slope / velocity\n",
    "    out[f\"index_btc_reserve_risk__rr_slope{slope_window}\"] = rr.diff(slope_window) / float(slope_window)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# Usage:\n",
    "# READY()\n",
    "df_rr = fetch_bitcoin_reserve_risk_table(KEYS)\n",
    "df_rr.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MERGE FEATURES INTO 1 DATAFRAME BY DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "6E--a8gBQwHs"
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# READY\n",
    "\n",
    "def _dedupe_by_date(df: pd.DataFrame, how: str = \"last\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Убирает дубли по date.\n",
    "    how:\n",
    "      - \"last\": оставляет последнюю строку по date\n",
    "      - \"first\": оставляет первую\n",
    "      - \"mean\": усредняет все numeric колонки внутри одного date (остальные игнор)\n",
    "    \"\"\"\n",
    "    if df is None or df.empty:\n",
    "        return df\n",
    "    if \"date\" not in df.columns:\n",
    "        raise ValueError(\"DataFrame must contain 'date' column\")\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"date\"] = df[\"date\"].astype(\"string\")\n",
    "\n",
    "    if how in (\"last\", \"first\"):\n",
    "        keep = how\n",
    "        return df.sort_values(\"date\", kind=\"stable\").drop_duplicates(\"date\", keep=keep).reset_index(drop=True)\n",
    "\n",
    "    if how == \"mean\":\n",
    "        num_cols = [c for c in df.columns if c != \"date\" and pd.api.types.is_numeric_dtype(df[c])]\n",
    "        # если numeric нет — просто дедыуп по last\n",
    "        if not num_cols:\n",
    "            return df.sort_values(\"date\", kind=\"stable\").drop_duplicates(\"date\", keep=\"last\").reset_index(drop=True)\n",
    "        out = df.groupby(\"date\", as_index=False)[num_cols].mean()\n",
    "        return out.sort_values(\"date\", kind=\"stable\").reset_index(drop=True)\n",
    "\n",
    "    raise ValueError(\"how must be one of: 'last', 'first', 'mean'\")\n",
    "\n",
    "\n",
    "def merge_by_date(dfs: list[pd.DataFrame], how: str = \"outer\", dedupe: str = \"last\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Объединяет список DF по колонке 'date'.\n",
    "    how: 'outer' (рекомендую) или 'inner'\n",
    "    dedupe: см. _dedupe_by_date\n",
    "    \"\"\"\n",
    "    # отфильтровать пустые\n",
    "    cleaned = []\n",
    "    for df in dfs:\n",
    "        if df is None or df.empty:\n",
    "            continue\n",
    "        cleaned.append(_dedupe_by_date(df, how=dedupe))\n",
    "\n",
    "    if not cleaned:\n",
    "        return pd.DataFrame(columns=[\"date\"])\n",
    "\n",
    "    merged = reduce(lambda left, right: left.merge(right, on=\"date\", how=how), cleaned)\n",
    "    merged = merged.sort_values(\"date\", kind=\"stable\").reset_index(drop=True)\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "qGa9rWHsQvgm"
   },
   "outputs": [],
   "source": [
    "dfs = [\n",
    "    df_oi,\n",
    "    df_oi_agg,\n",
    "    df_stable_oi,\n",
    "    df_coin_margin,\n",
    "    df_funding,\n",
    "    df_oi_weight_funding,\n",
    "    df_vol_weight_funding,\n",
    "    df_ls_accounts,\n",
    "    df_top_ls_accounts,\n",
    "    df_top_ls_positions,\n",
    "    df_net_pos,\n",
    "    df_liq,\n",
    "    df_liq_agg,\n",
    "    df_ob,\n",
    "    df_ob_agg,\n",
    "    df_taker,\n",
    "    df_taker_agg,\n",
    "    bitfinex_margin_ls_df,\n",
    "    futures_cgdi_index_df,\n",
    "    coinbase_premium_df,\n",
    "    df_lth_supply,\n",
    "    df_aa,\n",
    "    df_sth_supply,\n",
    "    df_rr\n",
    "]\n",
    "\n",
    "df_all = merge_by_date(dfs, how=\"outer\", dedupe=\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "cdz5fNioNlhP"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# READY\n",
    "def _normalize_time_to_date_spot(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Приводит timestamp к строке 'YYYY-MM-DD' (UTC).\n",
    "    Устойчива к смешанным единицам (s/ms/us/ns) в одном столбце.\n",
    "    \"\"\"\n",
    "    s = pd.to_numeric(series, errors=\"coerce\").to_numpy(dtype=\"float64\")\n",
    "\n",
    "    # выход сразу string\n",
    "    out = pd.Series(pd.NA, index=getattr(series, \"index\", None), dtype=\"string\")\n",
    "    if out.index is None:\n",
    "        out.index = pd.RangeIndex(len(s))\n",
    "\n",
    "    valid = ~np.isnan(s)\n",
    "    if not valid.any():\n",
    "        return out\n",
    "\n",
    "    v = s[valid]\n",
    "\n",
    "    # классификация по порядку величины (для каждого значения)\n",
    "    is_ns = v >= 1e17\n",
    "    is_us = (v >= 1e14) & (v < 1e17)\n",
    "    is_ms = (v >= 1e11) & (v < 1e14)\n",
    "    is_s  = v < 1e11\n",
    "\n",
    "    # numpy datetime64[ns] массив\n",
    "    dt_ns = np.empty(v.shape[0], dtype=\"datetime64[ns]\")\n",
    "    dt_ns[:] = np.datetime64(\"NaT\", \"ns\")\n",
    "\n",
    "    # заполняем dt_ns кусками, приводя к ns\n",
    "    if is_ns.any():\n",
    "        dt_ns[is_ns] = v[is_ns].astype(\"int64\").astype(\"datetime64[ns]\")\n",
    "\n",
    "    if is_us.any():\n",
    "        dt_ns[is_us] = (v[is_us].astype(\"int64\") * 1_000).astype(\"datetime64[ns]\")\n",
    "\n",
    "    if is_ms.any():\n",
    "        dt_ns[is_ms] = (v[is_ms].astype(\"int64\") * 1_000_000).astype(\"datetime64[ns]\")\n",
    "\n",
    "    if is_s.any():\n",
    "        dt_ns[is_s] = (v[is_s].astype(\"int64\") * 1_000_000_000).astype(\"datetime64[ns]\")\n",
    "\n",
    "    # в pandas datetime (UTC) и формат\n",
    "    dt = pd.to_datetime(dt_ns, utc=True, errors=\"coerce\")\n",
    "    out.loc[valid] = dt.strftime(\"%Y-%m-%d\")\n",
    "    return out\n",
    "\n",
    "\n",
    "def get_spot_price_history(\n",
    "    api_key: str,\n",
    "    exchange: str = \"Binance\",\n",
    "    symbol: str = \"BTCUSDT\",\n",
    "    interval: str = \"1d\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Spot price OHLCV (USD volume) history.\n",
    "    Endpoint:\n",
    "    /api/spot/price/history?exchange=...&symbol=...&interval=...\n",
    "\n",
    "    Возвращает DF:\n",
    "    date (YYYY-MM-DD),\n",
    "    spot_price_history__open/high/low/close,\n",
    "    spot_price_history__volume_usd\n",
    "    \"\"\"\n",
    "    endpoint_slug = \"spot_price_history\"\n",
    "\n",
    "    df = _coinglass_get_dataframe(\n",
    "        endpoint=\"/spot/price/history\",\n",
    "        api_key=api_key,\n",
    "        params={\"exchange\": exchange, \"symbol\": symbol, \"interval\": interval},\n",
    "    )\n",
    "\n",
    "    # time -> date\n",
    "    if \"time\" in df.columns:\n",
    "        df[\"date\"] = _normalize_time_to_date_spot(df[\"time\"])\n",
    "        df = df.drop(columns=[\"time\"])\n",
    "    else:\n",
    "        df[\"date\"] = pd.NA\n",
    "\n",
    "    # numeric fields (обычно уже числа, но нормализуем)\n",
    "    for col in [\"open\", \"high\", \"low\", \"close\", \"volume_usd\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # prefix all except date\n",
    "    # df = _prefix_columns(df, prefix=endpoint_slug, keep=(\"date\",))\n",
    "\n",
    "    cols = [\"date\"] + [c for c in df.columns if c != \"date\"]\n",
    "    df = df[cols].sort_values(\"date\", kind=\"stable\").reset_index(drop=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "k_WH6qewVjlt"
   },
   "outputs": [],
   "source": [
    "KEYS = \"8b16782a668f4eb48397ddf3d97020bd\"\n",
    "\n",
    "df_spot = get_spot_price_history(\n",
    "    api_key=KEYS,\n",
    "    exchange=\"Binance\",\n",
    "    symbol=\"BTCUSDT\",\n",
    "    interval=\"1d\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "EJoKUhVjNle-"
   },
   "outputs": [],
   "source": [
    "df_all = merge_by_date(dfs + [df_spot], how=\"outer\", dedupe=\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "2_hPR3fTNlc7",
    "outputId": "07cabae3-d85d-4c80-e69e-ba26efaafccb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                                       0\n",
       "futures_open_interest_history__open     4636\n",
       "futures_open_interest_history__high     4636\n",
       "futures_open_interest_history__low      4636\n",
       "futures_open_interest_history__close    4636\n",
       "                                        ... \n",
       "open                                    4636\n",
       "high                                    4636\n",
       "low                                     4636\n",
       "close                                   4636\n",
       "volume_usd                              4636\n",
       "Length: 99, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iw6Ko8CQhSIu",
    "outputId": "3e25ac1a-7e64-4844-88cb-4b1f443fc19d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__diff1\"] = out[c].diff(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[c + \"__pct1\"] = out[c].pct_change(1)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[new_col] = (a - b) / (a + b + eps)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[new_col] = (a - b) / (a + b + eps)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[new_col] = (a - b) / (a + b + eps)\n",
      "C:\\Users\\flays\\AppData\\Local\\Temp\\ipykernel_10160\\1357788098.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[new_col] = (a - b) / (a + b + eps)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "N_DAYS = 1\n",
    "# ---------- 1) Нормализация спот-колонок ----------\n",
    "def ensure_spot_prefix(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    mapping = {\n",
    "        \"open\": \"spot_price_history__open\",\n",
    "        \"high\": \"spot_price_history__high\",\n",
    "        \"low\": \"spot_price_history__low\",\n",
    "        \"close\": \"spot_price_history__close\",\n",
    "        \"volume_usd\": \"spot_price_history__volume_usd\",\n",
    "    }\n",
    "    # переименуем только если целевой префикс-колонки ещё нет\n",
    "    rename = {}\n",
    "    for old, new in mapping.items():\n",
    "        if old in out.columns and new not in out.columns:\n",
    "            rename[old] = new\n",
    "    if rename:\n",
    "        out = out.rename(columns=rename)\n",
    "    return out\n",
    "\n",
    "\n",
    "# ---------- 2) Бинарный таргет на завтра ----------\n",
    "def add_y_up_1d(df: pd.DataFrame, close_col: str = \"spot_price_history__close\") -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    out[\"date\"] = pd.to_datetime(out[\"date\"], errors=\"coerce\")\n",
    "    out = out.sort_values(\"date\", kind=\"stable\").reset_index(drop=True)\n",
    "\n",
    "    c = pd.to_numeric(out[close_col], errors=\"coerce\")\n",
    "    out[\"y_up_1d\"] = (c.shift(-1*N_DAYS) > c).astype(\"Int64\")\n",
    "    return out\n",
    "\n",
    "\n",
    "# ---------- 3) Feature engineering: diff/pct + imbalance ----------\n",
    "def add_engineered_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    eps = 1e-12\n",
    "\n",
    "    # diff/pct для всех numeric (кроме таргета)\n",
    "    base_numeric = [\n",
    "        c for c in out.columns\n",
    "        if c not in {\"date\", \"y_up_1d\"}\n",
    "        and pd.api.types.is_numeric_dtype(out[c])\n",
    "    ]\n",
    "    for c in base_numeric:\n",
    "        out[c + \"__diff1\"] = out[c].diff(1)\n",
    "        out[c + \"__pct1\"] = out[c].pct_change(1)\n",
    "\n",
    "    # imbalances (если пары колонок есть)\n",
    "    def _imbalance(num_col_a, num_col_b, new_col):\n",
    "        if num_col_a in out.columns and num_col_b in out.columns:\n",
    "            a = pd.to_numeric(out[num_col_a], errors=\"coerce\")\n",
    "            b = pd.to_numeric(out[num_col_b], errors=\"coerce\")\n",
    "            out[new_col] = (a - b) / (a + b + eps)\n",
    "\n",
    "    _imbalance(\n",
    "        \"futures_v2_taker_buy_sell_volume_history__taker_buy_volume_usd\",\n",
    "        \"futures_v2_taker_buy_sell_volume_history__taker_sell_volume_usd\",\n",
    "        \"feat__taker_imbalance_v2\",\n",
    "    )\n",
    "    _imbalance(\n",
    "        \"futures_aggregated_taker_buy_sell_volume_history__aggregated_buy_volume_usd\",\n",
    "        \"futures_aggregated_taker_buy_sell_volume_history__aggregated_sell_volume_usd\",\n",
    "        \"feat__taker_imbalance_agg\",\n",
    "    )\n",
    "    _imbalance(\n",
    "        \"futures_liquidation_history__short_liquidation_usd\",\n",
    "        \"futures_liquidation_history__long_liquidation_usd\",\n",
    "        \"feat__liq_imbalance_short_minus_long\",\n",
    "    )\n",
    "    _imbalance(\n",
    "        \"futures_orderbook_ask_bids_history__bids_usd\",\n",
    "        \"futures_orderbook_ask_bids_history__asks_usd\",\n",
    "        \"feat__orderbook_imbalance_usd\",\n",
    "    )\n",
    "\n",
    "    # почистим бесконечности\n",
    "    out = out.replace([np.inf, -np.inf], np.nan)\n",
    "    return out\n",
    "\n",
    "\n",
    "# ---------- 4) Корреляции + (опционально) p-value + FDR ----------\n",
    "def bh_fdr(pvals: pd.Series) -> pd.Series:\n",
    "    p = pvals.dropna()\n",
    "    n = len(p)\n",
    "    out = pd.Series(np.nan, index=pvals.index, dtype=\"float64\")\n",
    "    if n == 0:\n",
    "        return out\n",
    "    order = np.argsort(p.values)\n",
    "    ranked = p.values[order]\n",
    "    q = ranked * n / (np.arange(1, n + 1))\n",
    "    q = np.minimum.accumulate(q[::-1])[::-1]\n",
    "    out.loc[p.index[order]] = np.clip(q, 0, 1)\n",
    "    return out\n",
    "\n",
    "\n",
    "def corr_report(df: pd.DataFrame, method: str = \"pearson\", min_n: int = 60) -> pd.DataFrame:\n",
    "    tmp = df.copy()\n",
    "    tmp[\"y_up_1d\"] = pd.to_numeric(tmp[\"y_up_1d\"], errors=\"coerce\")\n",
    "\n",
    "    features = [\n",
    "        c for c in tmp.columns\n",
    "        if c not in {\"date\", \"y_up_1d\"}\n",
    "        and pd.api.types.is_numeric_dtype(tmp[c])\n",
    "    ]\n",
    "\n",
    "    # быстрый corr (без p-values)\n",
    "    corr = tmp[features].corrwith(tmp[\"y_up_1d\"], method=method)\n",
    "    res = corr.rename(\"corr\").to_frame()\n",
    "    res[\"abs_corr\"] = res[\"corr\"].abs()\n",
    "\n",
    "    # n по каждой фиче\n",
    "    y = tmp[\"y_up_1d\"]\n",
    "    n_list = []\n",
    "    for c in features:\n",
    "        m = tmp[c].notna() & y.notna()\n",
    "        n_list.append(int(m.sum()))\n",
    "    res[\"n\"] = n_list\n",
    "\n",
    "    # p-values если доступен scipy\n",
    "    try:\n",
    "        from scipy.stats import pearsonr, spearmanr\n",
    "        pvals = []\n",
    "        for c in features:\n",
    "            m = tmp[c].notna() & y.notna()\n",
    "            if m.sum() < min_n:\n",
    "                pvals.append(np.nan)\n",
    "                continue\n",
    "            x = pd.to_numeric(tmp.loc[m, c], errors=\"coerce\")\n",
    "            yy = tmp.loc[m, \"y_up_1d\"]\n",
    "            if method == \"pearson\":\n",
    "                _, p = pearsonr(x, yy)\n",
    "            else:\n",
    "                _, p = spearmanr(x, yy)\n",
    "            pvals.append(p)\n",
    "        res[\"p_value\"] = pvals\n",
    "        res[\"q_value_fdr\"] = bh_fdr(res[\"p_value\"])\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    res = (\n",
    "        res.reset_index()\n",
    "           .rename(columns={\"index\": \"feature\"})\n",
    "           .sort_values(\"abs_corr\", ascending=False)\n",
    "           .reset_index(drop=True)\n",
    "    )\n",
    "    return res\n",
    "\n",
    "\n",
    "# ===================== RUN =====================\n",
    "df0 = ensure_spot_prefix(df_all)\n",
    "df1 = add_y_up_1d(df0, close_col=\"spot_price_history__close\")\n",
    "df1 = df1.dropna(subset=[\"y_up_1d\", \"spot_price_history__close\"]).reset_index(drop=True)\n",
    "\n",
    "df2 = add_engineered_features(df1)\n",
    "\n",
    "pear = corr_report(df2, method=\"pearson\", min_n=60)\n",
    "spear = corr_report(df2, method=\"spearman\", min_n=60)\n",
    "\n",
    "# print(\"Class balance y_up_1d:\")\n",
    "# print(df2[\"y_up_1d\"].value_counts(dropna=False), \"\\nUp-rate:\", float(df2[\"y_up_1d\"].mean()))\n",
    "\n",
    "# print(\"\\nTop-30 Pearson:\")\n",
    "# print(pear.head(30))\n",
    "\n",
    "# print(\"\\nTop-30 Spearman:\")\n",
    "# print(spear.head(30))\n",
    "\n",
    "# # если p_value/q_value_fdr есть — удобно посмотреть, что реально значимо\n",
    "# if \"q_value_fdr\" in pear.columns:\n",
    "#     print(\"\\nPearson: features with q_value_fdr <= 0.10 (если есть):\")\n",
    "#     print(pear[pear[\"q_value_fdr\"] <= 0.10].head(50))\n",
    "\n",
    "# print(df2.isna().sum().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "AZ7Wy2rCLwOR"
   },
   "outputs": [],
   "source": [
    "df_ml = df_all.copy()\n",
    "df_ml[\"date\"] = pd.to_datetime(df_ml[\"date\"], errors=\"coerce\")\n",
    "df_ml = df_ml.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "close = pd.to_numeric(df_ml[\"close\"], errors=\"coerce\")\n",
    "df_ml[\"y_up_1d\"] = (close.shift(-1*N_DAYS) > close).astype(\"Int64\")\n",
    "\n",
    "df_ml = df_ml.dropna(subset=[\"y_up_1d\", \"close\"]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l1H1Os45hXpJ",
    "outputId": "a6f9d20e-bca6-4acf-bfd7-ac952ef9516c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              feature      corr   p_value  \\\n",
      "0                                      cb_premium_abs  0.058288  0.065402   \n",
      "1                    index_btc_lth_supply__lth_supply  0.056903  0.072364   \n",
      "2                    index_btc_sth_supply__sth_supply -0.048604  0.124926   \n",
      "3                                   cgdi_dev_softsign -0.048388  0.185302   \n",
      "4   futures_top_long_short_position_ratio_history_... -0.047385  0.134285   \n",
      "5                                      cgdi_log_level -0.046743  0.200714   \n",
      "6   futures_open_interest_aggregated_stablecoin_hi... -0.046290  0.143529   \n",
      "7   futures_top_long_short_position_ratio_history_... -0.045409  0.151315   \n",
      "8   futures_top_long_short_position_ratio_history_...  0.045409  0.151315   \n",
      "9   futures_open_interest_aggregated_stablecoin_hi... -0.044113  0.163347   \n",
      "10                                   cgdi_index_value -0.042985  0.239371   \n",
      "11                                 cgdi_dev_from_base -0.042985  0.239371   \n",
      "12  futures_open_interest_aggregated_stablecoin_hi... -0.039183  0.215711   \n",
      "13  futures_v2_taker_buy_sell_volume_history__take...  0.033595  0.288533   \n",
      "14  futures_open_interest_aggregated_stablecoin_hi... -0.032931  0.298174   \n",
      "15                  futures_funding_rate_history__low  0.032905  0.298558   \n",
      "16                       index_btc_reserve_risk__vocd  0.032520  0.304741   \n",
      "17  futures_v2_taker_buy_sell_volume_history__take...  0.032021  0.311739   \n",
      "18                          bfx_margin_log_long_short -0.031505  0.319601   \n",
      "19                               cb_implied_ref_price -0.031153  0.325044   \n",
      "20               futures_open_interest_history__close -0.028502  0.367931   \n",
      "21  futures_top_long_short_account_ratio_history__...  0.028356  0.370386   \n",
      "22  futures_top_long_short_account_ratio_history__... -0.028356  0.370386   \n",
      "23                futures_funding_rate_history__close  0.027609  0.383124   \n",
      "24                 futures_open_interest_history__low -0.027472  0.385486   \n",
      "25       futures_orderbook_ask_bids_history__asks_usd -0.025861  0.515038   \n",
      "26  futures_aggregated_taker_buy_sell_volume_histo...  0.025799  0.415102   \n",
      "27  futures_orderbook_aggregated_ask_bids_history_... -0.025373  0.523002   \n",
      "28                futures_open_interest_history__open -0.024026  0.447891   \n",
      "29   futures_v2_net_position_history__net_long_change -0.023914  0.450010   \n",
      "\n",
      "       n  abs_corr  q_value_fdr  \n",
      "0   1000  0.058288     0.962168  \n",
      "1    998  0.056903     0.962168  \n",
      "2    998  0.048604     0.962168  \n",
      "3    751  0.048388     0.962168  \n",
      "4   1000  0.047385     0.962168  \n",
      "5    751  0.046743     0.962168  \n",
      "6   1000  0.046290     0.962168  \n",
      "7   1000  0.045409     0.962168  \n",
      "8   1000  0.045409     0.962168  \n",
      "9   1000  0.044113     0.962168  \n",
      "10   751  0.042985     0.962168  \n",
      "11   751  0.042985     0.962168  \n",
      "12  1000  0.039183     0.962168  \n",
      "13  1000  0.033595     0.962168  \n",
      "14  1000  0.032931     0.962168  \n",
      "15  1000  0.032905     0.962168  \n",
      "16   998  0.032520     0.962168  \n",
      "17  1000  0.032021     0.962168  \n",
      "18  1000  0.031505     0.962168  \n",
      "19  1000  0.031153     0.962168  \n",
      "20  1000  0.028502     0.962168  \n",
      "21  1000  0.028356     0.962168  \n",
      "22  1000  0.028356     0.962168  \n",
      "23  1000  0.027609     0.962168  \n",
      "24  1000  0.027472     0.962168  \n",
      "25   636  0.025861     0.962168  \n",
      "26  1000  0.025799     0.962168  \n",
      "27   636  0.025373     0.962168  \n",
      "28  1000  0.024026     0.962168  \n",
      "29  1000  0.023914     0.962168  \n",
      "                                              feature      corr  abs_corr  \\\n",
      "0               index_btc_reserve_risk__log_rr__diff1 -0.068402  0.068402   \n",
      "1                   index_btc_lth_supply__price__pct1 -0.067929  0.067929   \n",
      "2                 index_btc_reserve_risk__price__pct1 -0.067929  0.067929   \n",
      "3                   index_btc_sth_supply__price__pct1 -0.067929  0.067929   \n",
      "4    index_btc_reserve_risk__reserve_risk_index__pct1 -0.067543  0.067543   \n",
      "5                index_btc_reserve_risk__log_rr__pct1  0.066819  0.066819   \n",
      "6   futures_open_interest_aggregated_history__clos... -0.066217  0.066217   \n",
      "7   futures_liquidation_aggregated_history__aggreg... -0.063572  0.063572   \n",
      "8                     spot_price_history__close__pct1 -0.063199  0.063199   \n",
      "9   index_btc_reserve_risk__reserve_risk_index__diff1 -0.061507  0.061507   \n",
      "10  futures_global_long_short_account_ratio_histor... -0.061321  0.061321   \n",
      "11       index_btc_active_addresses__aa_slope14__pct1 -0.061129  0.061129   \n",
      "12           futures_funding_rate_history__open__pct1 -0.060186  0.060186   \n",
      "13           index_btc_sth_supply__supply_pct30__pct1 -0.059003  0.059003   \n",
      "14  futures_top_long_short_account_ratio_history__... -0.058385  0.058385   \n",
      "15                                     cb_premium_abs  0.058288  0.058288   \n",
      "16                   index_btc_lth_supply__lth_supply  0.056903  0.056903   \n",
      "17  futures_global_long_short_account_ratio_histor... -0.056509  0.056509   \n",
      "18  futures_liquidation_history__short_liquidation... -0.055580  0.055580   \n",
      "19  futures_global_long_short_account_ratio_histor...  0.054443  0.054443   \n",
      "20  futures_global_long_short_account_ratio_histor... -0.054443  0.054443   \n",
      "21  futures_top_long_short_position_ratio_history_... -0.053890  0.053890   \n",
      "22  futures_top_long_short_account_ratio_history__... -0.053791  0.053791   \n",
      "23  futures_open_interest_aggregated_history__low_... -0.053460  0.053460   \n",
      "24  futures_top_long_short_account_ratio_history__... -0.052797  0.052797   \n",
      "25  futures_top_long_short_account_ratio_history__...  0.052797  0.052797   \n",
      "26                   bfx_margin_log_long_short__diff1 -0.051494  0.051494   \n",
      "27             index_btc_reserve_risk__rr_z180__diff1 -0.050576  0.050576   \n",
      "28  futures_top_long_short_position_ratio_history_... -0.049892  0.049892   \n",
      "29         futures_open_interest_history__close__pct1 -0.049805  0.049805   \n",
      "\n",
      "       n   p_value  q_value_fdr  \n",
      "0    996  0.030886     0.920135  \n",
      "1    999  0.031808     0.920135  \n",
      "2    999  0.031808     0.920135  \n",
      "3    999  0.031808     0.920135  \n",
      "4    999  0.032795     0.920135  \n",
      "5    999  0.034715     0.920135  \n",
      "6    999  0.036386     0.920135  \n",
      "7    999  0.044554     0.920135  \n",
      "8    999  0.045824     0.920135  \n",
      "9    996  0.052317     0.920135  \n",
      "10   999  0.052675     0.920135  \n",
      "11   999  0.053421     0.920135  \n",
      "12   999  0.057218     0.920135  \n",
      "13   999  0.062296     0.920135  \n",
      "14   999  0.065091     0.920135  \n",
      "15  1000  0.065402     0.920135  \n",
      "16   998  0.072364     0.920135  \n",
      "17   999  0.074220     0.920135  \n",
      "18   999  0.079112     0.920135  \n",
      "19   999  0.085451     0.920135  \n",
      "20   999  0.085451     0.920135  \n",
      "21   999  0.088680     0.920135  \n",
      "22   999  0.089267     0.920135  \n",
      "23   999  0.091258     0.920135  \n",
      "24   999  0.095353     0.920135  \n",
      "25   999  0.095353     0.920135  \n",
      "26   999  0.103822     0.920135  \n",
      "27   996  0.110676     0.920135  \n",
      "28   999  0.115036     0.920135  \n",
      "29   999  0.115674     0.920135  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "def bh_fdr(pvals: pd.Series) -> pd.Series:\n",
    "    \"\"\"Benjamini–Hochberg FDR.\"\"\"\n",
    "    p = pvals.dropna()\n",
    "    n = len(p)\n",
    "    if n == 0:\n",
    "        return pvals\n",
    "    order = np.argsort(p.values)\n",
    "    ranked = p.values[order]\n",
    "    q = ranked * n / (np.arange(1, n+1))\n",
    "    q = np.minimum.accumulate(q[::-1])[::-1]\n",
    "    out = pd.Series(np.nan, index=pvals.index, dtype=\"float64\")\n",
    "    out.loc[p.index[order]] = np.clip(q, 0, 1)\n",
    "    return out\n",
    "\n",
    "def corr_table_with_pvalues(df: pd.DataFrame, target=\"y_up_1d\", method=\"pearson\") -> pd.DataFrame:\n",
    "    y = pd.to_numeric(df[target], errors=\"coerce\")\n",
    "    num_cols = [c for c in df.columns if c not in {\"date\", target} and pd.api.types.is_numeric_dtype(df[c])]\n",
    "    rows = []\n",
    "    for c in num_cols:\n",
    "        x = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "        m = x.notna() & y.notna()\n",
    "        if m.sum() < 30:\n",
    "            continue\n",
    "        if method == \"pearson\":\n",
    "            r, p = pearsonr(x[m], y[m])\n",
    "        else:\n",
    "            r, p = spearmanr(x[m], y[m])\n",
    "        rows.append((c, r, p, m.sum()))\n",
    "    res = pd.DataFrame(rows, columns=[\"feature\", \"corr\", \"p_value\", \"n\"])\n",
    "    res[\"abs_corr\"] = res[\"corr\"].abs()\n",
    "    res[\"q_value_fdr\"] = bh_fdr(res[\"p_value\"])\n",
    "    return res.sort_values(\"abs_corr\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "corr_p = corr_table_with_pvalues(df_ml, method=\"pearson\")\n",
    "corr_s = corr_table_with_pvalues(df_ml, method=\"spearman\")\n",
    "\n",
    "print(corr_p.head(30))\n",
    "# print(corr_s.head(30))\n",
    "print(pear.head(30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QM0vs7pphElM",
    "outputId": "43f54ba1-a7a3-437b-f5fe-1ae1c4ef870c"
   },
   "outputs": [],
   "source": [
    "df_feat = df_ml.copy()\n",
    "\n",
    "# 1) Изменения (дельты) и % изменения для ключевых фич\n",
    "for c in df_feat.columns:\n",
    "    if c in {\"date\", \"y_up_1d\"}:\n",
    "        continue\n",
    "    if pd.api.types.is_numeric_dtype(df_feat[c]):\n",
    "        df_feat[c + \"__diff1\"] = df_feat[c].diff(1)\n",
    "        df_feat[c + \"__pct1\"] = df_feat[c].pct_change(1)\n",
    "\n",
    "# 2) Дисбалансы (пример: taker, liquidation, orderbook)\n",
    "eps = 1e-12\n",
    "\n",
    "if \"futures_v2_taker_buy_sell_volume_history__taker_buy_volume_usd\" in df_feat.columns and \\\n",
    "   \"futures_v2_taker_buy_sell_volume_history__taker_sell_volume_usd\" in df_feat.columns:\n",
    "    buy = df_feat[\"futures_v2_taker_buy_sell_volume_history__taker_buy_volume_usd\"]\n",
    "    sell = df_feat[\"futures_v2_taker_buy_sell_volume_history__taker_sell_volume_usd\"]\n",
    "    df_feat[\"taker_imbalance\"] = (buy - sell) / (buy + sell + eps)\n",
    "\n",
    "if \"futures_liquidation_history__long_liquidation_usd\" in df_feat.columns and \\\n",
    "   \"futures_liquidation_history__short_liquidation_usd\" in df_feat.columns:\n",
    "    L = df_feat[\"futures_liquidation_history__long_liquidation_usd\"]\n",
    "    S = df_feat[\"futures_liquidation_history__short_liquidation_usd\"]\n",
    "    df_feat[\"liq_imbalance\"] = (S - L) / (S + L + eps)  # знак можно менять под твою логику\n",
    "\n",
    "if \"futures_orderbook_ask_bids_history__bids_usd\" in df_feat.columns and \\\n",
    "   \"futures_orderbook_ask_bids_history__asks_usd\" in df_feat.columns:\n",
    "    b = df_feat[\"futures_orderbook_ask_bids_history__bids_usd\"]\n",
    "    a = df_feat[\"futures_orderbook_ask_bids_history__asks_usd\"]\n",
    "    df_feat[\"ob_imbalance_usd\"] = (b - a) / (b + a + eps)\n",
    "\n",
    "df_feat = df_feat.replace([np.inf, -np.inf], np.nan).dropna(subset=[\"y_up_1d\"]).reset_index(drop=True)\n",
    "\n",
    "corr_p2 = corr_table_with_pvalues(df_feat, method=\"pearson\")\n",
    "print(corr_p2.head(30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HzXrWGVMitXM",
    "outputId": "6dfee4d8-7fa0-4d23-8af6-424e520f5da2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def group_effect_report(df: pd.DataFrame, target=\"y_up_1d\", top_n=30) -> pd.DataFrame:\n",
    "    y = pd.to_numeric(df[target], errors=\"coerce\")\n",
    "    feats = [c for c in df.columns if c not in {\"date\", target} and pd.api.types.is_numeric_dtype(df[c])]\n",
    "\n",
    "    rows = []\n",
    "    for f in feats:\n",
    "        x = pd.to_numeric(df[f], errors=\"coerce\")\n",
    "        m = x.notna() & y.notna()\n",
    "        if m.sum() < 60:\n",
    "            continue\n",
    "        x0 = x[m & (y == 0)]\n",
    "        x1 = x[m & (y == 1)]\n",
    "        if len(x0) < 20 or len(x1) < 20:\n",
    "            continue\n",
    "\n",
    "        mean0, mean1 = float(x0.mean()), float(x1.mean())\n",
    "        std0, std1 = float(x0.std(ddof=1)), float(x1.std(ddof=1))\n",
    "        pooled = np.sqrt(((len(x0)-1)*std0**2 + (len(x1)-1)*std1**2) / (len(x0)+len(x1)-2))\n",
    "        d = (mean1 - mean0) / (pooled + 1e-12)\n",
    "\n",
    "        rows.append((f, mean1, mean0, mean1-mean0, abs(d), d, len(x1), len(x0)))\n",
    "\n",
    "    res = pd.DataFrame(rows, columns=[\"feature\",\"mean_y1\",\"mean_y0\",\"lift\",\"abs_cohen_d\",\"cohen_d\",\"n_y1\",\"n_y0\"])\n",
    "    return res.sort_values(\"abs_cohen_d\", ascending=False).head(top_n).reset_index(drop=True)\n",
    "\n",
    "effect_tbl = group_effect_report(df2, target=\"y_up_1d\", top_n=30)\n",
    "print(effect_tbl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T_Mhh3LdfnEQ",
    "outputId": "75d49b78-0146-49b6-c3eb-d64dec120a5e"
   },
   "outputs": [],
   "source": [
    "# убедись, что нет NaN в date и что даты монотонны\n",
    "df2 = df2.sort_values(\"date\").reset_index(drop=True)\n",
    "assert df2[\"date\"].isna().sum() == 0\n",
    "assert (pd.to_datetime(df2[\"date\"]).diff().dropna() >= pd.Timedelta(0)).all()\n",
    "\n",
    "# проверка что таргет действительно завтрашний close относительно сегодняшнего\n",
    "c = df2[\"spot_price_history__close\"]\n",
    "y_check = (c.shift(-1*N_DAYS) > c).astype(\"Int64\")\n",
    "print(\"y совпадает:\", (y_check == df2[\"y_up_1d\"]).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2FmAk176fmLd",
    "outputId": "246f68c5-fec4-4467-f8be-c9ae09104c32"
   },
   "outputs": [],
   "source": [
    "def add_coverage(effect_tbl: pd.DataFrame, df: pd.DataFrame) -> pd.DataFrame:\n",
    "    eff = effect_tbl.copy()\n",
    "    eff[\"coverage\"] = eff[\"feature\"].apply(lambda c: float(df[c].notna().mean()) if c in df.columns else 0.0)\n",
    "    return eff.sort_values([\"abs_cohen_d\", \"coverage\"], ascending=[False, False]).reset_index(drop=True)\n",
    "\n",
    "effect_tbl_cov = add_coverage(effect_tbl, df2)   # df2 = датафрейм с y_up_1d и engineered features\n",
    "print(effect_tbl_cov.head(30))\n",
    "\n",
    "# Например, оставим только фичи с покрытием >= 0.85\n",
    "good_features = effect_tbl_cov.query(\"coverage >= 0.85\")[\"feature\"].tolist()\n",
    "print(\"features kept:\", len(good_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RaGUR-_7fmJA",
    "outputId": "c6d6b134-62bf-4f73-af0e-a6b39187b4fb"
   },
   "outputs": [],
   "source": [
    "corr_p = corr_table_with_pvalues(df2, method=\"pearson\")   # из прошлого кода\n",
    "corr_s = corr_table_with_pvalues(df2, method=\"spearman\")\n",
    "\n",
    "print(corr_p.head(30))\n",
    "print(\"Significant (q<=0.10):\")\n",
    "print(corr_p[corr_p[\"q_value_fdr\"] <= 0.10].head(50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "02dQowHPrPZU",
    "outputId": "50679306-8062-4c8d-cc26-b406c4be1f65"
   },
   "outputs": [],
   "source": [
    "pear[pear['abs_corr'] > 0.06]['feature'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j4u8LRKRR_k5"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score\n",
    "\n",
    "def walk_forward_logreg(\n",
    "    df: pd.DataFrame,\n",
    "    features: list[str],\n",
    "    target: str = \"y_up_1d\",\n",
    "    n_splits: int = 5,\n",
    "    thr: float = 0.5,\n",
    "):\n",
    "    d = df.copy()\n",
    "    d[\"date\"] = pd.to_datetime(d[\"date\"], errors=\"coerce\")\n",
    "    d = d.sort_values(\"date\", kind=\"stable\").reset_index(drop=True)\n",
    "\n",
    "    X = d[features].copy()\n",
    "    y = pd.to_numeric(d[target], errors=\"coerce\")\n",
    "\n",
    "    m = y.notna() & X.notna().any(axis=1)\n",
    "    X, y = X.loc[m].reset_index(drop=True), y.loc[m].astype(int).reset_index(drop=True)\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(max_iter=3000, class_weight=\"balanced\")),\n",
    "    ])\n",
    "\n",
    "    accs, aucs, precs, recs = [], [], [], []\n",
    "    for train_idx, test_idx in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        pipe.fit(X_train, y_train)\n",
    "        proba = pipe.predict_proba(X_test)[:, 1]\n",
    "        pred = (proba >= thr).astype(int)\n",
    "\n",
    "        accs.append(accuracy_score(y_test, pred))\n",
    "        precs.append(precision_score(y_test, pred, zero_division=0))\n",
    "        recs.append(recall_score(y_test, pred, zero_division=0))\n",
    "\n",
    "        # ROC AUC: если один класс — ставим nan, но длину сохраняем\n",
    "        if len(np.unique(y_test)) == 2:\n",
    "            aucs.append(roc_auc_score(y_test, proba))\n",
    "        else:\n",
    "            aucs.append(np.nan)\n",
    "\n",
    "    return {\n",
    "        \"n_features\": len(features),\n",
    "        \"thr\": thr,\n",
    "        \"acc_mean\": float(np.nanmean(accs)),\n",
    "        \"acc_splits\": accs,\n",
    "        \"precision_mean\": float(np.nanmean(precs)),\n",
    "        \"precision_splits\": precs,\n",
    "        \"recall_mean\": float(np.nanmean(recs)),\n",
    "        \"recall_splits\": recs,\n",
    "        \"auc_mean\": float(np.nanmean(aucs)),\n",
    "        \"auc_splits\": aucs,\n",
    "    }\n",
    "\n",
    "\n",
    "def print_metrics(res: dict, title: str = \"RESULTS\"):\n",
    "    print(f\"\\n{title}\")\n",
    "    print(f\"thr={res['thr']} | n_features={res['n_features']}\")\n",
    "    print(f\"Precision: {res['precision_mean']:.4f} | splits: {np.round(res['precision_splits'], 4)}\")\n",
    "    print(f\"Recall:    {res['recall_mean']:.4f} | splits: {np.round(res['recall_splits'], 4)}\")\n",
    "    print(f\"ROC AUC:   {res['auc_mean']:.4f} | splits: {np.round(res['auc_splits'], 4)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V36y0HO0Ra0M"
   },
   "outputs": [],
   "source": [
    "# Range model\n",
    "\n",
    "def add_range_target(\n",
    "    df: pd.DataFrame,\n",
    "    high_col: str,\n",
    "    low_col: str,\n",
    "    close_col: str | None = None,   # если хочешь дополнительно range_pct\n",
    "    date_col: str = \"date\",\n",
    "    ma_window: int = 14,\n",
    "    horizon: int = 1,               # N дней вперед для таргета\n",
    "    use_pct: bool = False,          # False: high-low, True: (high-low)/close\n",
    "    baseline_shift: int = 1,        # 1 => SMA только по прошлым дням (без leakage)\n",
    "    out_target_col: str | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    d = df.copy()\n",
    "    d[date_col] = pd.to_datetime(d[date_col], errors=\"coerce\")\n",
    "    d = d.sort_values(date_col, kind=\"stable\").reset_index(drop=True)\n",
    "\n",
    "    hi = pd.to_numeric(d[high_col], errors=\"coerce\")\n",
    "    lo = pd.to_numeric(d[low_col], errors=\"coerce\")\n",
    "    rng = hi - lo\n",
    "\n",
    "    d[\"range_abs\"] = rng\n",
    "\n",
    "    if close_col is not None:\n",
    "        close = pd.to_numeric(d[close_col], errors=\"coerce\")\n",
    "        d[\"range_pct\"] = rng / close\n",
    "    else:\n",
    "        d[\"range_pct\"] = np.nan\n",
    "\n",
    "    # выбираем, на чем строим таргет и baseline\n",
    "    base_series = d[\"range_pct\"] if use_pct else d[\"range_abs\"]\n",
    "    base_name = \"range_pct\" if use_pct else \"range_abs\"\n",
    "\n",
    "    # baseline SMA(14) — только прошлое (shift=1)\n",
    "    d[f\"{base_name}_ma{ma_window}\"] = (\n",
    "        base_series.shift(baseline_shift).rolling(ma_window, min_periods=ma_window).mean()\n",
    "    )\n",
    "\n",
    "    # будущий range на горизонте N\n",
    "    fut = base_series.shift(-horizon)\n",
    "\n",
    "    # бинарный таргет: будущий range выше/ниже текущей SMA(14)\n",
    "    y = np.where(\n",
    "        fut.notna() & d[f\"{base_name}_ma{ma_window}\"].notna(),\n",
    "        (fut > d[f\"{base_name}_ma{ma_window}\"]).astype(int),\n",
    "        np.nan,\n",
    "    )\n",
    "\n",
    "    if out_target_col is None:\n",
    "        out_target_col = f\"y_range_up_{base_name}_N{horizon}_ma{ma_window}\"\n",
    "\n",
    "    d[out_target_col] = y\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hStuKMKYRayT",
    "outputId": "13cbf06a-58c0-41b3-e56c-fee0a50d6feb"
   },
   "outputs": [],
   "source": [
    "HIGH_COL  = \"spot_price_history__high\"\n",
    "LOW_COL   = \"spot_price_history__low\"\n",
    "CLOSE_COL = \"spot_price_history__close\"\n",
    "\n",
    "\n",
    "d_rngp = add_range_target(\n",
    "    df2,\n",
    "    high_col=HIGH_COL,\n",
    "    low_col=LOW_COL,\n",
    "    close_col=CLOSE_COL,\n",
    "    ma_window=14,\n",
    "    horizon=1,\n",
    "    use_pct=True,      # (high-low)/close\n",
    "    baseline_shift=1,\n",
    ")\n",
    "\n",
    "target_col = \"y_range_up_range_pct_N1_ma14\"\n",
    "\n",
    "range_feats = [\n",
    "    \"range_pct\",\n",
    "    \"range_pct_ma14\",\n",
    "]\n",
    "feat_set = [c for c in (base_feats + range_feats) if c in d_rngp.columns]\n",
    "\n",
    "# res_rngp = walk_forward_logreg(d_rngp, features=feat_set, target=target_col, n_splits=5, thr=0.5)\n",
    "# print(res_rngp)\n",
    "res_rngp = walk_forward_logreg(d_rngp, features=feat_set, target=target_col, n_splits=5, thr=0.5)\n",
    "res_rngp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9pvCKWPtRhCx"
   },
   "outputs": [],
   "source": [
    "d_rngp['y_range_up_range_pct_N1_ma14'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JeiGCFSfdYA2",
    "outputId": "7756cea8-b9d5-4fe0-ed7e-c72f52777c8b"
   },
   "outputs": [],
   "source": [
    "# prediction models\n",
    "def add_lags(df: pd.DataFrame, cols: list[str], lags=(1, 2)) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    out[\"date\"] = pd.to_datetime(out[\"date\"], errors=\"coerce\")\n",
    "    out = out.sort_values(\"date\", kind=\"stable\").reset_index(drop=True)\n",
    "    for c in cols:\n",
    "        if c in out.columns:\n",
    "            x = pd.to_numeric(out[c], errors=\"coerce\")\n",
    "            for L in lags:\n",
    "                out[f\"{c}__lag{L}\"] = x.shift(L)\n",
    "    return out\n",
    "\n",
    "# BASE фичи (твои) для одного дня\n",
    "base_feats = [\n",
    "    \"spot_price_history__close__pct1\",\n",
    "    \"spot_price_history__close__diff1\",\n",
    "    \"futures_open_interest_aggregated_history__close__pct1\",\n",
    "    \"futures_liquidation_aggregated_history__aggregated_short_liquidation_usd__diff1\",\n",
    "    \"futures_global_long_short_account_ratio_history__global_account_long_percent__pct1\"\n",
    "    \"futures_top_long_short_account_ratio_history__top_account_long_short_ratio__pct1\"\n",
    "    \"premium__diff1\",\n",
    "    \"cb_premium_abs\"\n",
    "    ]\n",
    "\n",
    "# base_feats = ['index_btc_reserve_risk__log_rr__diff1',\n",
    "#        'index_btc_sth_supply__price__pct1',\n",
    "#        'index_btc_reserve_risk__price__pct1',\n",
    "#        'index_btc_lth_supply__price__pct1',\n",
    "#        'index_btc_reserve_risk__reserve_risk_index__pct1',\n",
    "#        'futures_open_interest_aggregated_history__close__pct1',\n",
    "#        'index_btc_reserve_risk__log_rr__pct1',\n",
    "#        'spot_price_history__close__pct1',\n",
    "#        'index_btc_reserve_risk__reserve_risk_index__diff1',\n",
    "#        'futures_liquidation_aggregated_history__aggregated_short_liquidation_usd__diff1',\n",
    "#        'futures_funding_rate_history__open__pct1',\n",
    "#        'index_btc_active_addresses__aa_slope14__pct1'\n",
    "#        ]\n",
    "\n",
    "# base фичи для 3 дней\n",
    "# base_feats = [\n",
    "#     \"spot_price_history__close__pct1\",\n",
    "#     \"spot_price_history__close__diff1\",\n",
    "#     'feat__orderbook_imbalance_usd',\n",
    "#     'futures_liquidation_aggregated_history__aggregated_short_liquidation_usd__diff1'\n",
    "#     'futures_open_interest_aggregated_stablecoin_history__close',\n",
    "#     'futures_open_interest_aggregated_stablecoin_history__low',\n",
    "#     'cgdi_log_level', 'cgdi_dev_softsign', 'cgdi_dev_from_base',\n",
    "#     'cgdi_index_value'\n",
    "# ]\n",
    "\n",
    "# base фичи для 4 days\n",
    "# base_feats = [\n",
    "#     'futures_open_interest_aggregated_stablecoin_history__close',\n",
    "#        'feat__orderbook_imbalance_usd',\n",
    "#        'futures_open_interest_aggregated_stablecoin_history__low',\n",
    "#        'futures_open_interest_history__low__diff1',\n",
    "#        'futures_open_interest_aggregated_stablecoin_history__open',\n",
    "#        'cgdi_dev_from_base', 'cgdi_index_value',\n",
    "#        'futures_open_interest_aggregated_stablecoin_history__high',\n",
    "#        'cgdi_log_level', 'cgdi_dev_softsign'\n",
    "# ]\n",
    "\n",
    "# base features for 5 days\n",
    "# base_feats = [\n",
    "#     'cgdi_dev_from_base', 'cgdi_index_value', 'cgdi_log_level',\n",
    "#        'cgdi_dev_softsign',\n",
    "#        'futures_open_interest_aggregated_stablecoin_history__close',\n",
    "#        'futures_open_interest_aggregated_stablecoin_history__low',\n",
    "#        'futures_open_interest_aggregated_stablecoin_history__high',\n",
    "#        'futures_open_interest_aggregated_stablecoin_history__open',\n",
    "#        'futures_orderbook_aggregated_ask_bids_history__aggregated_asks_usd__pct1',\n",
    "#        'futures_orderbook_ask_bids_history__asks_usd__pct1'\n",
    "# ]\n",
    "\n",
    "# base features for 7 days\n",
    "# base_feats = [\n",
    "#     'cgdi_dev_from_base', 'cgdi_index_value', 'cgdi_log_level',\n",
    "#        'cgdi_dev_softsign',\n",
    "#        'futures_open_interest_aggregated_stablecoin_history__close',\n",
    "#        'futures_open_interest_aggregated_stablecoin_history__low',\n",
    "#        'futures_open_interest_aggregated_stablecoin_history__high',\n",
    "#        'futures_open_interest_aggregated_stablecoin_history__open',\n",
    "#        'futures_orderbook_aggregated_ask_bids_history__aggregated_asks_usd__pct1',\n",
    "#        'futures_orderbook_ask_bids_history__asks_usd__pct1'\n",
    "# ]\n",
    "\n",
    "base_feats = [c for c in base_feats if c in df2.columns]\n",
    "\n",
    "# какие из них деривативные (кроме спота) — на них делаем лаги\n",
    "deriv = [c for c in base_feats if not c.startswith(\"spot_price_history__\")]\n",
    "\n",
    "df_lag = add_lags(df2, cols=deriv, lags=(1, 2,3 ,7 ))\n",
    "\n",
    "lag_feats = (\n",
    "    base_feats\n",
    "    + [f\"{c}__lag1\" for c in deriv]\n",
    "    + [f\"{c}__lag2\" for c in deriv]\n",
    "    + [f\"{c}__lag3\" for c in deriv]\n",
    "    + [f\"{c}__lag5\" for c in deriv]  # было lag4, но ты создаёшь lag5\n",
    ")\n",
    "lag_feats = [c for c in lag_feats if c in df_lag.columns]\n",
    "\n",
    "print(\"BASE feats:\", base_feats)\n",
    "print(\"LAG feats:\", lag_feats)\n",
    "\n",
    "res_base = walk_forward_logreg(df2, base_feats, n_splits=5, thr=0.5)\n",
    "res_lag  = walk_forward_logreg(df_lag, lag_feats, n_splits=5, thr=0.5)\n",
    "\n",
    "print(\"\\nBASE:\", res_base)\n",
    "print(\"\\nLAG :\", res_lag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0WBgyF33tWes",
    "outputId": "af16f5bf-28bf-4e8f-fc7e-dc8a7df6412a"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "# --------- CV eval (one config) ----------\n",
    "def walk_forward_logreg_cfg(\n",
    "    df: pd.DataFrame,\n",
    "    features: list[str],\n",
    "    target: str = \"y_up_1d\",\n",
    "    n_splits: int = 5,\n",
    "    thr: float = 0.5,\n",
    "    imputer_strategy: str = \"mean\",          # \"mean\" | \"median\"\n",
    "    C: float = 1.0,\n",
    "    penalty: str = \"l2\",                     # \"l1\" | \"l2\" | \"elasticnet\"\n",
    "    solver: str = \"lbfgs\",                   # lbfgs/liblinear/saga\n",
    "    l1_ratio: float | None = None,           # only for elasticnet+saga\n",
    "    class_weight: str | dict | None = \"balanced\",\n",
    "):\n",
    "    d = df.copy()\n",
    "    d[\"date\"] = pd.to_datetime(d[\"date\"], errors=\"coerce\")\n",
    "    d = d.sort_values(\"date\", kind=\"stable\").reset_index(drop=True)\n",
    "\n",
    "    X = d[features].copy()\n",
    "    y = pd.to_numeric(d[target], errors=\"coerce\")\n",
    "\n",
    "    m = y.notna() & X.notna().any(axis=1)\n",
    "    X, y = X.loc[m].reset_index(drop=True), y.loc[m].astype(int).reset_index(drop=True)\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "    clf_kwargs = dict(\n",
    "        max_iter=4000,\n",
    "        class_weight=class_weight,\n",
    "        C=float(C),\n",
    "        penalty=penalty,\n",
    "        solver=solver,\n",
    "    )\n",
    "    if penalty == \"elasticnet\":\n",
    "        clf_kwargs[\"l1_ratio\"] = float(l1_ratio if l1_ratio is not None else 0.5)\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=imputer_strategy)),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(**clf_kwargs)),\n",
    "    ])\n",
    "\n",
    "    accs, aucs, precs, recs = [], [], [], []\n",
    "    for tr, te in tscv.split(X):\n",
    "        X_tr, X_te = X.iloc[tr], X.iloc[te]\n",
    "        y_tr, y_te = y.iloc[tr], y.iloc[te]\n",
    "\n",
    "        pipe.fit(X_tr, y_tr)\n",
    "        proba = pipe.predict_proba(X_te)[:, 1]\n",
    "        pred = (proba >= thr).astype(int)\n",
    "\n",
    "        accs.append(accuracy_score(y_te, pred))\n",
    "        precs.append(precision_score(y_te, pred, zero_division=0))\n",
    "        recs.append(recall_score(y_te, pred, zero_division=0))\n",
    "\n",
    "        if y_te.nunique() == 2:\n",
    "            aucs.append(roc_auc_score(y_te, proba))\n",
    "\n",
    "    return {\n",
    "        \"thr\": thr,\n",
    "        \"imputer\": imputer_strategy,\n",
    "        \"C\": float(C),\n",
    "        \"penalty\": penalty,\n",
    "        \"solver\": solver,\n",
    "        \"l1_ratio\": None if penalty != \"elasticnet\" else float(clf_kwargs[\"l1_ratio\"]),\n",
    "        \"n_features\": len(features),\n",
    "        \"acc_mean\": float(np.mean(accs)),\n",
    "        \"precision_mean\": float(np.mean(precs)),\n",
    "        \"recall_mean\": float(np.mean(recs)),\n",
    "        \"auc_mean\": float(np.mean(aucs)) if aucs else np.nan,\n",
    "        \"acc_splits\": accs,\n",
    "        \"auc_splits\": aucs,\n",
    "    }\n",
    "\n",
    "\n",
    "# --------- Simple grid search ----------\n",
    "def tune_logreg_timecv(\n",
    "    df: pd.DataFrame,\n",
    "    features: list[str],\n",
    "    target: str = \"y_up_1d\",\n",
    "    n_splits: int = 5,\n",
    "    score: str = \"auc\",          # \"auc\" | \"acc\" | \"precision\" | \"recall\"\n",
    "    topk: int = 10,\n",
    "):\n",
    "    # небольшая, но полезная сетка\n",
    "    grid = []\n",
    "\n",
    "    # L2 (обычно лучший дефолт)\n",
    "    for imp in [\"mean\", \"median\"]:\n",
    "        for thr in [0.5, 0.52, 0.55]:\n",
    "            for C in [0.05, 0.1, 0.3, 1.0, 3.0, 10.0]:\n",
    "                grid.append(dict(imputer_strategy=imp, thr=thr, C=C, penalty=\"l2\", solver=\"lbfgs\", l1_ratio=None))\n",
    "\n",
    "    # L1 (saga)\n",
    "    for imp in [\"mean\", \"median\"]:\n",
    "        for thr in [0.5, 0.52, 0.55]:\n",
    "            for C in [0.05, 0.1, 0.3, 1.0, 3.0]:\n",
    "                grid.append(dict(imputer_strategy=imp, thr=thr, C=C, penalty=\"l1\", solver=\"saga\", l1_ratio=None))\n",
    "\n",
    "    # ElasticNet (saga)\n",
    "    for imp in [\"mean\", \"median\"]:\n",
    "        for thr in [0.5, 0.52, 0.55]:\n",
    "            for C in [0.05, 0.1, 0.3, 1.0, 3.0]:\n",
    "                for l1r in [0.2, 0.5, 0.8]:\n",
    "                    grid.append(dict(imputer_strategy=imp, thr=thr, C=C, penalty=\"elasticnet\", solver=\"saga\", l1_ratio=l1r))\n",
    "\n",
    "    rows = []\n",
    "    for cfg in tqdm(grid):\n",
    "        try:\n",
    "            r = walk_forward_logreg_cfg(\n",
    "                df=df,\n",
    "                features=features,\n",
    "                target=target,\n",
    "                n_splits=n_splits,\n",
    "                thr=cfg[\"thr\"],\n",
    "                imputer_strategy=cfg[\"imputer_strategy\"],\n",
    "                C=cfg[\"C\"],\n",
    "                penalty=cfg[\"penalty\"],\n",
    "                solver=cfg[\"solver\"],\n",
    "                l1_ratio=cfg[\"l1_ratio\"],\n",
    "            )\n",
    "            rows.append(r)\n",
    "        except Exception as e:\n",
    "            # некоторые комбинации могут падать (редко, но бывает) — просто пропускаем\n",
    "            continue\n",
    "\n",
    "    res = pd.DataFrame(rows)\n",
    "\n",
    "    key = {\n",
    "        \"auc\": \"auc_mean\",\n",
    "        \"acc\": \"acc_mean\",\n",
    "        \"precision\": \"precision_mean\",\n",
    "        \"recall\": \"recall_mean\",\n",
    "    }[score]\n",
    "\n",
    "    res = res.sort_values(key, ascending=False).reset_index(drop=True)\n",
    "    return res.head(topk), res\n",
    "\n",
    "\n",
    "# -------------------- RUN --------------------\n",
    "print(\"BASE feats:\", base_feats)\n",
    "print(\"LAG  feats:\", lag_feats)\n",
    "\n",
    "top_base, all_base = tune_logreg_timecv(df2, base_feats, target=\"y_up_1d\", n_splits=5, score=\"auc\", topk=10)\n",
    "top_lag,  all_lag  = tune_logreg_timecv(df_lag, lag_feats, target=\"y_up_1d\", n_splits=5, score=\"auc\", topk=10)\n",
    "\n",
    "print(\"\\nTOP BASE by AUC:\")\n",
    "print(top_base[[\"auc_mean\",\"acc_mean\",\"precision_mean\",\"recall_mean\",\"thr\",\"imputer\",\"penalty\",\"solver\",\"C\",\"l1_ratio\",\"n_features\"]])\n",
    "\n",
    "print(\"\\nTOP LAG by AUC:\")\n",
    "print(top_lag[[\"auc_mean\",\"acc_mean\",\"precision_mean\",\"recall_mean\",\"thr\",\"imputer\",\"penalty\",\"solver\",\"C\",\"l1_ratio\",\"n_features\"]])\n",
    "\n",
    "# если хочешь сохранить лучшую конфигурацию:\n",
    "best = top_lag.iloc[0].to_dict() if len(top_lag) else top_base.iloc[0].to_dict()\n",
    "print(\"\\nBEST CONFIG:\", {k: best[k] for k in [\"auc_mean\",\"thr\",\"imputer\",\"penalty\",\"solver\",\"C\",\"l1_ratio\"]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oum8n_-dt2IU",
    "outputId": "852a0e5a-c6ef-4b4a-e4fd-bec7cc37c5c2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "\n",
    "def oos_predictions_logreg(df: pd.DataFrame, features: list[str], target=\"y_up_1d\", n_splits=5):\n",
    "    d = df.copy()\n",
    "    d[\"date\"] = pd.to_datetime(d[\"date\"], errors=\"coerce\")\n",
    "    d = d.sort_values(\"date\", kind=\"stable\").reset_index(drop=True)\n",
    "\n",
    "    X = d[features].copy()\n",
    "    y = pd.to_numeric(d[target], errors=\"coerce\")\n",
    "\n",
    "    m = y.notna() & X.notna().any(axis=1)\n",
    "    X = X.loc[m].reset_index(drop=True)\n",
    "    y = y.loc[m].astype(int).reset_index(drop=True)\n",
    "    dates = d.loc[m, \"date\"].reset_index(drop=True)\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(max_iter=3000, class_weight=\"balanced\")),\n",
    "    ])\n",
    "\n",
    "    proba_oos = np.full(len(X), np.nan)\n",
    "    fold_id = np.full(len(X), -1, dtype=int)\n",
    "\n",
    "    for i, (tr, te) in enumerate(tscv.split(X), start=1):\n",
    "        pipe.fit(X.iloc[tr], y.iloc[tr])\n",
    "        p = pipe.predict_proba(X.iloc[te])[:, 1]\n",
    "        proba_oos[te] = p\n",
    "        fold_id[te] = i\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"date\": dates,\n",
    "        \"y\": y,\n",
    "        \"p_up\": proba_oos,\n",
    "        \"fold\": fold_id,\n",
    "    }).dropna(subset=[\"p_up\"]).reset_index(drop=True)\n",
    "\n",
    "    # общие метрики\n",
    "    auc = roc_auc_score(out[\"y\"], out[\"p_up\"])\n",
    "    acc = accuracy_score(out[\"y\"], (out[\"p_up\"] >= 0.5).astype(int))\n",
    "    return out, auc, acc\n",
    "\n",
    "\n",
    "def threshold_report(oos: pd.DataFrame, up_thr=0.55, down_thr=0.45):\n",
    "    # long if p>=up_thr, short if p<=down_thr, else no trade\n",
    "    p = oos[\"p_up\"]\n",
    "    y = oos[\"y\"]\n",
    "\n",
    "    take_long = p >= up_thr\n",
    "    take_short = p <= down_thr\n",
    "    take = take_long | take_short\n",
    "\n",
    "    correct = (take_long & (y == 1)) | (take_short & (y == 0))\n",
    "\n",
    "    rep = {\n",
    "        \"up_thr\": up_thr,\n",
    "        \"down_thr\": down_thr,\n",
    "        \"coverage_trades\": float(take.mean()),\n",
    "        \"winrate_on_trades\": float(correct[take].mean()) if take.any() else np.nan,\n",
    "        \"n_trades\": int(take.sum()),\n",
    "        \"n_long\": int(take_long.sum()),\n",
    "        \"n_short\": int(take_short.sum()),\n",
    "        \"avg_p_up_all\": float(p.mean()),\n",
    "        \"avg_p_up_long\": float(p[take_long].mean()) if take_long.any() else np.nan,\n",
    "        \"avg_p_up_short\": float(p[take_short].mean()) if take_short.any() else np.nan,\n",
    "    }\n",
    "    return rep\n",
    "\n",
    "\n",
    "# ----- run -----\n",
    "oos, auc, acc = oos_predictions_logreg(df2, base_feats, n_splits=5)\n",
    "print(\"OOS AUC:\", auc, \"OOS ACC@0.5:\", acc)\n",
    "\n",
    "# попробуем сетку порогов\n",
    "for up_thr, down_thr in [(0.505, 0.495),(0.51, 0.49),(0.52,0.48),(0.55,0.45),(0.57,0.43),(0.60,0.40), (0.62, 0.38), (0.7, 0.3)]:\n",
    "    print(threshold_report(oos, up_thr=up_thr, down_thr=down_thr))\n",
    "\n",
    "# можно посмотреть по фолдам\n",
    "by_fold = oos.groupby(\"fold\").apply(lambda g: pd.Series({\n",
    "    \"auc\": roc_auc_score(g[\"y\"], g[\"p_up\"]) if g[\"y\"].nunique()==2 else np.nan,\n",
    "    \"acc\": accuracy_score(g[\"y\"], (g[\"p_up\"]>=0.5).astype(int)),\n",
    "    \"n\": len(g)\n",
    "})).reset_index()\n",
    "print(by_fold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5qiG4GFla6vx",
    "outputId": "3eb93863-c0b3-4f21-baa1-c3da7366ef35"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, accuracy_score\n",
    "\n",
    "def fold_diagnostics(oos: pd.DataFrame):\n",
    "    rows = []\n",
    "    for f, g in oos.groupby(\"fold\"):\n",
    "        y = g[\"y\"].astype(int).values\n",
    "        p = g[\"p_up\"].values\n",
    "        pred = (p >= 0.5).astype(int)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y, pred, labels=[0,1]).ravel()\n",
    "        rows.append({\n",
    "            \"fold\": f,\n",
    "            \"n\": len(g),\n",
    "            \"y_mean\": float(y.mean()),\n",
    "            \"p_mean\": float(np.mean(p)),\n",
    "            \"auc\": roc_auc_score(y, p) if len(np.unique(y))==2 else np.nan,\n",
    "            \"acc\": accuracy_score(y, pred),\n",
    "            \"pred_pos_rate\": float(pred.mean()),\n",
    "            \"TP\": int(tp), \"FP\": int(fp), \"TN\": int(tn), \"FN\": int(fn),\n",
    "        })\n",
    "    return pd.DataFrame(rows).sort_values(\"fold\").reset_index(drop=True)\n",
    "\n",
    "print(fold_diagnostics(oos))\n",
    "print(\"BASE always-long acc:\", float(oos[\"y\"].mean()))\n",
    "print(\"BASE always-short acc:\", float(1 - oos[\"y\"].mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ackPijl-bLdS",
    "outputId": "eddd457c-fc43-4e30-8c1d-e2d9d0ac396b"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "print(\"Brier:\", brier_score_loss(oos[\"y\"].astype(int), oos[\"p_up\"]))\n",
    "\n",
    "# квантильный lift: winrate по бинам вероятности\n",
    "tmp = oos.copy()\n",
    "tmp[\"bin\"] = pd.qcut(tmp[\"p_up\"], q=10, duplicates=\"drop\")\n",
    "lift = tmp.groupby(\"bin\").apply(lambda g: pd.Series({\n",
    "    \"n\": len(g),\n",
    "    \"avg_p\": g[\"p_up\"].mean(),\n",
    "    \"win_if_long\": float((g[\"y\"]==1).mean()),\n",
    "})).reset_index()\n",
    "print(lift.sort_values(\"avg_p\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 963
    },
    "id": "To1yCF6vy3j-",
    "outputId": "b381b3ee-7bc4-4822-b7b7-866c94606de1"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "def oos_proba_logreg(df: pd.DataFrame, features: list[str], target: str = \"y_up_1d\", n_splits: int = 5):\n",
    "    d = df.copy()\n",
    "    d[\"date\"] = pd.to_datetime(d[\"date\"], errors=\"coerce\")\n",
    "    d = d.sort_values(\"date\", kind=\"stable\").reset_index(drop=True)\n",
    "\n",
    "    X = d[features].copy()\n",
    "    y = pd.to_numeric(d[target], errors=\"coerce\")\n",
    "\n",
    "    m = y.notna() & X.notna().any(axis=1)\n",
    "    X, y = X.loc[m].reset_index(drop=True), y.loc[m].astype(int).reset_index(drop=True)\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(max_iter=3000, class_weight=\"balanced\")),\n",
    "    ])\n",
    "\n",
    "    proba_oos = np.full(len(X), np.nan)\n",
    "    for train_idx, test_idx in tscv.split(X):\n",
    "        pipe.fit(X.iloc[train_idx], y.iloc[train_idx])\n",
    "        proba_oos[test_idx] = pipe.predict_proba(X.iloc[test_idx])[:, 1]\n",
    "\n",
    "    out = pd.DataFrame({\"y\": y, \"p\": proba_oos}).dropna()\n",
    "    return out[\"y\"].values, out[\"p\"].values\n",
    "\n",
    "\n",
    "def plot_roc(y, p, title=\"ROC\"):\n",
    "    auc = roc_auc_score(y, p)\n",
    "    fpr, tpr, _ = roc_curve(y, p)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f\"AUC={auc:.4f}\")\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\", label=\"random\")\n",
    "    plt.xlabel(\"FPR\")\n",
    "    plt.ylabel(\"TPR\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return auc\n",
    "\n",
    "\n",
    "y_b, p_b = oos_proba_logreg(df2, base_feats, n_splits=5)\n",
    "auc_b = plot_roc(y_b, p_b, title=\"ROC (BASE, OOS)\")\n",
    "\n",
    "y_l, p_l = oos_proba_logreg(df_lag, lag_feats, n_splits=5)\n",
    "auc_l = plot_roc(y_l, p_l, title=\"ROC (LAG, OOS)\")\n",
    "\n",
    "print(\"AUC BASE:\", auc_b)\n",
    "print(\"AUC LAG :\", auc_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
